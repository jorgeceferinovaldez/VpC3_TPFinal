{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V7EYBOY7HZu3","executionInfo":{"status":"ok","timestamp":1748724972527,"user_tz":180,"elapsed":21313,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}},"outputId":"d4a484b0-a2a2-4731-94ef-5884b0d62930"},"id":"V7EYBOY7HZu3","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"id":"aa8fd880","metadata":{"id":"aa8fd880","executionInfo":{"status":"ok","timestamp":1748724989890,"user_tz":180,"elapsed":14269,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","from timm.models import create_model\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset\n","from torchvision import transforms\n","\n","from tqdm import tqdm\n","from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n","from PIL import Image\n","import random\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import sys\n","import json"]},{"cell_type":"markdown","id":"54461da9","metadata":{"id":"54461da9"},"source":["### Modelos"]},{"cell_type":"code","execution_count":3,"id":"14392931","metadata":{"id":"14392931","executionInfo":{"status":"ok","timestamp":1748725004367,"user_tz":180,"elapsed":4,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["# Modelos de detección de anomalías con Swin Transformer\n","# Modelo supervisado (clasificación normal vs. anómalo)\n","class SwinTransformerAnomalyDetector(nn.Module):\n","    def __init__(self, pretrained=True, num_classes=1):\n","        super(SwinTransformerAnomalyDetector, self).__init__()\n","        # Cargar modelo Swin Transformer preentrenado\n","        self.swin = create_model(\n","            'swin_tiny_patch4_window7_224',\n","            pretrained=pretrained,\n","            num_classes=0  # Sin cabeza de clasificación\n","        )\n","\n","        # Agregar cabeza de detección de anomalías\n","        self.anomaly_head = nn.Sequential(\n","            nn.Linear(768, 256),  # 768 es la dimensión de salida del Swin-T\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(256, 64),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.Linear(64, num_classes),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        features = self.swin(x)\n","        return self.anomaly_head(features)"]},{"cell_type":"code","execution_count":4,"id":"87f0eadc","metadata":{"id":"87f0eadc","executionInfo":{"status":"ok","timestamp":1748725007524,"user_tz":180,"elapsed":3,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["# Modelo no supervisado (autoencoder para reconstrucción)\n","class SwinTransformerAutoencoder(nn.Module):\n","    def __init__(self, pretrained=True):\n","        super(SwinTransformerAutoencoder, self).__init__()\n","        # Codificador: Swin Transformer preentrenado\n","        self.encoder = create_model(\n","            'swin_tiny_patch4_window7_224',\n","            pretrained=pretrained,\n","            num_classes=0\n","        )\n","\n","        # Decodificador para reconstruir la imagen\n","        self.decoder = nn.Sequential(\n","            nn.Linear(768, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 224*224*3),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        # Obtener representación latente\n","        latent = self.encoder(x)\n","        # Reconstruir la imagen\n","        batch_size = x.size(0)\n","        reconstructed = self.decoder(latent).view(batch_size, 3, 224, 224)\n","        return reconstructed, latent\n","\n","    def detect_anomaly(self, x):\n","        reconstructed, _ = self.forward(x)\n","        # Calcular error de reconstrucción como MSE\n","        reconstruction_error = torch.mean((x - reconstructed) ** 2, dim=[1, 2, 3])\n","        return reconstruction_error  # Mayor error = mayor probabilidad de anomalía\n"]},{"cell_type":"markdown","id":"a38c443c","metadata":{"id":"a38c443c"},"source":["### Funciones y clases auxiliares\n"]},{"cell_type":"code","execution_count":5,"id":"6ecf1516","metadata":{"id":"6ecf1516","executionInfo":{"status":"ok","timestamp":1748725010523,"user_tz":180,"elapsed":2,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["# Dataset y DataLoader para MVTec AD\n","class MVTecDataset(Dataset):\n","    def __init__(self, root_path, category, is_train=True, transform=None, mask_transform=None):\n","        \"\"\"\n","        Args:\n","            root_path: Ruta al directorio raíz de MVTec AD\n","            category: Categoría de objetos ('bottle', 'cable', 'carpet', etc.)\n","            is_train: Si es True, carga imágenes de entrenamiento (normales)\n","                      Si es False, carga imágenes de prueba (normales y anómalas)\n","            transform: Transformaciones opcionales a aplicar a las imágenes\n","            mask_transform: Transformaciones opcionales a aplicar a las máscaras\n","        \"\"\"\n","        self.root_path = root_path\n","        self.category = category\n","        self.is_train = is_train\n","        self.transform = transform\n","        self.mask_transform = mask_transform\n","\n","        # Definir directorios\n","        if self.is_train:\n","            self.image_dir = os.path.join(root_path, category, 'train', 'good')\n","            self.image_paths = [os.path.join(self.image_dir, f) for f in os.listdir(self.image_dir)\n","                               if f.endswith('.png')]\n","            self.labels = np.zeros(len(self.image_paths), dtype=np.float32)  # 0 = normal\n","            self.mask_paths = None\n","\n","        else:  # Test set\n","            self.image_dir = os.path.join(root_path, category, 'test')\n","            self.image_paths = []\n","            self.labels = []\n","            self.mask_paths = []\n","\n","            # Imágenes normales (buenas)\n","            good_dir = os.path.join(self.image_dir, 'good')\n","            if os.path.exists(good_dir):\n","                good_images = [os.path.join(good_dir, f) for f in os.listdir(good_dir)\n","                              if f.endswith('.png')]\n","                self.image_paths.extend(good_images)\n","                self.labels.extend([0] * len(good_images))  # 0 = normal\n","                self.mask_paths.extend([None] * len(good_images))\n","\n","            # Imágenes anómalas (con defectos)\n","            defect_types = [d for d in os.listdir(self.image_dir)\n","                           if os.path.isdir(os.path.join(self.image_dir, d)) and d != 'good']\n","\n","            for defect in defect_types:\n","                defect_dir = os.path.join(self.image_dir, defect)\n","                defect_images = [os.path.join(defect_dir, f) for f in os.listdir(defect_dir)\n","                                if f.endswith('.png')]\n","                self.image_paths.extend(defect_images)\n","                self.labels.extend([1] * len(defect_images))  # 1 = anomalía\n","\n","                # Añadir máscaras de ground truth (si existen)\n","                gt_dir = os.path.join(root_path, category, 'ground_truth', defect)\n","                if os.path.exists(gt_dir):\n","                    for img_path in defect_images:\n","                        img_name = os.path.basename(img_path)\n","                        mask_name = img_name.replace('.png', '_mask.png')\n","                        mask_path = os.path.join(gt_dir, mask_name)\n","                        if os.path.exists(mask_path):\n","                            self.mask_paths.append(mask_path)\n","                        else:\n","                            self.mask_paths.append(None)\n","                else:\n","                    self.mask_paths.extend([None] * len(defect_images))\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        # Cargar imagen\n","        img_path = self.image_paths[idx]\n","        image = Image.open(img_path).convert('RGB') # Convertir a RGB\n","        label = self.labels[idx]\n","\n","        # Cargar máscara si existe (solo para test y anomalías)\n","        mask = None\n","        if not self.is_train and self.mask_paths[idx] is not None: # Si es test y hay máscara\n","            mask_path = self.mask_paths[idx]\n","            mask = Image.open(mask_path).convert('L') # Convertir a escala de grises\n","            if self.mask_transform:\n","                mask = self.mask_transform(mask) # Aplicar transformaciones a la máscara\n","            elif self.transform:\n","                mask = transforms.Compose([\n","                    transforms.Resize((224, 224)),\n","                    transforms.ToTensor(),\n","                ])(mask) # Aplicar transformaciones por defecto a la máscara\n","        else:\n","            # Crear una máscara vacía si no existe\n","            mask = torch.zeros((1, 224, 224))\n","\n","        # Aplicar transformaciones a la imagen\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        # Siempre devolver tres elementos\n","        return image, label, mask"]},{"cell_type":"code","execution_count":6,"id":"ef60b12e","metadata":{"id":"ef60b12e","executionInfo":{"status":"ok","timestamp":1748725014073,"user_tz":180,"elapsed":11,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["def split_test_datasets(test_datasets, categories, test_size=0.5, random_state=42):\n","    \"\"\"\n","    Divide cada dataset de test en validation y test final\n","\n","    Args:\n","        test_datasets: Lista de datasets de test\n","        categories: Lista de nombres de categorías\n","        test_size: Proporción para test final (0.5 = 50% val, 50% test)\n","        random_state: Semilla para reproducibilidad\n","\n","    Returns:\n","        val_datasets, final_test_datasets: Listas de datasets divididos\n","    \"\"\"\n","    val_datasets = []\n","    final_test_datasets = []\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"DIVISIÓN DE DATASETS DE TEST\")\n","    print(\"=\"*60)\n","\n","    for i, test_dataset in enumerate(test_datasets):\n","        # Obtener índices del dataset\n","        indices = list(range(len(test_dataset)))\n","\n","        # Dividir índices manteniendo la proporción de anomalías\n","        labels = [test_dataset.labels[j] for j in indices]\n","\n","        # Contar normales y anomalías\n","        normal_count = sum(1 for l in labels if l == 0)\n","        anomaly_count = sum(1 for l in labels if l == 1)\n","\n","        try:\n","            val_indices, test_indices = train_test_split(\n","                indices,\n","                test_size=test_size,\n","                stratify=labels,  # Mantener proporción de normales/anómalas\n","                random_state=random_state\n","            )\n","        except ValueError:\n","            # Si no se puede estratificar (ej: solo una clase), hacer split simple\n","            val_indices, test_indices = train_test_split(\n","                indices,\n","                test_size=test_size,\n","                random_state=random_state\n","            )\n","\n","        # Crear subsets\n","        val_subset = Subset(test_dataset, val_indices)\n","        test_subset = Subset(test_dataset, test_indices)\n","\n","        val_datasets.append(val_subset)\n","        final_test_datasets.append(test_subset)\n","\n","        print(f\"{categories[i]:12} | Total: {len(indices):3} | \"\n","              f\"Normal: {normal_count:3} | Anomalía: {anomaly_count:3} | \"\n","              f\"Val: {len(val_subset):3} | Test: {len(test_subset):3}\")\n","\n","    print(\"=\"*60)\n","    return val_datasets, final_test_datasets"]},{"cell_type":"markdown","id":"b9c0aecb","metadata":{"id":"b9c0aecb"},"source":["### Funciones de entrenamiento"]},{"cell_type":"code","execution_count":7,"id":"e9bb6e57","metadata":{"id":"e9bb6e57","executionInfo":{"status":"ok","timestamp":1748725017431,"user_tz":180,"elapsed":16,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["# Entrenamiento del modelo supervisado\n","def train_supervised_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, output_dir):\n","    \"\"\"Entrena un modelo supervisado de detección de anomalías\"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","    best_auc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        # Entrenamiento\n","        model.train()\n","        train_loss = 0.0\n","\n","        for images, labels, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (train)\"):\n","            images = images.to(device)\n","            labels = labels.to(device).float().view(-1, 1)\n","\n","            # Forward\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            # Backward\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","        # Validación\n","        model.eval()\n","        val_loss = 0.0\n","        all_scores = []\n","        all_labels = []\n","\n","        with torch.no_grad():\n","            for images, labels, _ in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (val)\"):\n","                images = images.to(device)\n","                labels = labels.to(device).float().view(-1, 1)\n","\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","\n","                all_scores.extend(outputs.cpu().numpy().flatten())\n","                all_labels.extend(labels.cpu().numpy().flatten())\n","\n","        # Calcular ROC AUC\n","        fpr, tpr, _ = roc_curve(all_labels, all_scores)\n","        roc_auc = auc(fpr, tpr)\n","\n","        # Guardar el mejor modelo\n","        if roc_auc > best_auc:\n","            best_auc = roc_auc\n","            torch.save(model.state_dict(), os.path.join(output_dir, 'mejor_modelo_supervisado.pth'))\n","            print(f\"     Nuevo mejor modelo guardado! AUC: {roc_auc:.4f}\")\n","\n","        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n","              f\"Train Loss: {train_loss/len(train_loader):.4f}, \"\n","              f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n","              f\"ROC AUC: {roc_auc:.4f}\")\n","\n","        scheduler.step()\n","\n","    return model"]},{"cell_type":"code","execution_count":8,"id":"9923750a","metadata":{"id":"9923750a","executionInfo":{"status":"ok","timestamp":1748725020598,"user_tz":180,"elapsed":12,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["def train_autoencoder_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, output_dir):\n","    \"\"\"Entrena un modelo de autoencoder para detección de anomalías no supervisada\"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","    best_auc = 0.0\n","    best_val_loss = float('inf')  # Para casos donde no se puede calcular AUC\n","\n","    for epoch in range(num_epochs):\n","        # Entrenamiento (solo con imágenes normales)\n","        model.train()\n","        train_loss = 0.0\n","\n","        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (train)\"):\n","            images, _, _ = batch  # Desempacar correctamente (imagen, etiqueta, máscara)\n","            images = images.to(device)\n","\n","            # Forward\n","            reconstructed, _ = model(images)\n","            loss = criterion(reconstructed, images)\n","\n","            # Backward\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","        # Validación - Calcular val_loss y ROC AUC\n","        model.eval()\n","        val_loss = 0.0\n","        all_scores = []\n","        all_labels = []\n","\n","        with torch.no_grad():\n","            for images, labels, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (val)\"):\n","                images = images.to(device)\n","\n","                reconstructed, _ = model(images)\n","\n","                # Calcular validation loss (solo en imágenes normales para ser consistente)\n","                normal_mask = labels == 0\n","                if normal_mask.sum() > 0:\n","                    normal_images = images[normal_mask]\n","                    normal_reconstructed = reconstructed[normal_mask]\n","                    val_loss += criterion(normal_reconstructed, normal_images).item()\n","\n","                # Calcular error de reconstrucción por imagen (para ROC AUC)\n","                error = torch.mean((images - reconstructed) ** 2, dim=[1, 2, 3])\n","\n","                all_scores.extend(error.cpu().numpy())\n","                all_labels.extend(labels.numpy())\n","\n","        # Calcular métricas\n","        avg_train_loss = train_loss / len(train_loader)\n","        avg_val_loss = val_loss / len(val_loader) if val_loss > 0 else 0.0\n","\n","        # ROC AUC solo si tenemos ambas clases (normal y anomalía)\n","        if len(set(all_labels)) > 1:\n","            fpr, tpr, _ = roc_curve(all_labels, all_scores)\n","            roc_auc = auc(fpr, tpr)\n","\n","            # Guardar el mejor modelo basado en AUC\n","            if roc_auc > best_auc:\n","                best_auc = roc_auc\n","                torch.save(model.state_dict(), os.path.join(output_dir, 'mejor_modelo_multiclase_autoencoder.pth'))\n","                print(f\"     Nuevo mejor modelo guardado! AUC: {roc_auc:.4f}\")\n","\n","            print(f\"Epoch {epoch+1}/{num_epochs}, \"\n","                  f\"Train Loss: {avg_train_loss:.4f}, \"\n","                  f\"Val Loss: {avg_val_loss:.4f}, \"\n","                  f\"ROC AUC: {roc_auc:.4f}\")\n","        else:\n","            # Si solo tenemos una clase, guardar basado en val_loss\n","            if epoch == 0 or avg_val_loss < best_val_loss:\n","                best_val_loss = avg_val_loss\n","                torch.save(model.state_dict(), os.path.join(output_dir, 'mejor_modelo_autoencoder.pth'))\n","                print(f\"     Nuevo mejor modelo guardado! Val Loss: {avg_val_loss:.4f}\")\n","\n","            print(f\"Epoch {epoch+1}/{num_epochs}, \"\n","                  f\"Train Loss: {avg_train_loss:.4f}, \"\n","                  f\"Val Loss: {avg_val_loss:.4f}\")\n","\n","        scheduler.step()\n","\n","    return model"]},{"cell_type":"markdown","id":"6634e8ac","metadata":{"id":"6634e8ac"},"source":["### Funciones de Visualización"]},{"cell_type":"code","execution_count":9,"id":"78ba2e46","metadata":{"id":"78ba2e46","executionInfo":{"status":"ok","timestamp":1748725023990,"user_tz":180,"elapsed":42,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["def visualize_examples(images, labels, scores, masks, threshold, output_dir, model_type):\n","    \"\"\"Visualiza ejemplos de predicciones correctas e incorrectas\"\"\"\n","    # Crear directorio principal si no existe\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Crear directorio de examples\n","    examples_dir = os.path.join(output_dir, 'examples')\n","    os.makedirs(examples_dir, exist_ok=True)\n","\n","    print(f\"Creando visualizaciones en: {examples_dir}\")\n","\n","    # Convertir a numpy arrays si no lo son\n","    images = np.array(images)\n","    labels = np.array(labels)\n","    scores = np.array(scores)\n","    predictions = (scores >= threshold).astype(int)\n","\n","    print(f\"Total de imágenes: {len(images)}\")\n","    print(f\"Distribución de etiquetas - Normal: {np.sum(labels == 0)}, Anomalía: {np.sum(labels == 1)}\")\n","    print(f\"Distribución de predicciones - Normal: {np.sum(predictions == 0)}, Anomalía: {np.sum(predictions == 1)}\")\n","\n","    # Índices para cada categoría (TP, TN, FP, FN)\n","    true_positive = np.where((predictions == 1) & (labels == 1))[0]\n","    true_negative = np.where((predictions == 0) & (labels == 0))[0]\n","    false_positive = np.where((predictions == 1) & (labels == 0))[0]\n","    false_negative = np.where((predictions == 0) & (labels == 1))[0]\n","\n","    print(f\"True Positives: {len(true_positive)}\")\n","    print(f\"True Negatives: {len(true_negative)}\")\n","    print(f\"False Positives: {len(false_positive)}\")\n","    print(f\"False Negatives: {len(false_negative)}\")\n","\n","    # Limitar número de ejemplos\n","    max_examples = 5\n","    categories = [\n","        ('true_positive', true_positive[:max_examples]),\n","        ('true_negative', true_negative[:max_examples]),\n","        ('false_positive', false_positive[:max_examples]),\n","        ('false_negative', false_negative[:max_examples])\n","    ]\n","\n","    # Determinar si tenemos máscaras disponibles\n","    has_masks = len(masks) > 0 and any(mask is not None for mask in masks)\n","    print(f\"Máscaras disponibles: {has_masks}\")\n","\n","    # Visualizar ejemplos por categoría\n","    for category_name, indices in categories:\n","        if len(indices) == 0:\n","            print(f\"No hay ejemplos para {category_name}\")\n","            continue\n","\n","        print(f\"Creando visualización para {category_name} con {len(indices)} ejemplos\")\n","\n","        # Determinar el número de subplots (2 o 3 columnas por muestra)\n","        n_cols = 3 if has_masks else 2\n","        fig_width = 4 * len(indices) * n_cols\n","        fig_height = 4\n","\n","        plt.figure(figsize=(fig_width, fig_height))\n","\n","        for i, idx in enumerate(indices):\n","            try:\n","                # Imagen original\n","                subplot_idx = i * n_cols + 1\n","                plt.subplot(1, len(indices) * n_cols, subplot_idx)\n","\n","                img = images[idx]\n","                if img.shape[0] == 3:  # Si está en formato CHW\n","                    img = img.transpose(1, 2, 0)  # Convertir a HWC\n","\n","                # Desnormalizar la imagen\n","                img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n","                img = np.clip(img, 0, 1)\n","\n","                plt.imshow(img)\n","                plt.title(f\"Original\\nScore: {scores[idx]:.4f}\\nLabel: {int(labels[idx])}\")\n","                plt.axis('off')\n","\n","                # Máscara de ground truth (si está disponible)\n","                if has_masks and idx < len(masks) and masks[idx] is not None:\n","                    plt.subplot(1, len(indices) * n_cols, subplot_idx + 1)\n","                    mask = masks[idx]\n","                    if hasattr(mask, 'squeeze'):\n","                        mask = mask.squeeze()\n","                    elif isinstance(mask, np.ndarray) and mask.ndim > 2:\n","                        mask = np.squeeze(mask)\n","\n","                    plt.imshow(mask, cmap='gray')\n","                    plt.title(\"Ground Truth\")\n","                    plt.axis('off')\n","\n","                    # Predicción\n","                    plt.subplot(1, len(indices) * n_cols, subplot_idx + 2)\n","                else:\n","                    # Sin máscara, solo predicción\n","                    plt.subplot(1, len(indices) * n_cols, subplot_idx + 1)\n","\n","                # Mostrar predicción\n","                if predictions[idx] == 1:\n","                    plt.text(0.5, 0.5, \"ANOMALY\", ha='center', va='center',\n","                             fontsize=16, color='red', weight='bold',\n","                             transform=plt.gca().transAxes)\n","                else:\n","                    plt.text(0.5, 0.5, \"NORMAL\", ha='center', va='center',\n","                             fontsize=16, color='green', weight='bold',\n","                             transform=plt.gca().transAxes)\n","\n","                plt.title(f\"Prediction\\nThreshold: {threshold:.4f}\")\n","                plt.axis('off')\n","\n","            except Exception as e:\n","                print(f\"Error procesando imagen {idx} en categoría {category_name}: {e}\")\n","                continue\n","\n","        plt.suptitle(f\"{category_name.replace('_', ' ').title()}\", fontsize=16, y=0.98)\n","        plt.tight_layout()\n","\n","        # Guardar figura\n","        filename = os.path.join(examples_dir, f'{category_name}.png')\n","        try:\n","            plt.savefig(filename, dpi=150, bbox_inches='tight')\n","            print(f\"Guardado: {filename}\")\n","        except Exception as e:\n","            print(f\"Error guardando {filename}: {e}\")\n","        finally:\n","            plt.close()  # Cerrar figura para liberar memoria\n","\n","    # Matriz de confusión\n","    try:\n","        from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","        cm = confusion_matrix(labels, predictions)\n","        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Anomalía'])\n","\n","        plt.figure(figsize=(8, 6))\n","        disp.plot(cmap='Blues')\n","        plt.title('Matriz de Confusión')\n","\n","        cm_filename = os.path.join(output_dir, 'confusion_matrix.png')\n","        plt.savefig(cm_filename, dpi=150, bbox_inches='tight')\n","        print(f\"Matriz de confusión guardada: {cm_filename}\")\n","        plt.close()\n","\n","    except Exception as e:\n","        print(f\"Error creando matriz de confusión: {e}\")\n","\n","    print(f\"Visualizaciones completadas en: {examples_dir}\")\n","\n","\n","# Función auxiliar para verificar y crear directorios\n","def ensure_directory_exists(path):\n","    \"\"\"Asegura que un directorio existe, lo crea si no existe\"\"\"\n","    try:\n","        os.makedirs(path, exist_ok=True)\n","        print(f\"Directorio verificado/creado: {path}\")\n","        return True\n","    except Exception as e:\n","        print(f\"Error creando directorio {path}: {e}\")\n","        return False\n"]},{"cell_type":"code","execution_count":10,"id":"6a05e9b0","metadata":{"id":"6a05e9b0","executionInfo":{"status":"ok","timestamp":1748725029622,"user_tz":180,"elapsed":34,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["def visualize_anomaly_maps(model, test_loader, device, output_dir, threshold, model_type):\n","    \"\"\"Genera y guarda mapas de anomalías para imágenes de test\"\"\"\n","    os.makedirs(os.path.join(output_dir, 'anomaly_maps'), exist_ok=True)\n","    model.eval()\n","\n","    # Seleccionar algunas imágenes para visualización\n","    samples_seen = {'normal': 0, 'anomaly': 0}\n","    max_samples = 5\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            # Manejar batch con o sin máscara\n","            if len(batch) == 3:\n","                images, labels, masks = batch\n","                has_masks = True\n","            else:\n","                images, labels = batch\n","                masks = None\n","                has_masks = False\n","\n","            images = images.to(device)\n","            batch_size = images.size(0)\n","\n","            # Modelo autoencoder\n","            if model_type == 'autoencoder':\n","                reconstructed, _ = model(images)\n","                # Calcular error de reconstrucción por píxel\n","                error_maps = torch.abs(images - reconstructed)\n","                # Normalizar mapas de error para visualización\n","                error_maps_mean = error_maps.mean(dim=1)  # Promediar a través de los canales\n","\n","                # Convertir a numpy para visualización\n","                images_np = images.cpu().numpy()\n","                error_maps_np = error_maps_mean.cpu().numpy()\n","                reconstructed_np = reconstructed.cpu().numpy()\n","\n","                for i in range(batch_size):\n","                    label = labels[i].item()\n","                    category = 'normal' if label == 0 else 'anomaly'\n","\n","                    if samples_seen[category] < max_samples:\n","                        # Determinar número de subplots\n","                        n_cols = 4 if has_masks else 3\n","                        fig, axes = plt.subplots(1, n_cols, figsize=(5 * n_cols, 5))\n","\n","                        # Imagen original\n","                        img = images_np[i].transpose(1, 2, 0)\n","                        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n","                        img = np.clip(img, 0, 1)\n","                        axes[0].imshow(img)\n","                        axes[0].set_title(\"Original\")\n","                        axes[0].axis('off')\n","\n","                        # Imagen reconstruida\n","                        rec_img = reconstructed_np[i].transpose(1, 2, 0)\n","                        rec_img = rec_img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n","                        rec_img = np.clip(rec_img, 0, 1)\n","                        axes[1].imshow(rec_img)\n","                        axes[1].set_title(\"Reconstrucción\")\n","                        axes[1].axis('off')\n","\n","                        # Mapa de error\n","                        error_map = error_maps_np[i]\n","                        vmax = np.max(error_map) if np.max(error_map) > 0 else 1\n","                        im = axes[2].imshow(error_map, cmap='jet', vmin=0, vmax=vmax)\n","                        axes[2].set_title(f\"Mapa de Anomalía\\n(Score: {error_maps_mean[i].mean().item():.4f})\")\n","                        axes[2].axis('off')\n","\n","                        # Máscara de ground truth (si está disponible)\n","                        if has_masks and masks is not None:\n","                            mask_np = masks[i].squeeze().cpu().numpy()\n","                            axes[3].imshow(mask_np, cmap='gray')\n","                            axes[3].set_title(\"Ground Truth Mask\")\n","                            axes[3].axis('off')\n","\n","                        plt.colorbar(im, ax=axes[2])\n","                        plt.tight_layout()\n","                        plt.savefig(os.path.join(output_dir, 'anomaly_maps', f'{category}_{samples_seen[category]}.png'))\n","                        plt.close()\n","\n","                        samples_seen[category] += 1\n","\n","            # Modelo supervisado (como no genera mapas de error, guardamos las imágenes)\n","            elif model_type == 'supervisado':  # Cambiado de 'supervised' a 'supervisado'\n","                scores = model(images).cpu().numpy().flatten()\n","                images_np = images.cpu().numpy()\n","\n","                for i in range(batch_size):\n","                    label = labels[i].item()\n","                    category = 'normal' if label == 0 else 'anomaly'\n","\n","                    if samples_seen[category] < max_samples:\n","                        # Determinar número de subplots\n","                        n_cols = 2 if not has_masks else 3\n","                        fig, axes = plt.subplots(1, n_cols, figsize=(5 * n_cols, 5))\n","\n","                        # Imagen original\n","                        img = images_np[i].transpose(1, 2, 0)\n","                        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n","                        img = np.clip(img, 0, 1)\n","                        axes[0].imshow(img)\n","                        axes[0].set_title(f\"Original\\nScore: {scores[i]:.4f}\")\n","                        axes[0].axis('off')\n","\n","                        # Etiqueta de predicción\n","                        predicted = \"ANOMALY\" if scores[i] >= threshold else \"NORMAL\"\n","                        color = \"red\" if predicted == \"ANOMALY\" else \"green\"\n","                        axes[1].text(0.5, 0.5, predicted, ha='center', va='center',\n","                                    fontsize=20, color=color)\n","                        axes[1].set_title(f\"Prediction\\nScore: {scores[i]:.4f}\")\n","                        axes[1].axis('off')\n","\n","                        # Máscara de ground truth (si está disponible)\n","                        if has_masks and masks is not None:\n","                            mask_np = masks[i].squeeze().cpu().numpy()\n","                            axes[2].imshow(mask_np, cmap='gray')\n","                            axes[2].set_title(\"Ground Truth Mask\")\n","                            axes[2].axis('off')\n","\n","                        plt.tight_layout()\n","                        plt.savefig(os.path.join(output_dir, 'anomaly_maps', f'{category}_{samples_seen[category]}.png'))\n","                        plt.close()\n","\n","                        samples_seen[category] += 1\n","\n","            if all(count >= max_samples for count in samples_seen.values()):\n","                break\n"]},{"cell_type":"markdown","id":"7feb2801","metadata":{"id":"7feb2801"},"source":["### Funciones de Evaluación"]},{"cell_type":"code","execution_count":11,"id":"2da594df","metadata":{"id":"2da594df","executionInfo":{"status":"ok","timestamp":1748725037117,"user_tz":180,"elapsed":27,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["def evaluar_modelo(model, final_test_loader, device, output_dir, model_type='autoencoder'):\n","    \"\"\"\n","    Evaluación final del modelo en el conjunto de test independiente - versión mejorada\n","    \"\"\"\n","    # Asegurar que el directorio de salida existe\n","    ensure_directory_exists(output_dir)\n","\n","    model.eval()\n","    all_scores = []\n","    all_labels = []\n","    all_images = []\n","    all_masks = []\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"REALIZANDO EVALUACIÓN FINAL...\")\n","    print(\"=\"*50)\n","\n","    with torch.no_grad():\n","        for images, labels, masks in tqdm(final_test_loader, desc=\"Evaluación final\"):\n","            images = images.to(device)\n","\n","            if model_type == 'autoencoder':\n","                # Para autoencoder: calcular error de reconstrucción\n","                reconstructed, _ = model(images)\n","                error = torch.mean((images - reconstructed) ** 2, dim=[1, 2, 3])\n","                scores = error.cpu().numpy()\n","            else:\n","                # Para modelo supervisado\n","                outputs = model(images)\n","                scores = outputs.cpu().numpy().flatten()\n","\n","            all_scores.extend(scores)\n","            all_labels.extend(labels.numpy())\n","            all_images.extend(images.cpu().numpy())\n","            all_masks.extend(masks.cpu().numpy() if hasattr(masks, 'cpu') else masks)\n","\n","    # Resto de la función de evaluación...\n","    from sklearn.metrics import roc_curve, auc, average_precision_score, precision_recall_fscore_support, precision_recall_curve\n","\n","    # Calcular métricas finales\n","    fpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n","    avg_precision = average_precision_score(all_labels, all_scores)\n","    roc_auc = auc(fpr, tpr)\n","\n","    # Encontrar mejor threshold\n","    optimal_idx = np.argmax(tpr - fpr)\n","    optimal_threshold = thresholds[optimal_idx]\n","\n","    # Calcular accuracy con threshold óptimo\n","    predictions = (np.array(all_scores) > optimal_threshold).astype(int)\n","    accuracy = np.mean(predictions == all_labels)\n","\n","    # Calcular precision, recall, F1\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        all_labels, predictions, average='binary'\n","    )\n","\n","    precision_curve, recall_curve, _ = precision_recall_curve(all_labels, all_scores)\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\" RESULTADOS FINALES DEL MODELO\")\n","    print(\"=\"*50)\n","    print(f\"ROC AUC:     {roc_auc:.4f}\")\n","    print(f\"Accuracy:    {accuracy:.4f}\")\n","    print(f\"Precision:   {precision:.4f}\")\n","    print(f\"Recall:      {recall:.4f}\")\n","    print(f\"F1-Score:    {f1:.4f}\")\n","    print(f\"Threshold:   {optimal_threshold:.6f}\")\n","    print(\"=\"*50)\n","\n","    # Visualizar curvas\n","    plt.figure(figsize=(12, 5))\n","\n","    # ROC Curve\n","    plt.subplot(1, 2, 1)\n","    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n","    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic')\n","    plt.legend(loc=\"lower right\")\n","\n","    # Precision-Recall Curve\n","    plt.subplot(1, 2, 2)\n","    plt.plot(recall_curve, precision_curve, color='blue', lw=2, label=f'PR curve (AP = {avg_precision:.3f})')\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Precision-Recall Curve')\n","    plt.legend(loc=\"upper right\")\n","\n","    plt.tight_layout()\n","    curves_filename = os.path.join(output_dir, 'curvas_de_evaluacion.png')\n","    plt.savefig(curves_filename, dpi=150, bbox_inches='tight')\n","    plt.close()\n","\n","    print(f'Curvas de evaluación guardadas en: {curves_filename}')\n","    print(f'Directorio de salida: {output_dir}')\n","\n","    # Visualizar algunos ejemplos de predicciones\n","    visualize_examples(all_images, all_labels, all_scores, all_masks, optimal_threshold, output_dir, model_type)\n","\n","    return {\n","        'roc_auc': float(roc_auc),\n","        'accuracy': float(accuracy),\n","        'precision': float(precision),\n","        'recall': float(recall),\n","        'f1': float(f1),\n","        'threshold': float(optimal_threshold),\n","        'scores': all_scores,\n","        'labels': all_labels\n","    }"]},{"cell_type":"markdown","id":"d237edd4","metadata":{"id":"d237edd4"},"source":["### Cuerpo principal"]},{"cell_type":"code","execution_count":18,"id":"ce226cbb","metadata":{"id":"ce226cbb","executionInfo":{"status":"ok","timestamp":1748725223141,"user_tz":180,"elapsed":12,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["# Variables de configuración\n","#data_path = 'data/'  # Ruta al dataset MVTec AD\n","data_path = '/content/drive/MyDrive/VpCIII/data'\n","#output_dir = 'models/'  # Ruta para guardar el modelo entrenado\n","output_dir = '/content/models'\n","reports_path = 'reports/'  # Ruta para guardar los reportes e imágenes\n","\n","# Lista de todas las categorías en MVTec AD\n","categories = [\n","    \"bottle\",\n","    \"cable\",\n","    \"capsule\",\n","    \"carpet\",\n","    \"grid\",\n","    \"hazelnut\",\n","    \"leather\",\n","    \"metal_nut\",\n","    \"pill\",\n","    \"screw\",\n","    \"tile\",\n","    \"toothbrush\",\n","    \"transistor\",\n","    \"wood\",\n","    \"zipper\",\n","]"]},{"cell_type":"code","execution_count":19,"id":"82f5b0ef","metadata":{"id":"82f5b0ef","executionInfo":{"status":"ok","timestamp":1748725226549,"user_tz":180,"elapsed":5,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["# Crear directorios de salida en caso de que no existan\n","os.makedirs(output_dir, exist_ok=True)\n","os.makedirs(reports_path, exist_ok=True)"]},{"cell_type":"code","execution_count":20,"id":"7f3276bb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7f3276bb","executionInfo":{"status":"ok","timestamp":1748725228098,"user_tz":180,"elapsed":20,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}},"outputId":"14588409-1466-47c4-c386-b9a5dacf46dc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7e1eaaf8ab10>"]},"metadata":{},"execution_count":20}],"source":["# Semilla para reproducibilidad de los experimentos\n","random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)"]},{"cell_type":"code","execution_count":21,"id":"4cb162b3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cb162b3","executionInfo":{"status":"ok","timestamp":1748725230995,"user_tz":180,"elapsed":17,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}},"outputId":"3246964b-b9f0-4097-a292-912bb4482599"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Usando dispositivo: cuda\n"]}],"source":["# Si tenemos disponible GPU, lo usamos\n","# Chequeamos si tenemos disponible GPU (CUDA)\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","# Chequeamos si tenemos disponible aceleración por hardware en un chip de Apple (MPS)\n","elif torch.backends.mps.is_available():\n","    device = \"mps\"\n","# Por defecto usamos CPU\n","else:\n","    device = \"cpu\"\n","\n","print(f\" Usando dispositivo: {device}\")"]},{"cell_type":"code","execution_count":22,"id":"573cf6d4","metadata":{"id":"573cf6d4","executionInfo":{"status":"ok","timestamp":1748725233354,"user_tz":180,"elapsed":12,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["# Definir transformaciones\n","train_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# Transformación para máscaras (sin normalización)\n","mask_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"code","execution_count":23,"id":"6323f8d3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6323f8d3","executionInfo":{"status":"ok","timestamp":1748725265926,"user_tz":180,"elapsed":29868,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}},"outputId":"427ecf15-947d-427b-f6f2-f3ad1cb76a2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","CARGANDO DATASETS MVTec AD\n","============================================================\n","bottle       | Train: 209 | Test:  83\n","cable        | Train: 224 | Test: 150\n","capsule      | Train: 219 | Test: 132\n","carpet       | Train: 280 | Test: 117\n","grid         | Train: 264 | Test:  78\n","hazelnut     | Train: 391 | Test: 110\n","leather      | Train: 245 | Test: 124\n","metal_nut    | Train: 220 | Test: 115\n","pill         | Train: 267 | Test: 167\n","screw        | Train: 320 | Test: 160\n","tile         | Train: 230 | Test: 117\n","toothbrush   | Train:  60 | Test:  42\n","transistor   | Train: 213 | Test: 100\n","wood         | Train: 247 | Test:  79\n","zipper       | Train: 240 | Test: 151\n"]}],"source":["# Crear Datasets\n","print(\"\\n\" + \"=\"*60)\n","print(\"CARGANDO DATASETS MVTec AD\")\n","print(\"=\"*60)\n","\n","# Crear datasets para todas las categorías\n","train_datasets = []\n","test_datasets = []\n","\n","for category in categories:\n","    try:\n","        train_dataset = MVTecDataset(\n","            root_path=data_path,\n","            category=category,\n","            is_train=True,\n","            transform=train_transform,\n","            mask_transform=mask_transform\n","        )\n","\n","        test_dataset = MVTecDataset(\n","            root_path=data_path,\n","            category=category,\n","            is_train=False,\n","            transform=test_transform,\n","            mask_transform=mask_transform\n","        )\n","\n","        train_datasets.append(train_dataset)\n","        test_datasets.append(test_dataset)\n","        print(f\"{category:12} | Train: {len(train_dataset):3} | Test: {len(test_dataset):3}\")\n","    except Exception as e:\n","        print(f\" Error al cargar la categoría {category}: {e}\")"]},{"cell_type":"code","execution_count":24,"id":"78014831","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78014831","executionInfo":{"status":"ok","timestamp":1748725296742,"user_tz":180,"elapsed":50,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}},"outputId":"a6e2cf0a-d8a2-4db8-8cfe-8f70ab7d4f68"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","DIVISIÓN DE DATASETS DE TEST\n","============================================================\n","bottle       | Total:  83 | Normal:  20 | Anomalía:  63 | Val:  41 | Test:  42\n","cable        | Total: 150 | Normal:  58 | Anomalía:  92 | Val:  75 | Test:  75\n","capsule      | Total: 132 | Normal:  23 | Anomalía: 109 | Val:  66 | Test:  66\n","carpet       | Total: 117 | Normal:  28 | Anomalía:  89 | Val:  58 | Test:  59\n","grid         | Total:  78 | Normal:  21 | Anomalía:  57 | Val:  39 | Test:  39\n","hazelnut     | Total: 110 | Normal:  40 | Anomalía:  70 | Val:  55 | Test:  55\n","leather      | Total: 124 | Normal:  32 | Anomalía:  92 | Val:  62 | Test:  62\n","metal_nut    | Total: 115 | Normal:  22 | Anomalía:  93 | Val:  57 | Test:  58\n","pill         | Total: 167 | Normal:  26 | Anomalía: 141 | Val:  83 | Test:  84\n","screw        | Total: 160 | Normal:  41 | Anomalía: 119 | Val:  80 | Test:  80\n","tile         | Total: 117 | Normal:  33 | Anomalía:  84 | Val:  58 | Test:  59\n","toothbrush   | Total:  42 | Normal:  12 | Anomalía:  30 | Val:  21 | Test:  21\n","transistor   | Total: 100 | Normal:  60 | Anomalía:  40 | Val:  50 | Test:  50\n","wood         | Total:  79 | Normal:  19 | Anomalía:  60 | Val:  39 | Test:  40\n","zipper       | Total: 151 | Normal:  32 | Anomalía: 119 | Val:  75 | Test:  76\n","============================================================\n","\n"," RESUMEN DE DATASETS:\n","   Entrenamiento: 3629 imágenes\n","   Validación:     859 imágenes\n","   Test final:     866 imágenes\n","   Total:         5354 imágenes\n"]}],"source":["# Dividir datasets de test en validación y test final\n","val_datasets, final_test_datasets = split_test_datasets(test_datasets, categories, test_size=0.5)\n","\n","# Combinar datasets\n","train_dataset = ConcatDataset(train_datasets)  # Unir todos los datasets de entrenamiento\n","val_dataset = ConcatDataset(val_datasets)      # Unir todos los datasets de validación\n","final_test_dataset = ConcatDataset(final_test_datasets)  # Unir todos los datasets de test final\n","\n","print(f\"\\n RESUMEN DE DATASETS:\")\n","print(f\"   Entrenamiento: {len(train_dataset):4} imágenes\")\n","print(f\"   Validación:    {len(val_dataset):4} imágenes\")\n","print(f\"   Test final:    {len(final_test_dataset):4} imágenes\")\n","print(f\"   Total:         {len(train_dataset) + len(val_dataset) + len(final_test_dataset):4} imágenes\")\n"]},{"cell_type":"code","execution_count":25,"id":"f07cda72","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f07cda72","executionInfo":{"status":"ok","timestamp":1748725303091,"user_tz":180,"elapsed":23,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}},"outputId":"2362537a-28ea-4167-b296-7add3512d073"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," DataLoaders creados con batch_size=8\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]}],"source":["# Defino el tamaño de los lotes\n","batch_size = 8 # Tamaño de los lotes, mas grande muere\n","\n","# Crear dataloaders\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=4\n",")\n","\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    num_workers=4\n",")\n","\n","final_test_loader = DataLoader(\n","    final_test_dataset,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    num_workers=4\n",")\n","\n","print(f\"\\n DataLoaders creados con batch_size={batch_size}\")"]},{"cell_type":"code","execution_count":26,"id":"8e77422d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8e77422d","executionInfo":{"status":"ok","timestamp":1748725307562,"user_tz":180,"elapsed":18,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}},"outputId":"5f823c52-e6f7-408c-92d6-256cf92a2ae3"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," CONFIGURACIÓN DEL MODELO:\n","   Tipo:          autoencoder\n","   Pre-entrenado: True\n","   Learning rate: 0.0001\n","   Épocas:        1\n","   Categorías:    TODAS (15 categorías combinadas)\n","   Estrategia:    Multi-categoría para generalización\n"]}],"source":["# Para nuestro enfoque model_type pueden ser dos: 'supervisado' o 'autoencoder'\n","model_type = 'autoencoder' # Habria que entrenar los dos\n","#model_type = 'supervisado'\n","\n","pretrained = True # Usar pre-entrenado\n","lr = 1e-4\n","num_epochs = 1\n","\n","print(f\"\\n CONFIGURACIÓN DEL MODELO:\")\n","print(f\"   Tipo:          {model_type}\")\n","print(f\"   Pre-entrenado: {pretrained}\")\n","print(f\"   Learning rate: {lr}\")\n","print(f\"   Épocas:        {num_epochs}\")\n","print(f\"   Categorías:    TODAS ({len(categories)} categorías combinadas)\")\n","print(f\"   Estrategia:    Multi-categoría para generalización\")"]},{"cell_type":"code","execution_count":27,"id":"f7626f0f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":153,"referenced_widgets":["89883787a46342f3934ca4adbfadf10d","6e480d9f488c46bf967809a530235fa9","f990d011635249318d3b03195d771161","538577a90c904b5dbacd9e16a78cb766","386a9447d64a4066ba4e442670c93fa9","6ce79e0c989044009ba6b65f3dc5da31","ab35c391bb0348c3bc16b30969a46a6b","07cb59f8f43146019e6bf1ce5be8439c","758df5da7d124e9bbd8ed87ad89a858e","63cee4db58454733b5494aa150fce913","7f5695d425054f7ba6f12536ade00569"]},"id":"f7626f0f","executionInfo":{"status":"ok","timestamp":1748725317039,"user_tz":180,"elapsed":5078,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}},"outputId":"7599f093-015d-476c-aa7f-2ad0a6967b7a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89883787a46342f3934ca4adbfadf10d"}},"metadata":{}}],"source":["# Creamos el modelo\n","if model_type == 'supervisado':\n","    model = SwinTransformerAnomalyDetector(pretrained=pretrained).to(device)\n","    criterion = nn.BCELoss()\n","else:  # autoencoder\n","    model = SwinTransformerAutoencoder(pretrained=pretrained).to(device)\n","    criterion = nn.MSELoss()"]},{"cell_type":"code","execution_count":28,"id":"2af6a1ad","metadata":{"id":"2af6a1ad","executionInfo":{"status":"ok","timestamp":1748725320952,"user_tz":180,"elapsed":4,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["# Optimizador y scheduler\n","optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5) # AdamW es una variante de Adam con decaimiento de peso\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n","# Scheduler para reducir la tasa de aprendizaje CosineAnnealingLR sirve para reducir la tasa de aprendizaje de forma cíclica"]},{"cell_type":"code","execution_count":29,"id":"63891bc6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63891bc6","executionInfo":{"status":"ok","timestamp":1748725775902,"user_tz":180,"elapsed":452122,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}},"outputId":"774f04c8-ddad-4b60-e6a0-8958ea7ca0ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," INICIANDO ENTRENAMIENTO DEL MODELO AUTOENCODER...\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/1 (train): 100%|██████████| 454/454 [05:24<00:00,  1.40it/s]\n","Epoch 1/1 (val): 100%|██████████| 108/108 [02:02<00:00,  1.14s/it]\n"]},{"output_type":"stream","name":"stdout","text":["     Nuevo mejor modelo guardado! AUC: 0.5582\n","Epoch 1/1, Train Loss: 1.0191, Val Loss: 0.8213, ROC AUC: 0.5582\n","\n"," Entrenamiento finalizado!\n"]}],"source":["# Entrenamos el modelo\n","print(f\"\\n INICIANDO ENTRENAMIENTO DEL MODELO {model_type.upper()}...\")\n","print(\"=\"*60)\n","\n","if model_type == 'supervisado':\n","    model = train_supervised_model(\n","        model=model,\n","        train_loader=train_loader,\n","        val_loader=val_loader,  #  Usando val_loader en lugar de test_loader\n","        criterion=criterion,\n","        optimizer=optimizer,\n","        scheduler=scheduler,\n","        num_epochs=num_epochs,\n","        device=device,\n","        output_dir=output_dir\n","    )\n","else:\n","    model = train_autoencoder_model(\n","        model=model,\n","        train_loader=train_loader,\n","        val_loader=val_loader,  #  Usando val_loader en lugar de test_loader\n","        criterion=criterion,\n","        optimizer=optimizer,\n","        scheduler=scheduler,\n","        num_epochs=num_epochs,\n","        device=device,\n","        output_dir=output_dir\n","    )\n","\n","print(\"\\n Entrenamiento finalizado!\")"]},{"cell_type":"code","execution_count":30,"id":"33e4c91b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":783},"id":"33e4c91b","executionInfo":{"status":"ok","timestamp":1748725939418,"user_tz":180,"elapsed":131910,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}},"outputId":"eec80fcf-834b-4c4d-8f3c-152a30b0a5d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," CARGANDO MEJOR MODELO PARA EVALUACIÓN FINAL...\n","Directorio verificado/creado: reports/\n","\n","==================================================\n","REALIZANDO EVALUACIÓN FINAL...\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluación final:   0%|          | 0/109 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Evaluación final: 100%|██████████| 109/109 [02:02<00:00,  1.12s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","==================================================\n"," RESULTADOS FINALES DEL MODELO\n","==================================================\n","ROC AUC:     0.5645\n","Accuracy:    0.6859\n","Precision:   0.7625\n","Recall:      0.8254\n","F1-Score:    0.7927\n","Threshold:   0.376019\n","==================================================\n","Curvas de evaluación guardadas en: reports/curvas_de_evaluacion.png\n","Directorio de salida: reports/\n","Creando visualizaciones en: reports/examples\n","Total de imágenes: 866\n","Distribución de etiquetas - Normal: 236, Anomalía: 630\n","Distribución de predicciones - Normal: 183, Anomalía: 683\n","True Positives: 521\n","True Negatives: 74\n","False Positives: 162\n","False Negatives: 109\n","Máscaras disponibles: True\n","Creando visualización para true_positive con 5 ejemplos\n","Guardado: reports/examples/true_positive.png\n","Creando visualización para true_negative con 5 ejemplos\n","Guardado: reports/examples/true_negative.png\n","Creando visualización para false_positive con 5 ejemplos\n","Guardado: reports/examples/false_positive.png\n","Creando visualización para false_negative con 5 ejemplos\n","Guardado: reports/examples/false_negative.png\n","Matriz de confusión guardada: reports/confusion_matrix.png\n","Visualizaciones completadas en: reports/examples\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 800x600 with 0 Axes>"]},"metadata":{}}],"source":["# Evaluación Final con el conjunto de test independiente\n","print(f\"\\n CARGANDO MEJOR MODELO PARA EVALUACIÓN FINAL...\")\n","if model_type == 'supervisado':\n","    model.load_state_dict(torch.load(os.path.join(output_dir, 'mejor_modelo_supervisado.pth')))\n","else:\n","    # Cargar el mejor modelo autoencoder\n","    model.load_state_dict(torch.load(os.path.join(output_dir, 'mejor_modelo_multiclase_autoencoder.pth')))\n","\n","\n","# Evaluación final\n","final_results = evaluar_modelo(model, final_test_loader, device, reports_path, model_type='autoencoder', )\n"]},{"cell_type":"code","execution_count":31,"id":"fa330f93","metadata":{"id":"fa330f93","executionInfo":{"status":"ok","timestamp":1748725946959,"user_tz":180,"elapsed":11,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}}},"outputs":[],"source":["#print(final_results)\n","threshold = final_results['threshold']"]},{"cell_type":"code","execution_count":32,"id":"7633a801","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7633a801","executionInfo":{"status":"ok","timestamp":1748725950234,"user_tz":180,"elapsed":13,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}},"outputId":"aa830444-bbe4-4654-d1cb-f787e68bb52b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Resultados guardados en: reports/resultados_finales.json\n","\n"," ¡PROCESO COMPLETADO EXITOSAMENTE!\n"]}],"source":["# Guardar resultados finales\n","def convert_numpy_types(obj):\n","    \"\"\"Convierte tipos numpy a tipos nativos de Python para JSON\"\"\"\n","    if isinstance(obj, dict):\n","        return {key: convert_numpy_types(value) for key, value in obj.items()}\n","    elif isinstance(obj, list):\n","        return [convert_numpy_types(item) for item in obj]\n","    elif isinstance(obj, np.integer):\n","        return int(obj)\n","    elif isinstance(obj, np.floating):\n","        return float(obj)\n","    elif isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    else:\n","        return obj\n","\n","results_to_save = {k: v for k, v in final_results.items() if k not in ['scores', 'labels']}\n","results_to_save = convert_numpy_types(results_to_save)  # Convertir tipos numpy\n","results_file = os.path.join(reports_path, 'resultados_finales.json')\n","\n","with open(results_file, 'w') as f:\n","    json.dump(results_to_save, f, indent=2)\n","\n","print(f\"\\n Resultados guardados en: {results_file}\")\n","print(\"\\n ¡PROCESO COMPLETADO EXITOSAMENTE!\")"]},{"cell_type":"code","execution_count":33,"id":"58828f03","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58828f03","executionInfo":{"status":"ok","timestamp":1748725965371,"user_tz":180,"elapsed":10235,"user":{"displayName":"Quantum Technology Company SAS","userId":"00588190999422934580"}},"outputId":"7760cba2-82d7-4bca-d612-4603b1238c46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generando mapas de anomalías...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]}],"source":["# Visualizar mapas de anomalías\n","print(\"Generando mapas de anomalías...\")\n","visualize_anomaly_maps(\n","    model=model,\n","    test_loader=final_test_loader,\n","    device=device,\n","    output_dir=reports_path,\n","    threshold=threshold,\n","    model_type=model_type\n",")"]}],"metadata":{"kernelspec":{"display_name":"Python (VpCIII)","language":"python","name":"vpciii"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"89883787a46342f3934ca4adbfadf10d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e480d9f488c46bf967809a530235fa9","IPY_MODEL_f990d011635249318d3b03195d771161","IPY_MODEL_538577a90c904b5dbacd9e16a78cb766"],"layout":"IPY_MODEL_386a9447d64a4066ba4e442670c93fa9"}},"6e480d9f488c46bf967809a530235fa9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ce79e0c989044009ba6b65f3dc5da31","placeholder":"​","style":"IPY_MODEL_ab35c391bb0348c3bc16b30969a46a6b","value":"model.safetensors: 100%"}},"f990d011635249318d3b03195d771161":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07cb59f8f43146019e6bf1ce5be8439c","max":114286722,"min":0,"orientation":"horizontal","style":"IPY_MODEL_758df5da7d124e9bbd8ed87ad89a858e","value":114286722}},"538577a90c904b5dbacd9e16a78cb766":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63cee4db58454733b5494aa150fce913","placeholder":"​","style":"IPY_MODEL_7f5695d425054f7ba6f12536ade00569","value":" 114M/114M [00:00&lt;00:00, 149MB/s]"}},"386a9447d64a4066ba4e442670c93fa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ce79e0c989044009ba6b65f3dc5da31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab35c391bb0348c3bc16b30969a46a6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07cb59f8f43146019e6bf1ce5be8439c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"758df5da7d124e9bbd8ed87ad89a858e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63cee4db58454733b5494aa150fce913":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f5695d425054f7ba6f12536ade00569":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}