{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8fd880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import WeightedRandomSampler, Subset\n",
    "\n",
    "from pytorch_msssim import ssim  # pip install pytorch-msssim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    precision_recall_fscore_support,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from timm.models import create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54461da9",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9fc919",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformerAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    SwinTransformerAutoencoder\n",
    "    Autoencoder basado en un codificador Swin Transformer preentrenado y un decodificador convolucional.\n",
    "    Permite la reconstrucción de imágenes y la detección de anomalías mediante el error de reconstrucción.\n",
    "    Args:\n",
    "        pretrained (bool): Si True, utiliza pesos preentrenados para el Swin Transformer.\n",
    "    Attributes:\n",
    "        encoder (nn.Module): Codificador basado en Swin Transformer.\n",
    "        decoder (nn.Module): Decodificador convolucional para reconstrucción de imágenes.\n",
    "        scoring_criterion (callable or None): Función de pérdida utilizada para el scoring consistente.\n",
    "    Methods:\n",
    "        set_scoring_criterion(criterion):\n",
    "            Establece la función de pérdida para el scoring consistente durante la detección de anomalías.\n",
    "        forward(x):\n",
    "            Realiza la pasada hacia adelante del autoencoder.\n",
    "            Args:\n",
    "                x (Tensor): Imagen de entrada de tamaño [batch_size, C, H, W].\n",
    "            Returns:\n",
    "                Tuple[Tensor, Tensor]: Imagen reconstruida y representación latente.\n",
    "        detectar_anomalia(x):\n",
    "            Calcula el error de reconstrucción (MSE) entre la imagen original y la reconstruida para detección de anomalías.\n",
    "            Args:\n",
    "                x (Tensor): Imagen de entrada.\n",
    "            Returns:\n",
    "                Tensor: Error de reconstrucción por muestra.\n",
    "        detectar_anomalia_consistente(x):\n",
    "            Calcula el error de reconstrucción usando la función de pérdida definida (scoring_criterion).\n",
    "            Si no se ha definido, utiliza MSE por defecto.\n",
    "            Args:\n",
    "                x (Tensor): Imagen de entrada.\n",
    "            Returns:\n",
    "                Tensor: Error de reconstrucción consistente por muestra.\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(SwinTransformerAutoencoder, self).__init__()\n",
    "\n",
    "        # Codificador: Swin transformer preentrenado\n",
    "        self.encoder = create_model(\n",
    "            'swin_tiny_patch4_window7_224',\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0\n",
    "        )\n",
    "\n",
    "        # Decodificador\n",
    "        self.decoder = DecodificadorConvolucional()\n",
    "        \n",
    "        # AGREGAR: Función de scoring para detección consistente\n",
    "        self.scoring_criterion = None\n",
    "\n",
    "    # Método para establecer el criterio de scoring\n",
    "    def set_scoring_criterion(self, criterion):\n",
    "        \"\"\"\n",
    "        Establece el criterio de evaluación (scoring) para el modelo.\n",
    "\n",
    "        Parámetros:\n",
    "            criterion (callable): Función que recibe las predicciones y los valores reales, y devuelve una métrica de evaluación.\n",
    "\n",
    "        Ejemplo:\n",
    "            >>> model.set_scoring_criterion(mean_squared_error)\n",
    "        \"\"\"\n",
    "\n",
    "        self.scoring_criterion = criterion\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Obtener representación latente\n",
    "        latente = self.encoder(x)  # [batch_size, 768]\n",
    "\n",
    "        # Reconstruir la imagen\n",
    "        reconstruida = self.decoder(latente)\n",
    "        return reconstruida, latente\n",
    "    \n",
    "    # Metodo para detectar anomalías\n",
    "    # Usar MSE como error de reconstrucción\n",
    "    def detectar_anomalia(self, x):\n",
    "        \"\"\"\n",
    "        Detecta anomalías calculando el error de reconstrucción entre la entrada y su reconstrucción.\n",
    "\n",
    "        Parámetros:\n",
    "            x (torch.Tensor): Tensor de entrada con dimensiones (batch_size, canales, alto, ancho).\n",
    "\n",
    "        Devuelve:\n",
    "            torch.Tensor: Error de reconstrucción (MSE) para cada elemento del batch.\n",
    "        \"\"\"\n",
    "\n",
    "        reconstruida, _ = self.forward(x)\n",
    "\n",
    "        # Calcular error de reconstrucción como MSE\n",
    "        error_reconstruccion = torch.mean((x - reconstruida) ** 2, dim=[1, 2, 3])\n",
    "        return error_reconstruccion\n",
    "    \n",
    "    # Método para scoring consistente\n",
    "    def detectar_anomalia_consistente(self, x):\n",
    "        \"\"\"\n",
    "        Detecta anomalías utilizando el mismo criterio de puntuación (función de pérdida) empleado durante el entrenamiento.\n",
    "        Parámetros:\n",
    "            x (torch.Tensor): Entrada a evaluar para detectar anomalías.\n",
    "        Devuelve:\n",
    "            torch.Tensor: Puntuación de error combinada que indica el grado de anomalía de la entrada.\n",
    "        Notas:\n",
    "            - Si no se ha definido un criterio de puntuación (`scoring_criterion`), utiliza el método alternativo `detectar_anomalia` basado en MSE.\n",
    "            - La puntuación devuelta es consistente con la función de pérdida usada en el entrenamiento del modelo.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.scoring_criterion is None:\n",
    "            # Fallback al MSE si no hay criterio definido\n",
    "            return self.detectar_anomalia(x)\n",
    "            \n",
    "        reconstruida, _ = self.forward(x)\n",
    "        \n",
    "        # Usar la función combinada para scoring (consistente con entrenamiento)\n",
    "        combined_error, _ = self.scoring_criterion(reconstruida, x)\n",
    "        return combined_error\n",
    "\n",
    "\n",
    "class DecodificadorConvolucional(nn.Module):\n",
    "    \"\"\"\n",
    "    DecodificadorConvolucional es una red neuronal basada en PyTorch diseñada para decodificar un vector latente en una imagen RGB de tamaño 224x224. Utiliza una arquitectura de decodificación progresiva con bloques convolucionales y upsampling, seguida de un refinamiento final para mejorar la calidad de la imagen generada.\n",
    "    Parámetros:\n",
    "        dim_latente (int): Dimensión del vector latente de entrada. Por defecto es 768.\n",
    "    Atributos:\n",
    "        proyeccion_inicial (nn.Sequential): Proyección inicial del vector latente a un mapa de características 8x8.\n",
    "        decodificador_bloque1-4 (BloqueDecodificador): Bloques convolucionales para upsampling progresivo y reducción de canales.\n",
    "        upsample_final (nn.Upsample): Upsampling final para ajustar la salida a 224x224 píxeles.\n",
    "        refinamiento (nn.Sequential): Bloque de capas convolucionales y de normalización para refinar la imagen.\n",
    "        conv_final (nn.Sequential): Capa final para mapear a 3 canales RGB y aplicar activación sigmoide.\n",
    "    Métodos:\n",
    "        forward(x):\n",
    "            Realiza el paso hacia adelante de la red, decodificando el vector latente x en una imagen RGB de tamaño [batch_size, 3, 224, 224].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim_latente=768):\n",
    "        super(DecodificadorConvolucional, self).__init__()\n",
    "\n",
    "        # Proyección inicial mejorada con más capacidad\n",
    "        self.proyeccion_inicial = nn.Sequential(\n",
    "            nn.Linear(dim_latente, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512 * 8 * 8),  # Empezar en 8x8 en lugar de 7x7\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # Bloques decodificadores mejorados con más canales\n",
    "        # 8x8 -> 16x16\n",
    "        self.decodificador_bloque1 = BloqueDecodificador(512, 384, upsample=True)\n",
    "        \n",
    "        # 16x16 -> 32x32  \n",
    "        self.decodificador_bloque2 = BloqueDecodificador(384, 256, upsample=True)\n",
    "        \n",
    "        # 32x32 -> 64x64\n",
    "        self.decodificador_bloque3 = BloqueDecodificador(256, 128, upsample=True)\n",
    "        \n",
    "        # 64x64 -> 128x128\n",
    "        self.decodificador_bloque4 = BloqueDecodificador(128, 64, upsample=True)\n",
    "        \n",
    "        # 128x128 -> 224x224 (upsampling con interpolación)\n",
    "        self.upsample_final = nn.Upsample(size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Refinamiento final con múltiples capas\n",
    "        self.refinamiento = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Capa final para generar RGB\n",
    "        self.conv_final = nn.Sequential(\n",
    "            nn.Conv2d(8, 3, kernel_size=1),  # 1x1 conv para mapear a RGB\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Proyección inicial\n",
    "        x = self.proyeccion_inicial(x)  # [batch_size, 512*8*8]\n",
    "        x = x.view(x.size(0), 512, 8, 8)  # [batch_size, 512, 8, 8]\n",
    "\n",
    "        # Decodificación progresiva\n",
    "        x = self.decodificador_bloque1(x)  # [batch_size, 384, 16, 16]\n",
    "        x = self.decodificador_bloque2(x)  # [batch_size, 256, 32, 32] \n",
    "        x = self.decodificador_bloque3(x)  # [batch_size, 128, 64, 64]\n",
    "        x = self.decodificador_bloque4(x)  # [batch_size, 64, 128, 128]\n",
    "        \n",
    "        # Upsampling final a 224x224\n",
    "        x = self.upsample_final(x)  # [batch_size, 64, 224, 224]\n",
    "        \n",
    "        # Refinamiento\n",
    "        x = self.refinamiento(x)  # [batch_size, 8, 224, 224]\n",
    "        \n",
    "        # Generar imagen final\n",
    "        x = self.conv_final(x)  # [batch_size, 3, 224, 224]\n",
    "\n",
    "        return x\n",
    "\n",
    "class BloqueDecodificador(nn.Module):\n",
    "    \"\"\"\n",
    "    BloqueDecodificador implementa un bloque de decodificación para redes neuronales, típicamente usado en arquitecturas de segmentación o autoencoders.\n",
    "    Parámetros:\n",
    "        in_channels (int): Número de canales de entrada.\n",
    "        out_channels (int): Número de canales de salida.\n",
    "        upsample (bool, opcional): Si es True, aplica upsampling usando ConvTranspose2d. Si es False, usa una Conv2d 1x1. Por defecto es True.\n",
    "    Atributos:\n",
    "        upsample_layer (nn.Module): Capa utilizada para upsampling o ajuste de canales.\n",
    "        upsample_bn (nn.BatchNorm2d): Normalización por lotes después del upsampling.\n",
    "        conv_block (nn.Sequential): Bloque residual con dos capas convolucionales, batch normalization y activación ReLU.\n",
    "        relu (nn.ReLU): Función de activación ReLU.\n",
    "        attention (nn.Sequential): Mecanismo simple de atención de canales usando pooling global y convoluciones 1x1.\n",
    "        dropout (nn.Dropout2d): Capa de dropout para regularización.\n",
    "    Proceso en forward:\n",
    "        1. Aplica upsampling o ajuste de canales a la entrada.\n",
    "        2. Pasa el resultado por un bloque convolucional residual.\n",
    "        3. Aplica un mecanismo de atención de canales.\n",
    "        4. Suma la identidad upsampleada (conexión residual).\n",
    "        5. Aplica activación ReLU y dropout.\n",
    "        6. Devuelve el tensor procesado.\n",
    "    Retorna:\n",
    "        torch.Tensor: Tensor de salida tras decodificación, atención y regularización.\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, in_channels, out_channels, upsample=True):\n",
    "        super(BloqueDecodificador, self).__init__()\n",
    "\n",
    "        self.upsample = upsample\n",
    "\n",
    "        if upsample:\n",
    "            # Usar ConvTranspose2d más efectiva\n",
    "            self.upsample_layer = nn.ConvTranspose2d(\n",
    "                in_channels, out_channels, \n",
    "                kernel_size=4, stride=2, padding=1, bias=False\n",
    "            )\n",
    "            self.upsample_bn = nn.BatchNorm2d(out_channels)\n",
    "        else:\n",
    "            self.upsample_layer = nn.Conv2d(in_channels, out_channels, 1)\n",
    "            self.upsample_bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Bloque residual mejorado\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        \n",
    "        # Conexión residual\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Attention mechanism simple\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(out_channels, out_channels // 4, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels // 4, out_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Dropout para regularización\n",
    "        self.dropout = nn.Dropout2d(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Upsampling\n",
    "        identity = self.upsample_layer(x)\n",
    "        identity = self.upsample_bn(identity)\n",
    "        identity = self.relu(identity)\n",
    "        \n",
    "        # Bloque residual\n",
    "        out = self.conv_block(identity)\n",
    "        \n",
    "        # Attention\n",
    "        att = self.attention(out)\n",
    "        out = out * att\n",
    "        \n",
    "        # Conexión residual\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f19c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de perdida combinada \n",
    "class CombinedReconstructionLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    CombinedReconstructionLoss combina las pérdidas MSE, SSIM y L1 para tareas de reconstrucción de imágenes.\n",
    "    Parámetros:\n",
    "        mse_weight (float, opcional): Peso para la pérdida de error cuadrático medio (MSE). Por defecto 1.0.\n",
    "        ssim_weight (float, opcional): Peso para la pérdida de índice de similitud estructural (SSIM). Por defecto 0.15.\n",
    "        l1_weight (float, opcional): Peso para la pérdida L1 (error absoluto medio). Por defecto 0.05.\n",
    "    Forward (entrada):\n",
    "        reconstructed (Tensor): Imagen reconstruida.\n",
    "        original (Tensor): Imagen original (objetivo).\n",
    "    Devuelve:\n",
    "        total_loss (Tensor): Suma ponderada de las pérdidas MSE, SSIM y L1.\n",
    "        loss_dict (dict): Diccionario con los valores individuales de cada pérdida:\n",
    "            - 'mse': Pérdida MSE (float)\n",
    "            - 'ssim': Pérdida SSIM (float)\n",
    "            - 'l1': Pérdida L1 (float)\n",
    "            - 'total': Pérdida total combinada (float)\n",
    "    Notas:\n",
    "        - SSIM se calcula como (1 - valor SSIM) para usarlo como término de pérdida.\n",
    "        - Se asume que todas las pérdidas se calculan sobre tensores con valores en [0, 1].\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mse_weight=1.0, ssim_weight=0.15, l1_weight=0.05):\n",
    "        super(CombinedReconstructionLoss, self).__init__()\n",
    "        self.mse_weight = mse_weight\n",
    "        self.ssim_weight = ssim_weight  \n",
    "        self.l1_weight = l1_weight\n",
    "        \n",
    "    def forward(self, reconstructed, original):\n",
    "        # MSE Loss (pérdida principal)\n",
    "        mse_loss = F.mse_loss(reconstructed, original)\n",
    "        \n",
    "        # SSIM Loss (preserva estructura)\n",
    "        ssim_val = ssim(reconstructed, original, data_range=1.0)\n",
    "        ssim_loss = 1 - ssim_val\n",
    "        \n",
    "        # L1 Loss (ayuda con detalles finos)\n",
    "        l1_loss = F.l1_loss(reconstructed, original)\n",
    "        \n",
    "        # Combinar pérdidas\n",
    "        total_loss = (self.mse_weight * mse_loss + \n",
    "                     self.ssim_weight * ssim_loss + \n",
    "                     self.l1_weight * l1_loss)\n",
    "        \n",
    "        return total_loss, {\n",
    "            'mse': mse_loss.item(),\n",
    "            'ssim': ssim_loss.item(), \n",
    "            'l1': l1_loss.item(),\n",
    "            'total': total_loss.item()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c443c",
   "metadata": {},
   "source": [
    "### Funciones y clases auxiliares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c74ad344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset y DataLoader para MVTec AD\n",
    "class MVTecDataset(Dataset):\n",
    "    \"\"\"\n",
    "    MVTecDataset es un Dataset de PyTorch para cargar el dataset MVTec Anomaly Detection.\n",
    "    Parámetros:\n",
    "        root_path (str): Directorio raíz del dataset MVTec.\n",
    "        category (str): Nombre de la categoría de objeto (por ejemplo, 'bottle', 'capsule').\n",
    "        is_train (bool, opcional): Si es True, carga el set de entrenamiento (solo imágenes normales). Si es False, carga el set de test (imágenes normales y anómalas). Por defecto es True.\n",
    "        transform (callable, opcional): Transformaciones a aplicar a las imágenes.\n",
    "        mask_transform (callable, opcional): Transformaciones a aplicar a las máscaras de ground truth.\n",
    "    Atributos:\n",
    "        image_paths (list): Lista de rutas de archivos de imagen.\n",
    "        labels (list o np.ndarray): Lista o array de etiquetas (0 para normal, 1 para anomalía).\n",
    "        mask_paths (list o None): Lista de rutas de máscaras o None si no aplica.\n",
    "    Métodos:\n",
    "        __len__(): Devuelve la cantidad de muestras en el dataset.\n",
    "        __getitem__(idx): Devuelve una tupla (imagen, etiqueta, máscara) para el índice idx.\n",
    "            - imagen (Tensor): Imagen transformada.\n",
    "            - etiqueta (float): 0 para normal, 1 para anomalía.\n",
    "            - máscara (Tensor): Tensor de máscara (todo ceros si no está disponible).\n",
    "    \"\"\"\n",
    "     \n",
    "    def __init__(self, root_path, category, is_train=True, transform=None, mask_transform=None):\n",
    "        self.root_path = root_path\n",
    "        self.category = category\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        \n",
    "        # Definir directorios\n",
    "        if self.is_train:\n",
    "            self.image_dir = os.path.join(root_path, category, 'train', 'good')\n",
    "            self.image_paths = [os.path.join(self.image_dir, f) for f in os.listdir(self.image_dir) \n",
    "                               if f.endswith('.png')]\n",
    "            self.labels = np.zeros(len(self.image_paths), dtype=np.float32)  # 0 = normal\n",
    "            self.mask_paths = None\n",
    "            \n",
    "        else:  # Test set\n",
    "            self.image_dir = os.path.join(root_path, category, 'test')\n",
    "            self.image_paths = []\n",
    "            self.labels = []\n",
    "            self.mask_paths = []\n",
    "            \n",
    "            # Imágenes normales (buenas)\n",
    "            good_dir = os.path.join(self.image_dir, 'good')\n",
    "            if os.path.exists(good_dir):\n",
    "                good_images = [os.path.join(good_dir, f) for f in os.listdir(good_dir) \n",
    "                              if f.endswith('.png')]\n",
    "                self.image_paths.extend(good_images)\n",
    "                self.labels.extend([0] * len(good_images))  # 0 = normal\n",
    "                self.mask_paths.extend([None] * len(good_images))\n",
    "            \n",
    "            # Imágenes anómalas (con defectos)\n",
    "            defect_types = [d for d in os.listdir(self.image_dir) \n",
    "                           if os.path.isdir(os.path.join(self.image_dir, d)) and d != 'good']\n",
    "            \n",
    "            for defect in defect_types:\n",
    "                defect_dir = os.path.join(self.image_dir, defect)\n",
    "                defect_images = [os.path.join(defect_dir, f) for f in os.listdir(defect_dir) \n",
    "                                if f.endswith('.png')]\n",
    "                self.image_paths.extend(defect_images)\n",
    "                self.labels.extend([1] * len(defect_images))  # 1 = anomalía\n",
    "                \n",
    "                # Añadir máscaras de ground truth (si existen)\n",
    "                gt_dir = os.path.join(root_path, category, 'ground_truth', defect)\n",
    "                if os.path.exists(gt_dir):\n",
    "                    for img_path in defect_images:\n",
    "                        img_name = os.path.basename(img_path)\n",
    "                        mask_name = img_name.replace('.png', '_mask.png')\n",
    "                        mask_path = os.path.join(gt_dir, mask_name)\n",
    "                        if os.path.exists(mask_path):\n",
    "                            self.mask_paths.append(mask_path)\n",
    "                        else:\n",
    "                            self.mask_paths.append(None)\n",
    "                else:\n",
    "                    self.mask_paths.extend([None] * len(defect_images))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Cargar imagen\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB') # Convertir a RGB\n",
    "        label = self.labels[idx]\n",
    "    \n",
    "        # Cargar máscara si existe (solo para test y anomalías)\n",
    "        mask = None\n",
    "        if not self.is_train and self.mask_paths[idx] is not None: # Si es test y hay máscara\n",
    "            mask_path = self.mask_paths[idx]\n",
    "            mask = Image.open(mask_path).convert('L') # Convertir a escala de grises\n",
    "            if self.mask_transform:\n",
    "                mask = self.mask_transform(mask) # Aplicar transformaciones a la máscara\n",
    "            elif self.transform:\n",
    "                mask = transforms.Compose([\n",
    "                    transforms.Resize((224, 224)),\n",
    "                    transforms.ToTensor(),\n",
    "                ])(mask) # Aplicar transformaciones por defecto a la máscara\n",
    "        else:\n",
    "            # Crear una máscara vacía si no existe\n",
    "            mask = torch.zeros((1, 224, 224))\n",
    "    \n",
    "        # Aplicar transformaciones a la imagen\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        # Siempre devolver tres elementos\n",
    "        return image, label, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef60b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_datasets(test_datasets, categories, test_size=0.5, random_state=42):\n",
    "    \"\"\"\n",
    "    Divide cada dataset en `test_datasets` en subconjuntos de validación y test, manteniendo la proporción de muestras normales y anómalas cuando es posible.\n",
    "    Args:\n",
    "        test_datasets (list): Lista de datasets a dividir. Cada dataset debe tener un atributo `labels` con las etiquetas de clase (0 para normal, 1 para anomalía).\n",
    "        categories (list): Lista de nombres de categoría correspondiente a cada dataset en `test_datasets`.\n",
    "        test_size (float, opcional): Proporción del dataset a incluir en el split de test. Por defecto es 0.5.\n",
    "        random_state (int, opcional): Semilla aleatoria para reproducibilidad. Por defecto es 42.\n",
    "    Returns:\n",
    "        tuple: Una tupla con dos listas:\n",
    "            - val_datasets (list): Lista de subconjuntos de validación para cada dataset de entrada.\n",
    "            - final_test_datasets (list): Lista de subconjuntos de test para cada dataset de entrada.\n",
    "    Notas:\n",
    "        - Si no es posible hacer un split estratificado (por ejemplo, solo hay una clase), se realiza un split aleatorio simple.\n",
    "        - Imprime un resumen de la división para cada categoría, incluyendo el conteo total, normales, anómalas, validación y test.\n",
    "    \"\"\"\n",
    "    \n",
    "    val_datasets = []\n",
    "    final_test_datasets = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DIVISIÓN DE DATASETS DE TEST\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, test_dataset in enumerate(test_datasets):\n",
    "        # Obtener índices del dataset\n",
    "        indices = list(range(len(test_dataset)))\n",
    "        \n",
    "        # Dividir índices manteniendo la proporción de anomalías\n",
    "        labels = [test_dataset.labels[j] for j in indices]\n",
    "        \n",
    "        # Contar normales y anomalías\n",
    "        normal_count = sum(1 for l in labels if l == 0)\n",
    "        anomaly_count = sum(1 for l in labels if l == 1)\n",
    "        \n",
    "        try:\n",
    "            val_indices, test_indices = train_test_split(\n",
    "                indices, \n",
    "                test_size=test_size,\n",
    "                stratify=labels,  # Mantener proporción de normales/anómalas\n",
    "                random_state=random_state\n",
    "            )\n",
    "        except ValueError:\n",
    "            # Si no se puede estratificar (ej: solo una clase), hacer split simple\n",
    "            val_indices, test_indices = train_test_split(\n",
    "                indices, \n",
    "                test_size=test_size,\n",
    "                random_state=random_state\n",
    "            )\n",
    "        \n",
    "        # Crear subsets\n",
    "        val_subset = Subset(test_dataset, val_indices)\n",
    "        test_subset = Subset(test_dataset, test_indices)\n",
    "        \n",
    "        val_datasets.append(val_subset)\n",
    "        final_test_datasets.append(test_subset)\n",
    "        \n",
    "        print(f\"{categories[i]:12} | Total: {len(indices):3} | \"\n",
    "              f\"Normal: {normal_count:3} | Anomalía: {anomaly_count:3} | \"\n",
    "              f\"Val: {len(val_subset):3} | Test: {len(test_subset):3}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    return val_datasets, final_test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36cf92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_sampler_balanceado(dataset, method='weighted'):\n",
    "    \"\"\"\n",
    "    Crea un sampler o un conjunto de índices balanceados para un dataset con clases desbalanceadas.\n",
    "    Parámetros\n",
    "    ----------\n",
    "    dataset : torch.utils.data.Dataset o torch.utils.data.ConcatDataset\n",
    "        El dataset del que se extraerán las etiquetas para balancear las clases.\n",
    "        Se asume que cada elemento del dataset retorna una tupla donde el segundo elemento es la etiqueta (0: normal, 1: anomalía).\n",
    "    method : str, opcional (por defecto 'weighted')\n",
    "        Método de balanceo a utilizar:\n",
    "            - 'weighted': utiliza WeightedRandomSampler para muestreo ponderado.\n",
    "            - 'oversample': duplica la clase minoritaria hasta igualar la mayoritaria.\n",
    "            - 'undersample': reduce la clase mayoritaria hasta igualar la minoritaria.\n",
    "    Retorna\n",
    "    -------\n",
    "    sampler : torch.utils.data.WeightedRandomSampler o None\n",
    "        Sampler balanceado para DataLoader si se usa el método 'weighted'. En otros métodos retorna None.\n",
    "    balanced_indices : list o None\n",
    "        Lista de índices balanceados para DataLoader si se usa 'oversample' o 'undersample'. En el método 'weighted' retorna None.\n",
    "    Notas\n",
    "    -----\n",
    "    - Imprime la distribución original de clases y detalles del método de balanceo utilizado.\n",
    "    - Para 'oversample' y 'undersample', los índices pueden ser usados con torch.utils.data.SubsetRandomSampler.\n",
    "    \"\"\"\n",
    "    # Extraer todas las etiquetas del dataset\n",
    "    if hasattr(dataset, 'datasets'):  # ConcatDataset\n",
    "        labels = []\n",
    "        for i in range(len(dataset)):\n",
    "            _, label, _ = dataset[i]\n",
    "            labels.append(int(label))\n",
    "    else:  # Dataset simple\n",
    "        labels = []\n",
    "        for i in range(len(dataset)):\n",
    "            _, label, _ = dataset[i]\n",
    "            labels.append(int(label))\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Contar clases\n",
    "    class_counts = Counter(labels)\n",
    "    print(f\"   Distribución original: Normal={class_counts[0]}, Anomalía={class_counts[1]}\")\n",
    "    \n",
    "    if method == 'weighted':\n",
    "        # Weighted Random Sampler\n",
    "        class_weights = {}\n",
    "        total_samples = len(labels)\n",
    "        \n",
    "        for class_id, count in class_counts.items():\n",
    "            class_weights[class_id] = total_samples / (len(class_counts) * count)\n",
    "        \n",
    "        sample_weights = [class_weights[int(label)] for label in labels]\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights, \n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "        \n",
    "        print(f\"   Método: Weighted Sampling\")\n",
    "        print(f\"   Pesos: Normal={class_weights[0]:.3f}, Anomalía={class_weights[1]:.3f}\")\n",
    "        \n",
    "        return sampler, None\n",
    "    \n",
    "    elif method == 'oversample':\n",
    "        # Oversampling: duplicar la clase minoritaria\n",
    "        max_count = max(class_counts.values())\n",
    "        balanced_indices = []\n",
    "        \n",
    "        for class_id in [0, 1]:  # normal, anomaly\n",
    "            class_indices = np.where(labels == class_id)[0]\n",
    "            # Repetir indices hasta alcanzar max_count\n",
    "            repeats = max_count // len(class_indices)\n",
    "            remainder = max_count % len(class_indices)\n",
    "            \n",
    "            balanced_indices.extend(class_indices.tolist() * repeats)\n",
    "            balanced_indices.extend(class_indices[:remainder].tolist())\n",
    "        \n",
    "        np.random.shuffle(balanced_indices)\n",
    "        \n",
    "        print(f\"   Método: Oversampling\")\n",
    "        print(f\"   Tamaño balanceado: {len(balanced_indices)} (Normal={max_count}, Anomalía={max_count})\")\n",
    "        \n",
    "        return None, balanced_indices\n",
    "    \n",
    "    elif method == 'undersample':\n",
    "        # Undersampling: reducir la clase mayoritaria\n",
    "        min_count = min(class_counts.values())\n",
    "        balanced_indices = []\n",
    "        \n",
    "        for class_id in [0, 1]:\n",
    "            class_indices = np.where(labels == class_id)[0]\n",
    "            # Tomar solo min_count muestras\n",
    "            selected_indices = np.random.choice(class_indices, min_count, replace=False)\n",
    "            balanced_indices.extend(selected_indices.tolist())\n",
    "        \n",
    "        np.random.shuffle(balanced_indices)\n",
    "        \n",
    "        print(f\"   Método: Undersampling\")\n",
    "        print(f\"   Tamaño balanceado: {len(balanced_indices)} (Normal={min_count}, Anomalía={min_count})\")\n",
    "        \n",
    "        return None, balanced_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98e6df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_dataloader_balanceado(dataset, batch_size, method='weighted', num_workers=4):    \n",
    "    \"\"\"\n",
    "    Crea un DataLoader balanceado para entrenamiento con datasets desbalanceados.\n",
    "    Esta función crea un DataLoader que maneja el desbalance de clases usando\n",
    "    muestreo ponderado o muestreo por subconjunto basado en el método especificado.\n",
    "    Args:\n",
    "        dataset: Objeto dataset de PyTorch que contiene los datos de entrenamiento\n",
    "        batch_size (int): Número de muestras por lote\n",
    "        method (str, opcional): Método de balanceo a usar. Opciones:\n",
    "            - 'weighted': Usa WeightedRandomSampler para balancear clases\n",
    "            - Otros valores: Usa Subset con índices balanceados\n",
    "            Por defecto es 'weighted'\n",
    "        num_workers (int, opcional): Número de procesos worker para carga de datos.\n",
    "            Por defecto es 4\n",
    "    Returns:\n",
    "        DataLoader: Un DataLoader de PyTorch configurado con el método de balanceo\n",
    "        y parámetros especificados\n",
    "    Nota:\n",
    "        Esta función depende de `crear_sampler_balanceado()` para generar el\n",
    "        sampler apropiado o índices para balancear el dataset.\n",
    "    \"\"\"\n",
    "    sampler, indices = crear_sampler_balanceado(dataset, method=method)\n",
    "    \n",
    "    if sampler is not None:\n",
    "        # Usar WeightedRandomSampler\n",
    "        return DataLoader(\n",
    "            dataset, \n",
    "            batch_size=batch_size, \n",
    "            sampler=sampler,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "    else:\n",
    "        # Usar Subset con indices balanceados\n",
    "        from torch.utils.data import Subset\n",
    "        balanced_dataset = Subset(dataset, indices)\n",
    "        return DataLoader(\n",
    "            balanced_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=num_workers\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0aecb",
   "metadata": {},
   "source": [
    "### Funciones de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96f99969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, output_dir, logs_dir, model_name):\n",
    "    \"\"\"\n",
    "    Entrena un modelo autoencoder para detección de anomalías usando función de pérdida combinada.\n",
    "    Esta función realiza el entrenamiento y validación de un modelo autoencoder, utilizando una\n",
    "    función de pérdida combinada (MSE + SSIM + L1) tanto para entrenamiento como para puntuación\n",
    "    consistente de anomalías. El modelo se evalúa usando la métrica ROC AUC y se guarda el modelo\n",
    "    con mejor rendimiento.\n",
    "    Args:\n",
    "        model: El modelo autoencoder a entrenar. Debe tener el método set_scoring_criterion.\n",
    "        train_loader: DataLoader para datos de entrenamiento. Retorna (imágenes, etiquetas, máscaras).\n",
    "        val_loader: DataLoader para datos de validación. Retorna (imágenes, etiquetas, máscaras).\n",
    "        criterion: Función de pérdida combinada que retorna (pérdida, diccionario_componentes_pérdida).\n",
    "        optimizer: Optimizador de PyTorch para los parámetros del modelo.\n",
    "        scheduler: Planificador de tasa de aprendizaje que toma la pérdida de validación como entrada.\n",
    "        num_epochs (int): Número de épocas de entrenamiento.\n",
    "        device: Dispositivo de PyTorch (cpu/cuda) para el modelo y los datos.\n",
    "        output_dir (str): Ruta del directorio para guardar el checkpoint del mejor modelo.\n",
    "        logs_dir (str): Ruta del directorio para logs de TensorBoard.\n",
    "        model_name (str): Identificador de nombre para el modelo (usado en logging y guardado).\n",
    "    Returns:\n",
    "        model: El modelo entrenado con los mejores pesos cargados.\n",
    "    La función realiza las siguientes operaciones:\n",
    "    - Configura el logging de TensorBoard para monitoreo integral del entrenamiento\n",
    "    - Entrena el modelo usando pérdida combinada (MSE + SSIM + L1)\n",
    "    - Valida el modelo y calcula puntuaciones de anomalía usando la misma función de pérdida\n",
    "    - Rastrea la métrica ROC AUC para el rendimiento de detección de anomalías\n",
    "    - Guarda el mejor modelo basado en el AUC de validación más alto\n",
    "    - Registra métricas detalladas, componentes de pérdida y reconstrucciones de muestra\n",
    "    - Actualiza la tasa de aprendizaje usando el planificador\n",
    "    El bucle de entrenamiento incluye logging detallado de:\n",
    "    - Componentes individuales de pérdida (MSE, SSIM, L1, Total)\n",
    "    - Puntuaciones ROC AUC para evaluación de detección de anomalías\n",
    "    - Progresión de la tasa de aprendizaje\n",
    "    - Distribuciones de puntuación para muestras normales vs anómalas\n",
    "    - Reconstrucciones de imágenes de muestra para inspección visual\n",
    "    \"\"\"\n",
    "\n",
    "    writer = SummaryWriter(log_dir=f'{logs_dir}/{model_name}') # Para tensorboard\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Configurar el criterio de scoring en el modelo\n",
    "    model.set_scoring_criterion(criterion)\n",
    "\n",
    "    best_auc = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 201 #25\n",
    "    patience_counter = 0\n",
    "    early_stop = False\n",
    "\n",
    "    print(f\"\\n INICIANDO ENTRENAMIENTO\")\n",
    "    print(f\"   Épocas: {num_epochs}\")\n",
    "    print(f\"   Función de pérdida: MSE + SSIM + L1\")\n",
    "    print(f\"   Dispositivo: {device}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # =============\n",
    "        # Entrenamiento\n",
    "        # =============\n",
    "        model.train()\n",
    "        train_losses = {'total': 0.0, 'mse': 0.0, 'ssim': 0.0, 'l1': 0.0}\n",
    "        num_train_batches = 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (train)\"):\n",
    "            images, _, _ = batch  # Desempacar correctamente (imagen, etiqueta, máscara)\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            reconstructed, _ = model(images)\n",
    "\n",
    "            # Calcular pérdida combinada\n",
    "            loss, loss_components = criterion(reconstructed, images)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Acumular pérdidas para logging\n",
    "            for key in train_losses:\n",
    "                train_losses[key] += loss_components[key]\n",
    "            num_train_batches += 1\n",
    "        \n",
    "        # ==========\n",
    "        # Validación\n",
    "        # ==========\n",
    "        model.eval()\n",
    "        val_losses = {'total': 0.0, 'mse': 0.0, 'ssim': 0.0, 'l1': 0.0}\n",
    "        all_scores = []\n",
    "        all_labels = []\n",
    "        num_val_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (val)\"):\n",
    "                images = images.to(device)\n",
    "                reconstructed, _ = model(images)\n",
    "\n",
    "                # Calcular pérdida de validación usando función combinada\n",
    "                val_loss, val_loss_components = criterion(reconstructed, images)\n",
    "\n",
    "                # Acumular pérdidas\n",
    "                for key in val_losses:\n",
    "                    val_losses[key] += val_loss_components[key]\n",
    "                num_val_batches += 1\n",
    "\n",
    "                # Scoring Cconsistente: Usar función combinada para anomaly detection\n",
    "                batch_scores = []\n",
    "                for i in range(images.size(0)):\n",
    "                    single_img = images[i:i+1]  # Mantener dimensión batch\n",
    "                    single_rec = reconstructed[i:i+1]\n",
    "\n",
    "                    # Usar la misma función de pérdida para scoring\n",
    "                    combined_error, _ = criterion(single_rec, single_img)\n",
    "                    batch_scores.append(combined_error.item())\n",
    "\n",
    "                all_scores.extend(batch_scores)\n",
    "                all_labels.extend(labels.numpy())\n",
    "\n",
    "        # =====================================\n",
    "        # Calcular métricas y registrar logging\n",
    "        # =====================================\n",
    "\n",
    "        # Calcular promedios de pérdidas\n",
    "        avg_train_losses = {k: v / num_train_batches for k, v in train_losses.items()}\n",
    "        avg_val_losses = {k: v / num_val_batches for k, v in val_losses.items()}\n",
    "\n",
    "        # Calcular ROC AUC si tenemos ambas clases (normal y anomalía)\n",
    "        fpr, tpr, _ = roc_curve(all_labels, all_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Guardar el mejor modelo basado en AUC\n",
    "        if roc_auc > best_auc:\n",
    "            best_auc = roc_auc\n",
    "            torch.save(model.state_dict(), os.path.join(output_dir, f'{model_name}.pth'))\n",
    "            patience_counter = 0  # Resetear contador de paciencia\n",
    "            print(f\"      Nuevo mejor modelo guardado! AUC: {roc_auc:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"      AUC no mejorado. Paciencia: {patience_counter}/{patience}\")\n",
    "\n",
    "        # Logging detallado\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"   Train Loss:\")\n",
    "        print(f\"     Total: {avg_train_losses['total']:.4f} | MSE: {avg_train_losses['mse']:.4f} | SSIM: {avg_train_losses['ssim']:.4f} | L1: {avg_train_losses['l1']:.4f}\")\n",
    "        print(f\"   Val Loss:\")\n",
    "        print(f\"     Total: {avg_val_losses['total']:.4f} | MSE: {avg_val_losses['mse']:.4f} | SSIM: {avg_val_losses['ssim']:.4f} | L1: {avg_val_losses['l1']:.4f}\")\n",
    "        print(f\"   ROC AUC (Combined Scoring): {roc_auc:.4f} | Best: {best_auc:.4f}\")\n",
    "\n",
    "        # Guardo los valores en tensorboard\n",
    "        # Logging de pérdidas de entrenamiento\n",
    "        writer.add_scalar('Loss/Train_Total', avg_train_losses['total'], epoch)\n",
    "        writer.add_scalar('Loss/Train_MSE', avg_train_losses['mse'], epoch)\n",
    "        writer.add_scalar('Loss/Train_SSIM', avg_train_losses['ssim'], epoch)\n",
    "        writer.add_scalar('Loss/Train_L1', avg_train_losses['l1'], epoch)\n",
    "\n",
    "        # Logging de pérdidas de validación\n",
    "        writer.add_scalar('Loss/Val_Total', avg_val_losses['total'], epoch)\n",
    "        writer.add_scalar('Loss/Val_MSE', avg_val_losses['mse'], epoch)\n",
    "        writer.add_scalar('Loss/Val_SSIM', avg_val_losses['ssim'], epoch)\n",
    "        writer.add_scalar('Loss/Val_L1', avg_val_losses['l1'], epoch)\n",
    "\n",
    "        # Logging de métricas de evaluación\n",
    "        writer.add_scalar('Metrics/ROC_AUC', roc_auc, epoch)\n",
    "        writer.add_scalar('Metrics/Best_AUC', best_auc, epoch)\n",
    "\n",
    "        # Logging del learning rate\n",
    "        writer.add_scalar('Training/Learning_Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        # Logging de histogramas de scores para análisis más detallado\n",
    "        writer.add_histogram(\"Scores/Anomaly_Scores\", torch.tensor(all_scores), epoch)\n",
    "\n",
    "        # Separar scores por clase para mejor análisis\n",
    "        normal_scores = [\n",
    "            score for score, label in zip(all_scores, all_labels) if label == 0\n",
    "        ]\n",
    "        anomaly_scores = [\n",
    "            score for score, label in zip(all_scores, all_labels) if label == 1\n",
    "        ]\n",
    "\n",
    "        if normal_scores:\n",
    "            writer.add_histogram(\"Scores/Normal_Scores\", torch.tensor(normal_scores), epoch)\n",
    "        if anomaly_scores:\n",
    "            writer.add_histogram(\n",
    "                \"Scores/Anomaly_Scores\", torch.tensor(anomaly_scores), epoch\n",
    "            )\n",
    "\n",
    "        # Guardo imágenes de ejemplo cada cierto número de épocas\n",
    "        if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "            # Tomar las primeras 8 imágenes del batch de validación para visualización\n",
    "            with torch.no_grad():\n",
    "                sample_images = images[:8]\n",
    "                sample_reconstructed = reconstructed[:8]\n",
    "        \n",
    "                # Crear una grilla con imágenes originales y reconstruidas\n",
    "                comparison = torch.cat([sample_images, sample_reconstructed], dim=0)\n",
    "                writer.add_images('Images/Original_vs_Reconstructed', comparison, epoch, dataformats='NCHW')\n",
    "\n",
    "        writer.flush()\n",
    "\n",
    "        # Actualizar learning rate\n",
    "        #scheduler.step(avg_val_losses['total']) # Usar el scheduler con la pérdida de validación plateau\n",
    "        scheduler.step() # Para usar el scheduler sin pasarle la pérdida\n",
    "\n",
    "        print(f\"   Learning Rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        # Verificar early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\n Early stopping en época {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    print(f\"\\n ENTRENAMIENTO COMPLETADO!\")\n",
    "    print(f\"   Mejor AUC alcanzado: {best_auc:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6634e8ac",
   "metadata": {},
   "source": [
    "### Funciones de Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ba2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_examples(images, labels, scores, masks, threshold, output_dir, model_type):\n",
    "    \"\"\"\n",
    "    Genera visualizaciones de las predicciones del modelo categorizadas por resultados de clasificación.\n",
    "    Esta función crea ejemplos visuales de Verdaderos Positivos, Verdaderos Negativos, Falsos Positivos\n",
    "    y Falsos Negativos, junto con una matriz de confusión. Guarda todas las visualizaciones en el\n",
    "    directorio de salida especificado.\n",
    "    Args:\n",
    "        images (array-like): Imágenes de entrada para visualizar. Puede ser array numpy o lista.\n",
    "                           Forma esperada: (N, 3, H, W) o (N, H, W, 3)\n",
    "        labels (array-like): Etiquetas verdaderas (0 para normal, 1 para anomalía)\n",
    "        scores (array-like): Puntuaciones/probabilidades de predicción del modelo\n",
    "        masks (array-like): Máscaras verdaderas para localización de anomalías (opcional)\n",
    "        threshold (float): Umbral de decisión para convertir puntuaciones a predicciones binarias\n",
    "        output_dir (str): Ruta del directorio donde se guardarán las visualizaciones\n",
    "        model_type (str): Tipo de modelo que se está evaluando (para propósitos de documentación)\n",
    "    Returns:\n",
    "        None: La función guarda visualizaciones en disco e imprime información de progreso\n",
    "    Efectos Secundarios:\n",
    "        - Crea subdirectorio 'examples' en output_dir\n",
    "        - Guarda archivos PNG para cada categoría de predicción (hasta 5 ejemplos cada una)\n",
    "        - Guarda matriz de confusión como 'matriz_de_confusion.png'\n",
    "        - Imprime estadísticas sobre distribución de datos y progreso de procesamiento\n",
    "    Notas:\n",
    "        - Las imágenes se desnormalizan automáticamente usando estadísticas de ImageNet\n",
    "        - Soporta formatos de imagen CHW y HWC\n",
    "        - Maneja casos con o sin máscaras de verdad fundamental\n",
    "        - Limitado a 5 ejemplos por categoría para prevenir generación excesiva de archivos\n",
    "        - Usa matplotlib para visualización y requiere sklearn para matriz de confusión\n",
    "    Raises:\n",
    "        Exception: Captura y reporta errores durante procesamiento de imágenes o guardado de archivos\n",
    "                  pero continúa la ejecución para las visualizaciones restantes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Crear directorio principal si no existe\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Crear directorio de examples\n",
    "    examples_dir = os.path.join(output_dir, 'examples')\n",
    "    os.makedirs(examples_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Creando visualizaciones en: {examples_dir}\")\n",
    "    \n",
    "    # Convertir a numpy arrays si no lo son\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    scores = np.array(scores)\n",
    "    predictions = (scores >= threshold).astype(int)\n",
    "    \n",
    "    print(f\"Total de imágenes: {len(images)}\")\n",
    "    print(f\"Distribución de etiquetas - Normal: {np.sum(labels == 0)}, Anomalía: {np.sum(labels == 1)}\")\n",
    "    print(f\"Distribución de predicciones - Normal: {np.sum(predictions == 0)}, Anomalía: {np.sum(predictions == 1)}\")\n",
    "    \n",
    "    # Índices para cada categoría (TP, TN, FP, FN)\n",
    "    true_positive = np.where((predictions == 1) & (labels == 1))[0]\n",
    "    true_negative = np.where((predictions == 0) & (labels == 0))[0]\n",
    "    false_positive = np.where((predictions == 1) & (labels == 0))[0]\n",
    "    false_negative = np.where((predictions == 0) & (labels == 1))[0]\n",
    "    \n",
    "    print(f\"True Positives: {len(true_positive)}\")\n",
    "    print(f\"True Negatives: {len(true_negative)}\")\n",
    "    print(f\"False Positives: {len(false_positive)}\")\n",
    "    print(f\"False Negatives: {len(false_negative)}\")\n",
    "    \n",
    "    # Limitar número de ejemplos\n",
    "    max_examples = 5\n",
    "    categories = [\n",
    "        ('true_positive', true_positive[:max_examples]),\n",
    "        ('true_negative', true_negative[:max_examples]),\n",
    "        ('false_positive', false_positive[:max_examples]),\n",
    "        ('false_negative', false_negative[:max_examples])\n",
    "    ]\n",
    "    \n",
    "    # Determinar si tenemos máscaras disponibles\n",
    "    has_masks = len(masks) > 0 and any(mask is not None for mask in masks)\n",
    "    print(f\"Máscaras disponibles: {has_masks}\")\n",
    "    \n",
    "    # Visualizar ejemplos por categoría\n",
    "    for category_name, indices in categories:\n",
    "        if len(indices) == 0:\n",
    "            print(f\"No hay ejemplos para {category_name}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Creando visualización para {category_name} con {len(indices)} ejemplos\")\n",
    "        \n",
    "        # Determinar el número de subplots (2 o 3 columnas por muestra)\n",
    "        n_cols = 3 if has_masks else 2\n",
    "        fig_width = 4 * len(indices) * n_cols\n",
    "        fig_height = 4\n",
    "        \n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        \n",
    "        for i, idx in enumerate(indices):\n",
    "            try:\n",
    "                # Imagen original\n",
    "                subplot_idx = i * n_cols + 1\n",
    "                plt.subplot(1, len(indices) * n_cols, subplot_idx)\n",
    "                \n",
    "                img = images[idx]\n",
    "                if img.shape[0] == 3:  # Si está en formato CHW\n",
    "                    img = img.transpose(1, 2, 0)  # Convertir a HWC\n",
    "                \n",
    "                # Desnormalizar la imagen\n",
    "                img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                img = np.clip(img, 0, 1)\n",
    "                \n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"Original\\nScore: {scores[idx]:.4f}\\nLabel: {int(labels[idx])}\")\n",
    "                plt.axis('off')\n",
    "                \n",
    "                # Máscara de ground truth (si está disponible)\n",
    "                if has_masks and idx < len(masks) and masks[idx] is not None:\n",
    "                    plt.subplot(1, len(indices) * n_cols, subplot_idx + 1)\n",
    "                    mask = masks[idx]\n",
    "                    if hasattr(mask, 'squeeze'):\n",
    "                        mask = mask.squeeze()\n",
    "                    elif isinstance(mask, np.ndarray) and mask.ndim > 2:\n",
    "                        mask = np.squeeze(mask)\n",
    "                    \n",
    "                    plt.imshow(mask, cmap='gray')\n",
    "                    plt.title(\"Ground Truth\")\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    # Predicción\n",
    "                    plt.subplot(1, len(indices) * n_cols, subplot_idx + 2)\n",
    "                else:\n",
    "                    # Sin máscara, solo predicción\n",
    "                    plt.subplot(1, len(indices) * n_cols, subplot_idx + 1)\n",
    "                \n",
    "                # Mostrar predicción\n",
    "                if predictions[idx] == 1:\n",
    "                    plt.text(0.5, 0.5, \"ANOMALY\", ha='center', va='center', \n",
    "                             fontsize=16, color='red', weight='bold',\n",
    "                             transform=plt.gca().transAxes)\n",
    "                else:\n",
    "                    plt.text(0.5, 0.5, \"NORMAL\", ha='center', va='center', \n",
    "                             fontsize=16, color='green', weight='bold',\n",
    "                             transform=plt.gca().transAxes)\n",
    "                \n",
    "                plt.title(f\"Prediction\\nThreshold: {threshold:.4f}\")\n",
    "                plt.axis('off')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando imagen {idx} en categoría {category_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        plt.suptitle(f\"{category_name.replace('_', ' ').title()}\", fontsize=16, y=0.98)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Guardar figura\n",
    "        filename = os.path.join(examples_dir, f'{category_name}.png')\n",
    "        try:\n",
    "            plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "            print(f\"Guardado: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error guardando {filename}: {e}\")\n",
    "        finally:\n",
    "            plt.close()  # Cerrar figura para liberar memoria\n",
    "    \n",
    "    # Matriz de confusión\n",
    "    try:\n",
    "        from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Anomalía'])\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title('Matriz de Confusión')\n",
    "        \n",
    "        cm_filename = os.path.join(output_dir, 'matriz_de_confusion.png')\n",
    "        plt.savefig(cm_filename, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Matriz de confusión guardada: {cm_filename}\")\n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creando matriz de confusión: {e}\")\n",
    "    \n",
    "    print(f\"Visualizaciones completadas en: {examples_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a05e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_anomaly_maps(model, test_loader, device, output_dir, threshold):\n",
    "    \"\"\"\n",
    "    Visualiza los resultados de detección de anomalías generando gráficos comparativos de imágenes originales,\n",
    "    reconstrucciones y mapas de anomalía.\n",
    "    \n",
    "    Esta función procesa datos de prueba a través de un modelo autoencoder para generar mapas de anomalía\n",
    "    basados en errores de reconstrucción. Crea gráficos de visualización que muestran imágenes originales,\n",
    "    imágenes reconstruidas, mapas de error por píxel y máscaras de verdad fundamental (si están disponibles).\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo autoencoder entrenado para detección de anomalías\n",
    "        test_loader: DataLoader que contiene imágenes de prueba con etiquetas y máscaras opcionales\n",
    "        device: Dispositivo PyTorch (CPU/GPU) para inferencia del modelo\n",
    "        output_dir (str): Ruta del directorio donde se guardarán las visualizaciones de mapas de anomalía\n",
    "        threshold: Valor umbral para clasificación de anomalías (actualmente no utilizado)\n",
    "        model_type: Tipo de modelo que se está utilizando (actualmente no utilizado)\n",
    "        \n",
    "    Returns:\n",
    "        None: La función guarda los gráficos de visualización en disco\n",
    "        \n",
    "    Notas:\n",
    "        - Crea hasta 5 muestras cada una para las categorías normal y anomalía\n",
    "        - Soporta datasets con o sin máscaras de verdad fundamental\n",
    "        - Las imágenes se desnormalizan usando estadísticas de ImageNet antes de la visualización\n",
    "        - Los mapas de error se calculan como diferencias absolutas por píxel entre imágenes originales y reconstruidas\n",
    "        - Los gráficos de salida se guardan como archivos PNG en el subdirectorio 'anomaly_maps'\n",
    "        - La función espera formato de lote: (imágenes, etiquetas) o (imágenes, etiquetas, máscaras)\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(os.path.join(output_dir, 'anomaly_maps'), exist_ok=True)\n",
    "    model.eval()\n",
    "    \n",
    "    # Seleccionar algunas imágenes para visualización\n",
    "    samples_seen = {'normal': 0, 'anomaly': 0}\n",
    "    max_samples = 5\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            # Manejar batch con o sin máscara\n",
    "            if len(batch) == 3:\n",
    "                images, labels, masks = batch\n",
    "                has_masks = True\n",
    "            else:\n",
    "                images, labels = batch\n",
    "                masks = None\n",
    "                has_masks = False\n",
    "            \n",
    "            images = images.to(device)\n",
    "            batch_size = images.size(0)\n",
    "            \n",
    "            # Modelo autoencoder\n",
    "            \n",
    "            reconstructed, _ = model(images)\n",
    "            # Calcular error de reconstrucción por píxel\n",
    "            error_maps = torch.abs(images - reconstructed)\n",
    "            # Normalizar mapas de error para visualización\n",
    "            error_maps_mean = error_maps.mean(dim=1)  # Promediar a través de los canales\n",
    "                \n",
    "            # Convertir a numpy para visualización\n",
    "            images_np = images.cpu().numpy()\n",
    "            error_maps_np = error_maps_mean.cpu().numpy()\n",
    "            reconstructed_np = reconstructed.cpu().numpy()\n",
    "                \n",
    "            for i in range(batch_size):\n",
    "                label = labels[i].item()\n",
    "                category = 'normal' if label == 0 else 'anomaly'\n",
    "                    \n",
    "                if samples_seen[category] < max_samples:\n",
    "                    # Determinar número de subplots\n",
    "                    n_cols = 4 if has_masks else 3\n",
    "                    fig, axes = plt.subplots(1, n_cols, figsize=(5 * n_cols, 5))\n",
    "                        \n",
    "                    # Imagen original\n",
    "                    img = images_np[i].transpose(1, 2, 0)\n",
    "                    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                    img = np.clip(img, 0, 1)                        \n",
    "                    axes[0].imshow(img)\n",
    "                    axes[0].set_title(\"Original\")\n",
    "                    axes[0].axis('off')\n",
    "                        \n",
    "                    # Imagen reconstruida\n",
    "                    rec_img = reconstructed_np[i].transpose(1, 2, 0)\n",
    "                    rec_img = rec_img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                    rec_img = np.clip(rec_img, 0, 1)\n",
    "                    axes[1].imshow(rec_img)\n",
    "                    axes[1].set_title(\"Reconstrucción\")\n",
    "                    axes[1].axis('off')\n",
    "                        \n",
    "                    # Mapa de error\n",
    "                    error_map = error_maps_np[i]\n",
    "                    vmax = np.max(error_map) if np.max(error_map) > 0 else 1\n",
    "                    im = axes[2].imshow(error_map, cmap='jet', vmin=0, vmax=vmax)\n",
    "                    axes[2].set_title(f\"Mapa de Anomalía\\n(Score: {error_maps_mean[i].mean().item():.4f})\")\n",
    "                    axes[2].axis('off')\n",
    "                        \n",
    "                    # Máscara de ground truth (si está disponible)\n",
    "                    if has_masks and masks is not None:\n",
    "                        mask_np = masks[i].squeeze().cpu().numpy()\n",
    "                        axes[3].imshow(mask_np, cmap='gray')\n",
    "                        axes[3].set_title(\"Ground Truth Mask\")\n",
    "                        axes[3].axis('off')\n",
    "                        \n",
    "                    plt.colorbar(im, ax=axes[2])\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(os.path.join(output_dir, 'anomaly_maps', f'{category}_{samples_seen[category]}.png'))\n",
    "                    plt.close()\n",
    "                        \n",
    "                    samples_seen[category] += 1\n",
    "            \n",
    "            if all(count >= max_samples for count in samples_seen.values()):\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb2801",
   "metadata": {},
   "source": [
    "### Funciones de Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7f4ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, final_test_loader, device, output_dir, model_name, model_type='autoencoder'):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo de detección de anomalías en el conjunto de prueba final usando puntuación consistente.\n",
    "    \n",
    "    Esta función realiza una evaluación integral de un modelo de detección de anomalías,\n",
    "    calculando varias métricas, generando gráficos de visualización y guardando resultados.\n",
    "    \n",
    "    Args:\n",
    "        model: El modelo de detección de anomalías entrenado a evaluar. Debe tener el método\n",
    "               'detectar_anomalia_consistente' o una pasada hacia adelante estándar.\n",
    "        final_test_loader: DataLoader que contiene el dataset de prueba con imágenes,\n",
    "                          etiquetas y máscaras.\n",
    "        device: Objeto torch.device que especifica GPU o CPU para el cómputo.\n",
    "        output_dir (str): Ruta del directorio base donde se guardarán los resultados de evaluación.\n",
    "        model_name (str): Nombre del modelo, usado para crear subdirectorios.\n",
    "        model_type (str, opcional): Tipo de modelo que se está evaluando. Por defecto es 'autoencoder'.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario que contiene las métricas de evaluación con las siguientes claves:\n",
    "            - 'roc_auc': Área bajo la curva ROC\n",
    "            - 'avg_precision': Puntuación de precisión promedio\n",
    "            - 'accuracy': Precisión de clasificación usando el umbral óptimo\n",
    "            - 'precision': Puntuación de precisión\n",
    "            - 'recall': Puntuación de recall\n",
    "            - 'f1': Puntuación F1\n",
    "            - 'threshold': Valor del umbral óptimo\n",
    "            - 'scores': Lista de todas las puntuaciones de anomalía\n",
    "            - 'labels': Lista de todas las etiquetas verdaderas\n",
    "    \n",
    "    Efectos Secundarios:\n",
    "        - Crea el directorio de salida si no existe\n",
    "        - Guarda gráficos de evaluación (curva ROC, curva PR, distribución de puntuaciones) como PNG\n",
    "        - Imprime resultados detallados de evaluación en consola\n",
    "        - Llama a visualize_examples() para generar visualizaciones de ejemplo\n",
    "        - Establece el modelo en modo de evaluación\n",
    "    \n",
    "    Nota:\n",
    "        La función usa metodología de puntuación consistente, prefiriendo el método\n",
    "        'detectar_anomalia_consistente' del modelo si está disponible, de lo contrario\n",
    "        recurre al error de reconstrucción MSE.\n",
    "    \"\"\"\n",
    "    \n",
    "    output_dir = output_dir+model_name\n",
    "    ensure_directory_exists(output_dir)\n",
    "    \n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    all_images = []\n",
    "    all_masks = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" REALIZANDO EVALUACIÓN FINAL CON SCORING CONSISTENTE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, masks in tqdm(final_test_loader, desc=\"Evaluación final\"):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Usar scoring consitente\n",
    "            batch_scores = []\n",
    "            for i in range(images.size(0)):\n",
    "                single_img = images[i:i+1]  # Mantener dimensión batch\n",
    "                    \n",
    "                # Usar el método de detección consistente\n",
    "                if hasattr(model, 'detectar_anomalia_consistente'):\n",
    "                    score = model.detectar_anomalia_consistente(single_img)\n",
    "                    batch_scores.append(score.item())\n",
    "                else:\n",
    "                    # Fallback al método original si no está disponible\n",
    "                    reconstructed, _ = model(single_img)\n",
    "                    error = torch.mean((single_img - reconstructed) ** 2)\n",
    "                    batch_scores.append(error.item())\n",
    "                \n",
    "            scores = batch_scores\n",
    "            \n",
    "            all_scores.extend(scores)\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_images.extend(images.cpu().numpy())\n",
    "            all_masks.extend(masks.cpu().numpy() if hasattr(masks, 'cpu') else masks)\n",
    "    \n",
    "    # =========================\n",
    "    # Calcular Métricas Finales\n",
    "    # =========================\n",
    "\n",
    "    # Calcular métricas finales\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n",
    "    avg_precision = average_precision_score(all_labels, all_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Encontrar mejor threshold\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    # Calcular accuracy con threshold óptimo\n",
    "    predictions = (np.array(all_scores) > optimal_threshold).astype(int)\n",
    "    accuracy = np.mean(predictions == all_labels)\n",
    "    \n",
    "    # Calcular precision, recall, F1\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, predictions, average='binary'\n",
    "    )\n",
    "    \n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(all_labels, all_scores)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" RESULTADOS FINALES (SCORING CONSISTENTE)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ROC AUC:        {roc_auc:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Accuracy:       {accuracy:.4f}\")\n",
    "    print(f\"Precision:      {precision:.4f}\")\n",
    "    print(f\"Recall:         {recall:.4f}\")\n",
    "    print(f\"F1-Score:       {f1:.4f}\")\n",
    "    print(f\"Optimal Threshold: {optimal_threshold:.6f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # =================\n",
    "    # Visualizar curvas\n",
    "    # =================\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # ROC Curve\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Consistent Scoring)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(recall_curve, precision_curve, color='blue', lw=2, label=f'PR curve (AP = {avg_precision:.3f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    \n",
    "    # Score Distribution\n",
    "    plt.subplot(1, 3, 3)\n",
    "    normal_scores = [score for score, label in zip(all_scores, all_labels) if label == 0]\n",
    "    anomaly_scores = [score for score, label in zip(all_scores, all_labels) if label == 1]\n",
    "    \n",
    "    plt.hist(normal_scores, bins=50, alpha=0.7, label='Normal', color='green', density=True)\n",
    "    plt.hist(anomaly_scores, bins=50, alpha=0.7, label='Anomaly', color='red', density=True)\n",
    "    plt.axvline(optimal_threshold, color='black', linestyle='--', label=f'Threshold: {optimal_threshold:.3f}')\n",
    "    plt.xlabel('Anomaly Score')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Score Distribution')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    curves_filename = os.path.join(output_dir, 'evaluacion_final_consistente.png')\n",
    "    plt.savefig(curves_filename, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f' Gráficos de evaluación guardados en: {curves_filename}')\n",
    "    \n",
    "    # ===================\n",
    "    # Visualizar ejemplos\n",
    "    # ===================\n",
    "    visualize_examples(all_images, all_labels, all_scores, all_masks, optimal_threshold, output_dir, model_type)\n",
    "\n",
    "    return {\n",
    "        'roc_auc': float(roc_auc),\n",
    "        'avg_precision': float(avg_precision),\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'f1': float(f1),\n",
    "        'threshold': float(optimal_threshold),\n",
    "        'scores': all_scores,\n",
    "        'labels': all_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5096731c",
   "metadata": {},
   "source": [
    "### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcf5722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar para verificar y crear directorios\n",
    "def ensure_directory_exists(path):\n",
    "    \"\"\"\n",
    "    Asegura que un directorio exista, creándolo si es necesario.\n",
    "    Esta función intenta crear un directorio en la ruta especificada. Si el directorio\n",
    "    ya existe, no se genera ningún error debido al parámetro exist_ok=True. La función\n",
    "    proporciona retroalimentación en consola sobre el éxito o fallo de la operación.\n",
    "    Args:\n",
    "        path (str): La ruta del sistema de archivos donde el directorio debe existir o ser creado.\n",
    "    Returns:\n",
    "        bool: True si el directorio existe o fue creado exitosamente, False si ocurrió un error.\n",
    "    Raises:\n",
    "        Imprime mensajes de error en consola pero no levanta excepciones.\n",
    "    Example:\n",
    "        >>> ensure_directory_exists(\"/ruta/al/nuevo/directorio\")\n",
    "        Directorio verificado/creado: /ruta/al/nuevo/directorio\n",
    "        True\n",
    "        >>> ensure_directory_exists(\"/ruta/invalida\")\n",
    "        Error creando directorio /ruta/invalida: [Errno 13] Permiso denegado\n",
    "        False\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        print(f\"Directorio verificado/creado: {path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error creando directorio {path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3982fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para analizar el balance de un datset\n",
    "def analyze_dataset_balance(dataset, name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Analiza y muestra el balance de clases de un dataset de clasificación binaria.\n",
    "    Esta función extrae las etiquetas de un dataset, cuenta las ocurrencias de cada clase,\n",
    "    e imprime estadísticas detalladas sobre la distribución de muestras normales vs anomalías.\n",
    "    Args:\n",
    "        dataset: Un dataset iterable donde cada elemento retorna una tupla de (datos, etiqueta, metadatos).\n",
    "                Se espera que la etiqueta esté en el índice 1 y sea convertible a int.\n",
    "        name (str, opcional): Nombre del dataset para propósitos de visualización. Por defecto \"Dataset\".\n",
    "    Returns:\n",
    "        Counter: Un objeto Counter que contiene el conteo de cada etiqueta de clase.\n",
    "                La clase 0 representa muestras normales, la clase 1 representa anomalías.\n",
    "    Imprime:\n",
    "        - Número total de muestras\n",
    "        - Conteo y porcentaje de muestras normales (clase 0)\n",
    "        - Conteo y porcentaje de muestras con anomalías (clase 1)  \n",
    "        - Proporción de muestras normales respecto a anomalías\n",
    "    Ejemplo:\n",
    "        >>> counts = analyze_dataset_balance(my_dataset, \"Conjunto de Entrenamiento\")\n",
    "         ANÁLISIS DE BALANCE - Conjunto de Entrenamiento\n",
    "           Total muestras: 1000\n",
    "           Normal: 800 (80.0%)\n",
    "           Anomalía: 200 (20.0%)\n",
    "           Ratio Normal:Anomalía = 1:0.25\n",
    "    \"\"\"\n",
    "\n",
    "    labels = []\n",
    "    for i in range(len(dataset)):\n",
    "        _, label, _ = dataset[i]\n",
    "        labels.append(int(label))\n",
    "  \n",
    "    class_counts = Counter(labels)\n",
    "    total = len(labels)\n",
    "  \n",
    "    print(f\"\\n ANÁLISIS DE BALANCE - {name}\")\n",
    "    print(f\"   Total muestras: {total}\")\n",
    "    print(f\"   Normal: {class_counts[0]} ({class_counts[0]/total*100:.1f}%)\")\n",
    "    print(f\"   Anomalía: {class_counts[1]} ({class_counts[1]/total*100:.1f}%)\")\n",
    "    print(f\"   Ratio Normal:Anomalía = 1:{class_counts[1]/class_counts[0]:.2f}\")\n",
    "    \n",
    "    return class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efda44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numpy_types(obj):\n",
    "    \"\"\"\n",
    "    Convierte recursivamente tipos de datos NumPy a tipos nativos de Python.\n",
    "    Esta función recorre estructuras de datos anidadas (diccionarios y listas)\n",
    "    y convierte tipos específicos de NumPy a sus tipos nativos de Python correspondientes\n",
    "    para mejorar la compatibilidad con la serialización JSON y otras operaciones.\n",
    "    Args:\n",
    "        obj: El objeto a convertir. Puede ser un diccionario, lista, array de NumPy,\n",
    "             escalar de NumPy, o cualquier otro tipo.\n",
    "    Returns:\n",
    "        El objeto convertido con tipos NumPy reemplazados por tipos nativos de Python:\n",
    "        - np.integer -> int\n",
    "        - np.floating -> float  \n",
    "        - np.ndarray -> list\n",
    "        - Los diccionarios y listas se procesan recursivamente\n",
    "        - Otros tipos se devuelven sin cambios\n",
    "    Examples:\n",
    "        >>> import numpy as np\n",
    "        >>> data = {'array': np.array([1, 2, 3]), 'value': np.int64(42)}\n",
    "        >>> convert_numpy_types(data)\n",
    "        {'array': [1, 2, 3], 'value': 42}\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_types(item) for item in obj]\n",
    "    elif isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237edd4",
   "metadata": {},
   "source": [
    "### Cuerpo principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce226cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables de configuración\n",
    "data_path = 'data/'  # Ruta al dataset MVTec AD\n",
    "output_dir = 'models/'  # Ruta para guardar el modelo entrenado\n",
    "reports_path = 'reports/'  # Ruta para guardar los reportes e imágenes\n",
    "logs_dir = 'logs/' # Directorio de logs para tensorboard\n",
    "\n",
    "# Lista de todas las categorías en MVTec AD\n",
    "categories = [\n",
    "    \"bottle\",\n",
    "    \"cable\",\n",
    "    \"capsule\",\n",
    "    \"carpet\",\n",
    "    \"grid\",\n",
    "    \"hazelnut\",\n",
    "    \"leather\",\n",
    "    \"metal_nut\",\n",
    "    \"pill\",\n",
    "    \"screw\",\n",
    "    \"tile\",\n",
    "    \"toothbrush\",\n",
    "    \"transistor\",\n",
    "    \"wood\",\n",
    "    \"zipper\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82f5b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorios de salida en caso de que no existan\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(reports_path, exist_ok=True)\n",
    "os.makedirs(logs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f3276bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7cf041b99890>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Semilla para reproducibilidad de los experimentos\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cb162b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# Si tenemos disponible GPU, lo usamos\n",
    "# Chequeamos si tenemos disponible GPU (CUDA)\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# Chequeamos si tenemos disponible aceleración por hardware en un chip de Apple (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "# Por defecto usamos CPU\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\" Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "573cf6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir transformaciones\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Transformación para máscaras (sin normalización)\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6323f8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CARGANDO DATASETS MVTec AD\n",
      "============================================================\n",
      "bottle       | Train: 209 | Test:  83\n",
      "cable        | Train: 224 | Test: 150\n",
      "capsule      | Train: 219 | Test: 132\n",
      "carpet       | Train: 280 | Test: 117\n",
      "grid         | Train: 264 | Test:  78\n",
      "hazelnut     | Train: 391 | Test: 110\n",
      "leather      | Train: 245 | Test: 124\n",
      "metal_nut    | Train: 220 | Test: 115\n",
      "pill         | Train: 267 | Test: 167\n",
      "screw        | Train: 320 | Test: 160\n",
      "tile         | Train: 230 | Test: 117\n",
      "toothbrush   | Train:  60 | Test:  42\n",
      "transistor   | Train: 213 | Test: 100\n",
      "wood         | Train: 247 | Test:  79\n",
      "zipper       | Train: 240 | Test: 151\n"
     ]
    }
   ],
   "source": [
    "# Crear Datasets\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CARGANDO DATASETS MVTec AD\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear datasets para todas las categorías\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for category in categories:\n",
    "    try:\n",
    "        train_dataset = MVTecDataset(\n",
    "            root_path=data_path,\n",
    "            category=category,\n",
    "            is_train=True,\n",
    "            transform=train_transform,\n",
    "            mask_transform=mask_transform\n",
    "        )\n",
    "\n",
    "        test_dataset = MVTecDataset(\n",
    "            root_path=data_path,\n",
    "            category=category,\n",
    "            is_train=False,\n",
    "            transform=test_transform,\n",
    "            mask_transform=mask_transform\n",
    "        )\n",
    "                \n",
    "        train_datasets.append(train_dataset)\n",
    "        test_datasets.append(test_dataset)\n",
    "        print(f\"{category:12} | Train: {len(train_dataset):3} | Test: {len(test_dataset):3}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error al cargar la categoría {category}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78014831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DIVISIÓN DE DATASETS DE TEST\n",
      "============================================================\n",
      "bottle       | Total:  83 | Normal:  20 | Anomalía:  63 | Val:  41 | Test:  42\n",
      "cable        | Total: 150 | Normal:  58 | Anomalía:  92 | Val:  75 | Test:  75\n",
      "capsule      | Total: 132 | Normal:  23 | Anomalía: 109 | Val:  66 | Test:  66\n",
      "carpet       | Total: 117 | Normal:  28 | Anomalía:  89 | Val:  58 | Test:  59\n",
      "grid         | Total:  78 | Normal:  21 | Anomalía:  57 | Val:  39 | Test:  39\n",
      "hazelnut     | Total: 110 | Normal:  40 | Anomalía:  70 | Val:  55 | Test:  55\n",
      "leather      | Total: 124 | Normal:  32 | Anomalía:  92 | Val:  62 | Test:  62\n",
      "metal_nut    | Total: 115 | Normal:  22 | Anomalía:  93 | Val:  57 | Test:  58\n",
      "pill         | Total: 167 | Normal:  26 | Anomalía: 141 | Val:  83 | Test:  84\n",
      "screw        | Total: 160 | Normal:  41 | Anomalía: 119 | Val:  80 | Test:  80\n",
      "tile         | Total: 117 | Normal:  33 | Anomalía:  84 | Val:  58 | Test:  59\n",
      "toothbrush   | Total:  42 | Normal:  12 | Anomalía:  30 | Val:  21 | Test:  21\n",
      "transistor   | Total: 100 | Normal:  60 | Anomalía:  40 | Val:  50 | Test:  50\n",
      "wood         | Total:  79 | Normal:  19 | Anomalía:  60 | Val:  39 | Test:  40\n",
      "zipper       | Total: 151 | Normal:  32 | Anomalía: 119 | Val:  75 | Test:  76\n",
      "============================================================\n",
      "\n",
      " RESUMEN DE DATASETS:\n",
      "   Entrenamiento: 3629 imágenes\n",
      "   Validación:     859 imágenes\n",
      "   Test final:     866 imágenes\n",
      "   Total:         5354 imágenes\n"
     ]
    }
   ],
   "source": [
    "# Dividir datasets de test en validación y test final\n",
    "val_datasets, final_test_datasets = split_test_datasets(test_datasets, categories, test_size=0.5)\n",
    "\n",
    "# Combinar datasets\n",
    "train_dataset = ConcatDataset(train_datasets)  # Unir todos los datasets de entrenamiento\n",
    "val_dataset = ConcatDataset(val_datasets)      # Unir todos los datasets de validación\n",
    "final_test_dataset = ConcatDataset(final_test_datasets)  # Unir todos los datasets de test final\n",
    "\n",
    "print(f\"\\n RESUMEN DE DATASETS:\")\n",
    "print(f\"   Entrenamiento: {len(train_dataset):4} imágenes\")\n",
    "print(f\"   Validación:    {len(val_dataset):4} imágenes\")\n",
    "print(f\"   Test final:    {len(final_test_dataset):4} imágenes\")\n",
    "print(f\"   Total:         {len(train_dataset) + len(val_dataset) + len(final_test_dataset):4} imágenes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a0962b",
   "metadata": {},
   "source": [
    "#### Analizamos el balanceo de los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f07cda72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ANÁLISIS DE BALANCE - Validación ANTES\n",
      "   Total muestras: 859\n",
      "   Normal: 231 (26.9%)\n",
      "   Anomalía: 628 (73.1%)\n",
      "   Ratio Normal:Anomalía = 1:2.72\n",
      "\n",
      " ANÁLISIS DE BALANCE - Test ANTES\n",
      "   Total muestras: 866\n",
      "   Normal: 236 (27.3%)\n",
      "   Anomalía: 630 (72.7%)\n",
      "   Ratio Normal:Anomalía = 1:2.67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({1: 630, 0: 236})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a analizar como se encuentran balanceados los datasets\n",
    "analyze_dataset_balance(val_dataset, \"Validación ANTES\")\n",
    "analyze_dataset_balance(final_test_dataset, \"Test ANTES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a47d8",
   "metadata": {},
   "source": [
    "#### Balanceamos los datasets y creamos los dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e29b5445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CREANDO DATALOADERS BALANCEADOS...\n",
      "============================================================\n",
      " TRAIN LOADER (Sin balancear - normal para autoencoders)\n",
      "   Tamaño: 3629 muestras\n",
      "\n",
      " VALIDATION LOADER (Balanceado)\n",
      "   Distribución original: Normal=231, Anomalía=628\n",
      "   Método: Weighted Sampling\n",
      "   Pesos: Normal=1.859, Anomalía=0.684\n",
      "\n",
      " FINAL TEST LOADER (Balanceado)\n",
      "   Distribución original: Normal=236, Anomalía=630\n",
      "   Método: Weighted Sampling\n",
      "   Pesos: Normal=1.835, Anomalía=0.687\n",
      "\n",
      " DataLoaders balanceados creados con batch_size=16\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Defino el tamaño de los lotes\n",
    "batch_size = 16 # Tamaño de los lotes, mas grande requiere mas VRAM o RAM\n",
    "\n",
    "print(f\"\\n CREANDO DATALOADERS BALANCEADOS...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ENTRENAMIMENTO: Para autoencoders, generalmente NO se balancea\n",
    "# porque se entrenan principalmente con datos normales\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=8\n",
    ")\n",
    "print(f\" TRAIN LOADER (Sin balancear - normal para autoencoders)\")\n",
    "print(f\"   Tamaño: {len(train_dataset)} muestras\")\n",
    "\n",
    "# VALIDACIÓN: Balancear para evaluación justa\n",
    "print(f\"\\n VALIDATION LOADER (Balanceado)\")\n",
    "val_loader = crear_dataloader_balanceado(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    method='weighted',  # Opciones: 'weighted', 'oversample', 'undersample'\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "#TEST FINAL: Balancear para evaluación final justa  \n",
    "print(f\"\\n FINAL TEST LOADER (Balanceado)\")\n",
    "final_test_loader = crear_dataloader_balanceado(\n",
    "    final_test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    method='weighted',  # Usar el mismo método que validación\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "print(f\"\\n DataLoaders balanceados creados con batch_size={batch_size}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e77422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFIGURACIÓN DEL MODELO:\n",
      "   Tipo:          Autoencoder con Swin Transformer\n",
      "   Pre-entrenado: True\n",
      "   Learning rate: 2e-05\n",
      "   Weight decay:  0.0005\n",
      "   Batch size:    16\n",
      "   Device:        cuda\n",
      "   Modelo:        SwinTransformerAutoencoder_2\n",
      "   Épocas:        200\n",
      "   Categorías:    TODAS (15 categorías combinadas)\n"
     ]
    }
   ],
   "source": [
    "# Configuración del modelo\n",
    "\n",
    "model_name = \"SwinTransformerAutoencoder_2\" # Nombre para el modelo asi se guarda en el output_dir y # en los logs\n",
    "\n",
    "pretrained = True # Usar pre-entrenado\n",
    "lr = 2e-5 # Learning rate para el optimizador\n",
    "wd = 5e-4 # Weight decay para regularización\n",
    "num_epochs = 200 # Número de épocas para entrenamiento\n",
    "\n",
    "print(f\"\\n CONFIGURACIÓN DEL MODELO:\")\n",
    "print(f\"   Tipo:          Autoencoder con Swin Transformer\")\n",
    "print(f\"   Pre-entrenado: {pretrained}\")\n",
    "print(f\"   Learning rate: {lr}\")\n",
    "print(f\"   Weight decay:  {wd}\")\n",
    "print(f\"   Batch size:    {batch_size}\")\n",
    "print(f\"   Device:        {device}\")\n",
    "print(f\"   Modelo:        {model_name}\")\n",
    "print(f\"   Épocas:        {num_epochs}\")\n",
    "print(f\"   Categorías:    TODAS ({len(categories)} categorías combinadas)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05728912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Antes de entrenar lanzamos tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./logs --host 0.0.0.0 --port 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ddf219",
   "metadata": {},
   "source": [
    "### Para acceder a tensorboard:\n",
    "\n",
    "http://localhost:6006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7626f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo\n",
    "model = SwinTransformerAutoencoder(pretrained=pretrained).to(device)\n",
    "\n",
    "criterion = CombinedReconstructionLoss(\n",
    "    mse_weight=0.3, # 0.4,\n",
    "    ssim_weight=0.8,    # 0.5,\n",
    "    l1_weight=0.2  #0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2af6a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizador y scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd) # AdamW es una variante de Adam con decaimiento de peso\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=5) # Reduce el learning rate si la métrica no mejora\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63891bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " INICIANDO ENTRENAMIENTO DEL MODELO ...\n",
      "============================================================\n",
      "\n",
      " INICIANDO ENTRENAMIENTO\n",
      "   Épocas: 200\n",
      "   Función de pérdida: MSE + SSIM + L1\n",
      "   Dispositivo: cuda\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 (train): 100%|██████████| 227/227 [00:27<00:00,  8.32it/s]\n",
      "Epoch 1/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Nuevo mejor modelo guardado! AUC: 0.5016\n",
      "\n",
      "Epoch 1/200:\n",
      "   Train Loss:\n",
      "     Total: 1.5265 | MSE: 1.7632 | SSIM: 0.9587 | L1: 1.1527\n",
      "   Val Loss:\n",
      "     Total: 1.5125 | MSE: 1.7382 | SSIM: 0.9529 | L1: 1.1437\n",
      "   ROC AUC (Combined Scoring): 0.5016 | Best: 0.5016\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.48it/s]\n",
      "Epoch 2/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 1/201\n",
      "\n",
      "Epoch 2/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4970 | MSE: 1.7202 | SSIM: 0.9422 | L1: 1.1360\n",
      "   Val Loss:\n",
      "     Total: 1.4675 | MSE: 1.6463 | SSIM: 0.9414 | L1: 1.1027\n",
      "   ROC AUC (Combined Scoring): 0.4760 | Best: 0.5016\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 3/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 2/201\n",
      "\n",
      "Epoch 3/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4867 | MSE: 1.7016 | SSIM: 0.9382 | L1: 1.1282\n",
      "   Val Loss:\n",
      "     Total: 1.4520 | MSE: 1.6139 | SSIM: 0.9353 | L1: 1.0982\n",
      "   ROC AUC (Combined Scoring): 0.4823 | Best: 0.5016\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.44it/s]\n",
      "Epoch 4/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 3/201\n",
      "\n",
      "Epoch 4/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4797 | MSE: 1.6889 | SSIM: 0.9353 | L1: 1.1242\n",
      "   Val Loss:\n",
      "     Total: 1.4641 | MSE: 1.6395 | SSIM: 0.9406 | L1: 1.0991\n",
      "   ROC AUC (Combined Scoring): 0.4771 | Best: 0.5016\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.47it/s]\n",
      "Epoch 5/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 4/201\n",
      "\n",
      "Epoch 5/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4750 | MSE: 1.6801 | SSIM: 0.9335 | L1: 1.1208\n",
      "   Val Loss:\n",
      "     Total: 1.4329 | MSE: 1.6060 | SSIM: 0.9170 | L1: 1.0876\n",
      "   ROC AUC (Combined Scoring): 0.4880 | Best: 0.5016\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 6/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Nuevo mejor modelo guardado! AUC: 0.5335\n",
      "\n",
      "Epoch 6/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4718 | MSE: 1.6757 | SSIM: 0.9315 | L1: 1.1195\n",
      "   Val Loss:\n",
      "     Total: 1.4338 | MSE: 1.6154 | SSIM: 0.9146 | L1: 1.0876\n",
      "   ROC AUC (Combined Scoring): 0.5335 | Best: 0.5335\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.49it/s]\n",
      "Epoch 7/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 1/201\n",
      "\n",
      "Epoch 7/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4627 | MSE: 1.6591 | SSIM: 0.9282 | L1: 1.1122\n",
      "   Val Loss:\n",
      "     Total: 1.4445 | MSE: 1.6350 | SSIM: 0.9165 | L1: 1.1037\n",
      "   ROC AUC (Combined Scoring): 0.4782 | Best: 0.5335\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.46it/s]\n",
      "Epoch 8/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 2/201\n",
      "\n",
      "Epoch 8/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4584 | MSE: 1.6552 | SSIM: 0.9247 | L1: 1.1105\n",
      "   Val Loss:\n",
      "     Total: 1.4158 | MSE: 1.5503 | SSIM: 0.9225 | L1: 1.0639\n",
      "   ROC AUC (Combined Scoring): 0.4684 | Best: 0.5335\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.57it/s]\n",
      "Epoch 9/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 3/201\n",
      "\n",
      "Epoch 9/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4533 | MSE: 1.6496 | SSIM: 0.9208 | L1: 1.1090\n",
      "   Val Loss:\n",
      "     Total: 1.4192 | MSE: 1.5889 | SSIM: 0.9087 | L1: 1.0782\n",
      "   ROC AUC (Combined Scoring): 0.5139 | Best: 0.5335\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200 (train): 100%|██████████| 227/227 [00:27<00:00,  8.38it/s]\n",
      "Epoch 10/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 4/201\n",
      "\n",
      "Epoch 10/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4448 | MSE: 1.6358 | SSIM: 0.9167 | L1: 1.1031\n",
      "   Val Loss:\n",
      "     Total: 1.4388 | MSE: 1.6249 | SSIM: 0.9149 | L1: 1.0973\n",
      "   ROC AUC (Combined Scoring): 0.5185 | Best: 0.5335\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200 (train): 100%|██████████| 227/227 [00:27<00:00,  8.31it/s]\n",
      "Epoch 11/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 5/201\n",
      "\n",
      "Epoch 11/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4416 | MSE: 1.6331 | SSIM: 0.9141 | L1: 1.1019\n",
      "   Val Loss:\n",
      "     Total: 1.3935 | MSE: 1.5503 | SSIM: 0.8943 | L1: 1.0650\n",
      "   ROC AUC (Combined Scoring): 0.5212 | Best: 0.5335\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 12/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 6/201\n",
      "\n",
      "Epoch 12/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4360 | MSE: 1.6250 | SSIM: 0.9109 | L1: 1.0987\n",
      "   Val Loss:\n",
      "     Total: 1.3925 | MSE: 1.5468 | SSIM: 0.8945 | L1: 1.0645\n",
      "   ROC AUC (Combined Scoring): 0.4992 | Best: 0.5335\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 13/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 7/201\n",
      "\n",
      "Epoch 13/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4290 | MSE: 1.6123 | SSIM: 0.9080 | L1: 1.0944\n",
      "   Val Loss:\n",
      "     Total: 1.4104 | MSE: 1.5929 | SSIM: 0.8951 | L1: 1.0823\n",
      "   ROC AUC (Combined Scoring): 0.4692 | Best: 0.5335\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200 (train): 100%|██████████| 227/227 [00:27<00:00,  8.40it/s]\n",
      "Epoch 14/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 8/201\n",
      "\n",
      "Epoch 14/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4241 | MSE: 1.6040 | SSIM: 0.9059 | L1: 1.0912\n",
      "   Val Loss:\n",
      "     Total: 1.3849 | MSE: 1.5166 | SSIM: 0.8996 | L1: 1.0509\n",
      "   ROC AUC (Combined Scoring): 0.4861 | Best: 0.5335\n",
      "   Learning Rate: 2.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 15/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 9/201\n",
      "\n",
      "Epoch 15/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4160 | MSE: 1.5898 | SSIM: 0.9028 | L1: 1.0843\n",
      "   Val Loss:\n",
      "     Total: 1.3537 | MSE: 1.4671 | SSIM: 0.8842 | L1: 1.0310\n",
      "   ROC AUC (Combined Scoring): 0.5021 | Best: 0.5335\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.46it/s]\n",
      "Epoch 16/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 10/201\n",
      "\n",
      "Epoch 16/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4158 | MSE: 1.5898 | SSIM: 0.9022 | L1: 1.0852\n",
      "   Val Loss:\n",
      "     Total: 1.3483 | MSE: 1.4631 | SSIM: 0.8790 | L1: 1.0308\n",
      "   ROC AUC (Combined Scoring): 0.4927 | Best: 0.5335\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200 (train): 100%|██████████| 227/227 [00:27<00:00,  8.31it/s]\n",
      "Epoch 17/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 11/201\n",
      "\n",
      "Epoch 17/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4145 | MSE: 1.5882 | SSIM: 0.9014 | L1: 1.0848\n",
      "   Val Loss:\n",
      "     Total: 1.3842 | MSE: 1.5143 | SSIM: 0.8985 | L1: 1.0556\n",
      "   ROC AUC (Combined Scoring): 0.4894 | Best: 0.5335\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200 (train): 100%|██████████| 227/227 [00:27<00:00,  8.39it/s]\n",
      "Epoch 18/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 12/201\n",
      "\n",
      "Epoch 18/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4096 | MSE: 1.5789 | SSIM: 0.8997 | L1: 1.0807\n",
      "   Val Loss:\n",
      "     Total: 1.3791 | MSE: 1.5166 | SSIM: 0.8923 | L1: 1.0515\n",
      "   ROC AUC (Combined Scoring): 0.4864 | Best: 0.5335\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 19/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Nuevo mejor modelo guardado! AUC: 0.5402\n",
      "\n",
      "Epoch 19/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4072 | MSE: 1.5755 | SSIM: 0.8985 | L1: 1.0787\n",
      "   Val Loss:\n",
      "     Total: 1.3833 | MSE: 1.5455 | SSIM: 0.8850 | L1: 1.0582\n",
      "   ROC AUC (Combined Scoring): 0.5402 | Best: 0.5402\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.72it/s]\n",
      "Epoch 20/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 1/201\n",
      "\n",
      "Epoch 20/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4082 | MSE: 1.5774 | SSIM: 0.8985 | L1: 1.0809\n",
      "   Val Loss:\n",
      "     Total: 1.3561 | MSE: 1.4873 | SSIM: 0.8778 | L1: 1.0384\n",
      "   ROC AUC (Combined Scoring): 0.5011 | Best: 0.5402\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200 (train): 100%|██████████| 227/227 [00:27<00:00,  8.29it/s]\n",
      "Epoch 21/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 2/201\n",
      "\n",
      "Epoch 21/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4051 | MSE: 1.5711 | SSIM: 0.8976 | L1: 1.0785\n",
      "   Val Loss:\n",
      "     Total: 1.3596 | MSE: 1.4999 | SSIM: 0.8751 | L1: 1.0481\n",
      "   ROC AUC (Combined Scoring): 0.4856 | Best: 0.5402\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 22/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 3/201\n",
      "\n",
      "Epoch 22/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4000 | MSE: 1.5607 | SSIM: 0.8963 | L1: 1.0737\n",
      "   Val Loss:\n",
      "     Total: 1.3862 | MSE: 1.5381 | SSIM: 0.8917 | L1: 1.0570\n",
      "   ROC AUC (Combined Scoring): 0.5164 | Best: 0.5402\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 23/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 4/201\n",
      "\n",
      "Epoch 23/200:\n",
      "   Train Loss:\n",
      "     Total: 1.4003 | MSE: 1.5638 | SSIM: 0.8952 | L1: 1.0751\n",
      "   Val Loss:\n",
      "     Total: 1.3339 | MSE: 1.4231 | SSIM: 0.8796 | L1: 1.0167\n",
      "   ROC AUC (Combined Scoring): 0.4807 | Best: 0.5402\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.45it/s]\n",
      "Epoch 24/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 5/201\n",
      "\n",
      "Epoch 24/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3959 | MSE: 1.5529 | SSIM: 0.8949 | L1: 1.0708\n",
      "   Val Loss:\n",
      "     Total: 1.3431 | MSE: 1.4531 | SSIM: 0.8775 | L1: 1.0259\n",
      "   ROC AUC (Combined Scoring): 0.5060 | Best: 0.5402\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 25/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 6/201\n",
      "\n",
      "Epoch 25/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3946 | MSE: 1.5522 | SSIM: 0.8934 | L1: 1.0709\n",
      "   Val Loss:\n",
      "     Total: 1.3329 | MSE: 1.4161 | SSIM: 0.8818 | L1: 1.0131\n",
      "   ROC AUC (Combined Scoring): 0.4896 | Best: 0.5402\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 26/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 7/201\n",
      "\n",
      "Epoch 26/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3933 | MSE: 1.5495 | SSIM: 0.8930 | L1: 1.0702\n",
      "   Val Loss:\n",
      "     Total: 1.3437 | MSE: 1.4600 | SSIM: 0.8756 | L1: 1.0259\n",
      "   ROC AUC (Combined Scoring): 0.4829 | Best: 0.5402\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 27/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 8/201\n",
      "\n",
      "Epoch 27/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3894 | MSE: 1.5410 | SSIM: 0.8924 | L1: 1.0661\n",
      "   Val Loss:\n",
      "     Total: 1.3530 | MSE: 1.4875 | SSIM: 0.8730 | L1: 1.0418\n",
      "   ROC AUC (Combined Scoring): 0.4921 | Best: 0.5402\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 28/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 9/201\n",
      "\n",
      "Epoch 28/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3873 | MSE: 1.5393 | SSIM: 0.8907 | L1: 1.0646\n",
      "   Val Loss:\n",
      "     Total: 1.3303 | MSE: 1.4356 | SSIM: 0.8696 | L1: 1.0196\n",
      "   ROC AUC (Combined Scoring): 0.4852 | Best: 0.5402\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.55it/s]\n",
      "Epoch 29/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 10/201\n",
      "\n",
      "Epoch 29/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3834 | MSE: 1.5293 | SSIM: 0.8904 | L1: 1.0616\n",
      "   Val Loss:\n",
      "     Total: 1.3295 | MSE: 1.4313 | SSIM: 0.8705 | L1: 1.0182\n",
      "   ROC AUC (Combined Scoring): 0.5240 | Best: 0.5402\n",
      "   Learning Rate: 1.00e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 30/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 11/201\n",
      "\n",
      "Epoch 30/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3807 | MSE: 1.5239 | SSIM: 0.8896 | L1: 1.0594\n",
      "   Val Loss:\n",
      "     Total: 1.3660 | MSE: 1.4926 | SSIM: 0.8855 | L1: 1.0490\n",
      "   ROC AUC (Combined Scoring): 0.4885 | Best: 0.5402\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.58it/s]\n",
      "Epoch 31/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 12/201\n",
      "\n",
      "Epoch 31/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3804 | MSE: 1.5248 | SSIM: 0.8889 | L1: 1.0594\n",
      "   Val Loss:\n",
      "     Total: 1.3475 | MSE: 1.4838 | SSIM: 0.8693 | L1: 1.0348\n",
      "   ROC AUC (Combined Scoring): 0.5074 | Best: 0.5402\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.55it/s]\n",
      "Epoch 32/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 13/201\n",
      "\n",
      "Epoch 32/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3793 | MSE: 1.5215 | SSIM: 0.8889 | L1: 1.0583\n",
      "   Val Loss:\n",
      "     Total: 1.3531 | MSE: 1.4739 | SSIM: 0.8799 | L1: 1.0352\n",
      "   ROC AUC (Combined Scoring): 0.5139 | Best: 0.5402\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 33/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 14/201\n",
      "\n",
      "Epoch 33/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3797 | MSE: 1.5223 | SSIM: 0.8890 | L1: 1.0588\n",
      "   Val Loss:\n",
      "     Total: 1.3122 | MSE: 1.3902 | SSIM: 0.8690 | L1: 0.9995\n",
      "   ROC AUC (Combined Scoring): 0.5100 | Best: 0.5402\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 34/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Nuevo mejor modelo guardado! AUC: 0.5449\n",
      "\n",
      "Epoch 34/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3770 | MSE: 1.5171 | SSIM: 0.8882 | L1: 1.0566\n",
      "   Val Loss:\n",
      "     Total: 1.3196 | MSE: 1.4215 | SSIM: 0.8632 | L1: 1.0130\n",
      "   ROC AUC (Combined Scoring): 0.5449 | Best: 0.5449\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 35/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 1/201\n",
      "\n",
      "Epoch 35/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3751 | MSE: 1.5150 | SSIM: 0.8870 | L1: 1.0551\n",
      "   Val Loss:\n",
      "     Total: 1.3552 | MSE: 1.5037 | SSIM: 0.8697 | L1: 1.0416\n",
      "   ROC AUC (Combined Scoring): 0.5181 | Best: 0.5449\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.60it/s]\n",
      "Epoch 36/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 2/201\n",
      "\n",
      "Epoch 36/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3754 | MSE: 1.5137 | SSIM: 0.8876 | L1: 1.0559\n",
      "   Val Loss:\n",
      "     Total: 1.3406 | MSE: 1.4606 | SSIM: 0.8713 | L1: 1.0268\n",
      "   ROC AUC (Combined Scoring): 0.5056 | Best: 0.5449\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 37/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 3/201\n",
      "\n",
      "Epoch 37/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3726 | MSE: 1.5088 | SSIM: 0.8868 | L1: 1.0528\n",
      "   Val Loss:\n",
      "     Total: 1.3327 | MSE: 1.4464 | SSIM: 0.8684 | L1: 1.0206\n",
      "   ROC AUC (Combined Scoring): 0.4874 | Best: 0.5449\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 38/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 4/201\n",
      "\n",
      "Epoch 38/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3728 | MSE: 1.5099 | SSIM: 0.8865 | L1: 1.0533\n",
      "   Val Loss:\n",
      "     Total: 1.3490 | MSE: 1.4738 | SSIM: 0.8738 | L1: 1.0395\n",
      "   ROC AUC (Combined Scoring): 0.4696 | Best: 0.5449\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 39/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 5/201\n",
      "\n",
      "Epoch 39/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3728 | MSE: 1.5089 | SSIM: 0.8867 | L1: 1.0538\n",
      "   Val Loss:\n",
      "     Total: 1.3308 | MSE: 1.4280 | SSIM: 0.8736 | L1: 1.0174\n",
      "   ROC AUC (Combined Scoring): 0.5053 | Best: 0.5449\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 40/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 6/201\n",
      "\n",
      "Epoch 40/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3695 | MSE: 1.5028 | SSIM: 0.8856 | L1: 1.0510\n",
      "   Val Loss:\n",
      "     Total: 1.3299 | MSE: 1.4163 | SSIM: 0.8783 | L1: 1.0119\n",
      "   ROC AUC (Combined Scoring): 0.5055 | Best: 0.5449\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 41/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 7/201\n",
      "\n",
      "Epoch 41/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3701 | MSE: 1.5019 | SSIM: 0.8865 | L1: 1.0516\n",
      "   Val Loss:\n",
      "     Total: 1.3294 | MSE: 1.4601 | SSIM: 0.8583 | L1: 1.0238\n",
      "   ROC AUC (Combined Scoring): 0.5113 | Best: 0.5449\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 42/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 8/201\n",
      "\n",
      "Epoch 42/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3672 | MSE: 1.4977 | SSIM: 0.8852 | L1: 1.0488\n",
      "   Val Loss:\n",
      "     Total: 1.3314 | MSE: 1.4335 | SSIM: 0.8729 | L1: 1.0154\n",
      "   ROC AUC (Combined Scoring): 0.4826 | Best: 0.5449\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 43/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 9/201\n",
      "\n",
      "Epoch 43/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3676 | MSE: 1.4987 | SSIM: 0.8853 | L1: 1.0489\n",
      "   Val Loss:\n",
      "     Total: 1.3451 | MSE: 1.4835 | SSIM: 0.8659 | L1: 1.0364\n",
      "   ROC AUC (Combined Scoring): 0.4822 | Best: 0.5449\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 44/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 10/201\n",
      "\n",
      "Epoch 44/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3646 | MSE: 1.4928 | SSIM: 0.8844 | L1: 1.0461\n",
      "   Val Loss:\n",
      "     Total: 1.3541 | MSE: 1.4863 | SSIM: 0.8759 | L1: 1.0374\n",
      "   ROC AUC (Combined Scoring): 0.5034 | Best: 0.5449\n",
      "   Learning Rate: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.60it/s]\n",
      "Epoch 45/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 11/201\n",
      "\n",
      "Epoch 45/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3647 | MSE: 1.4932 | SSIM: 0.8842 | L1: 1.0470\n",
      "   Val Loss:\n",
      "     Total: 1.3235 | MSE: 1.4204 | SSIM: 0.8693 | L1: 1.0098\n",
      "   ROC AUC (Combined Scoring): 0.4936 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 46/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 12/201\n",
      "\n",
      "Epoch 46/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3660 | MSE: 1.4957 | SSIM: 0.8845 | L1: 1.0486\n",
      "   Val Loss:\n",
      "     Total: 1.3023 | MSE: 1.3813 | SSIM: 0.8599 | L1: 0.9999\n",
      "   ROC AUC (Combined Scoring): 0.4721 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 47/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 13/201\n",
      "\n",
      "Epoch 47/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3629 | MSE: 1.4890 | SSIM: 0.8839 | L1: 1.0454\n",
      "   Val Loss:\n",
      "     Total: 1.3157 | MSE: 1.4006 | SSIM: 0.8686 | L1: 1.0033\n",
      "   ROC AUC (Combined Scoring): 0.4952 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.57it/s]\n",
      "Epoch 48/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 14/201\n",
      "\n",
      "Epoch 48/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3628 | MSE: 1.4896 | SSIM: 0.8835 | L1: 1.0455\n",
      "   Val Loss:\n",
      "     Total: 1.3330 | MSE: 1.4472 | SSIM: 0.8678 | L1: 1.0227\n",
      "   ROC AUC (Combined Scoring): 0.4745 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 49/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 15/201\n",
      "\n",
      "Epoch 49/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3609 | MSE: 1.4871 | SSIM: 0.8826 | L1: 1.0436\n",
      "   Val Loss:\n",
      "     Total: 1.3110 | MSE: 1.3788 | SSIM: 0.8716 | L1: 1.0004\n",
      "   ROC AUC (Combined Scoring): 0.4924 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.59it/s]\n",
      "Epoch 50/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 16/201\n",
      "\n",
      "Epoch 50/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3622 | MSE: 1.4878 | SSIM: 0.8834 | L1: 1.0457\n",
      "   Val Loss:\n",
      "     Total: 1.3223 | MSE: 1.4235 | SSIM: 0.8655 | L1: 1.0140\n",
      "   ROC AUC (Combined Scoring): 0.4823 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 51/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 17/201\n",
      "\n",
      "Epoch 51/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3616 | MSE: 1.4878 | SSIM: 0.8828 | L1: 1.0450\n",
      "   Val Loss:\n",
      "     Total: 1.3335 | MSE: 1.4304 | SSIM: 0.8746 | L1: 1.0234\n",
      "   ROC AUC (Combined Scoring): 0.4699 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 52/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 18/201\n",
      "\n",
      "Epoch 52/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3614 | MSE: 1.4861 | SSIM: 0.8834 | L1: 1.0445\n",
      "   Val Loss:\n",
      "     Total: 1.3145 | MSE: 1.4075 | SSIM: 0.8636 | L1: 1.0068\n",
      "   ROC AUC (Combined Scoring): 0.5159 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 53/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 19/201\n",
      "\n",
      "Epoch 53/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3618 | MSE: 1.4882 | SSIM: 0.8830 | L1: 1.0446\n",
      "   Val Loss:\n",
      "     Total: 1.3365 | MSE: 1.4472 | SSIM: 0.8725 | L1: 1.0219\n",
      "   ROC AUC (Combined Scoring): 0.5049 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 54/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 20/201\n",
      "\n",
      "Epoch 54/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3580 | MSE: 1.4800 | SSIM: 0.8821 | L1: 1.0413\n",
      "   Val Loss:\n",
      "     Total: 1.3177 | MSE: 1.4172 | SSIM: 0.8640 | L1: 1.0067\n",
      "   ROC AUC (Combined Scoring): 0.4929 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 55/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 21/201\n",
      "\n",
      "Epoch 55/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3577 | MSE: 1.4800 | SSIM: 0.8819 | L1: 1.0407\n",
      "   Val Loss:\n",
      "     Total: 1.3350 | MSE: 1.4465 | SSIM: 0.8702 | L1: 1.0249\n",
      "   ROC AUC (Combined Scoring): 0.5256 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 56/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 22/201\n",
      "\n",
      "Epoch 56/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3585 | MSE: 1.4801 | SSIM: 0.8826 | L1: 1.0423\n",
      "   Val Loss:\n",
      "     Total: 1.3235 | MSE: 1.4280 | SSIM: 0.8642 | L1: 1.0188\n",
      "   ROC AUC (Combined Scoring): 0.4890 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.55it/s]\n",
      "Epoch 57/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 23/201\n",
      "\n",
      "Epoch 57/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3566 | MSE: 1.4764 | SSIM: 0.8820 | L1: 1.0404\n",
      "   Val Loss:\n",
      "     Total: 1.3059 | MSE: 1.3963 | SSIM: 0.8577 | L1: 1.0041\n",
      "   ROC AUC (Combined Scoring): 0.5266 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.55it/s]\n",
      "Epoch 58/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 24/201\n",
      "\n",
      "Epoch 58/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3577 | MSE: 1.4785 | SSIM: 0.8823 | L1: 1.0417\n",
      "   Val Loss:\n",
      "     Total: 1.3064 | MSE: 1.3886 | SSIM: 0.8624 | L1: 0.9993\n",
      "   ROC AUC (Combined Scoring): 0.5236 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 59/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 25/201\n",
      "\n",
      "Epoch 59/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3559 | MSE: 1.4757 | SSIM: 0.8816 | L1: 1.0395\n",
      "   Val Loss:\n",
      "     Total: 1.3398 | MSE: 1.4388 | SSIM: 0.8795 | L1: 1.0227\n",
      "   ROC AUC (Combined Scoring): 0.4696 | Best: 0.5449\n",
      "   Learning Rate: 2.50e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 60/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 26/201\n",
      "\n",
      "Epoch 60/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3566 | MSE: 1.4760 | SSIM: 0.8821 | L1: 1.0406\n",
      "   Val Loss:\n",
      "     Total: 1.3190 | MSE: 1.4151 | SSIM: 0.8656 | L1: 1.0097\n",
      "   ROC AUC (Combined Scoring): 0.4960 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 61/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 27/201\n",
      "\n",
      "Epoch 61/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3570 | MSE: 1.4780 | SSIM: 0.8817 | L1: 1.0411\n",
      "   Val Loss:\n",
      "     Total: 1.3222 | MSE: 1.4168 | SSIM: 0.8684 | L1: 1.0122\n",
      "   ROC AUC (Combined Scoring): 0.4537 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 62/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 28/201\n",
      "\n",
      "Epoch 62/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3541 | MSE: 1.4724 | SSIM: 0.8809 | L1: 1.0381\n",
      "   Val Loss:\n",
      "     Total: 1.3296 | MSE: 1.4405 | SSIM: 0.8663 | L1: 1.0219\n",
      "   ROC AUC (Combined Scoring): 0.4676 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.61it/s]\n",
      "Epoch 63/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 29/201\n",
      "\n",
      "Epoch 63/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3561 | MSE: 1.4766 | SSIM: 0.8812 | L1: 1.0407\n",
      "   Val Loss:\n",
      "     Total: 1.3143 | MSE: 1.3873 | SSIM: 0.8727 | L1: 0.9993\n",
      "   ROC AUC (Combined Scoring): 0.4919 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.55it/s]\n",
      "Epoch 64/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 30/201\n",
      "\n",
      "Epoch 64/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3559 | MSE: 1.4760 | SSIM: 0.8813 | L1: 1.0405\n",
      "   Val Loss:\n",
      "     Total: 1.3179 | MSE: 1.3944 | SSIM: 0.8735 | L1: 1.0041\n",
      "   ROC AUC (Combined Scoring): 0.4953 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.49it/s]\n",
      "Epoch 65/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 31/201\n",
      "\n",
      "Epoch 65/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3573 | MSE: 1.4792 | SSIM: 0.8815 | L1: 1.0417\n",
      "   Val Loss:\n",
      "     Total: 1.2911 | MSE: 1.3525 | SSIM: 0.8600 | L1: 0.9864\n",
      "   ROC AUC (Combined Scoring): 0.4937 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.58it/s]\n",
      "Epoch 66/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 32/201\n",
      "\n",
      "Epoch 66/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3543 | MSE: 1.4735 | SSIM: 0.8806 | L1: 1.0387\n",
      "   Val Loss:\n",
      "     Total: 1.3281 | MSE: 1.4430 | SSIM: 0.8628 | L1: 1.0248\n",
      "   ROC AUC (Combined Scoring): 0.5215 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 67/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 33/201\n",
      "\n",
      "Epoch 67/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3547 | MSE: 1.4729 | SSIM: 0.8812 | L1: 1.0396\n",
      "   Val Loss:\n",
      "     Total: 1.3306 | MSE: 1.4453 | SSIM: 0.8651 | L1: 1.0245\n",
      "   ROC AUC (Combined Scoring): 0.4772 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 68/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 34/201\n",
      "\n",
      "Epoch 68/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3545 | MSE: 1.4731 | SSIM: 0.8810 | L1: 1.0390\n",
      "   Val Loss:\n",
      "     Total: 1.3225 | MSE: 1.4204 | SSIM: 0.8666 | L1: 1.0158\n",
      "   ROC AUC (Combined Scoring): 0.5199 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.56it/s]\n",
      "Epoch 69/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 35/201\n",
      "\n",
      "Epoch 69/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3546 | MSE: 1.4735 | SSIM: 0.8808 | L1: 1.0394\n",
      "   Val Loss:\n",
      "     Total: 1.2977 | MSE: 1.3794 | SSIM: 0.8568 | L1: 0.9924\n",
      "   ROC AUC (Combined Scoring): 0.4915 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 70/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 36/201\n",
      "\n",
      "Epoch 70/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3505 | MSE: 1.4644 | SSIM: 0.8801 | L1: 1.0352\n",
      "   Val Loss:\n",
      "     Total: 1.3318 | MSE: 1.4486 | SSIM: 0.8660 | L1: 1.0223\n",
      "   ROC AUC (Combined Scoring): 0.4756 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.49it/s]\n",
      "Epoch 71/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 37/201\n",
      "\n",
      "Epoch 71/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3554 | MSE: 1.4755 | SSIM: 0.8809 | L1: 1.0399\n",
      "   Val Loss:\n",
      "     Total: 1.3073 | MSE: 1.4022 | SSIM: 0.8574 | L1: 1.0037\n",
      "   ROC AUC (Combined Scoring): 0.4931 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.61it/s]\n",
      "Epoch 72/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 38/201\n",
      "\n",
      "Epoch 72/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3506 | MSE: 1.4650 | SSIM: 0.8802 | L1: 1.0348\n",
      "   Val Loss:\n",
      "     Total: 1.3188 | MSE: 1.4324 | SSIM: 0.8576 | L1: 1.0149\n",
      "   ROC AUC (Combined Scoring): 0.4846 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 73/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 39/201\n",
      "\n",
      "Epoch 73/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3510 | MSE: 1.4652 | SSIM: 0.8804 | L1: 1.0359\n",
      "   Val Loss:\n",
      "     Total: 1.3291 | MSE: 1.4495 | SSIM: 0.8613 | L1: 1.0257\n",
      "   ROC AUC (Combined Scoring): 0.4764 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 74/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 40/201\n",
      "\n",
      "Epoch 74/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3530 | MSE: 1.4699 | SSIM: 0.8805 | L1: 1.0382\n",
      "   Val Loss:\n",
      "     Total: 1.3065 | MSE: 1.3881 | SSIM: 0.8630 | L1: 0.9982\n",
      "   ROC AUC (Combined Scoring): 0.4654 | Best: 0.5449\n",
      "   Learning Rate: 1.25e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.58it/s]\n",
      "Epoch 75/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Nuevo mejor modelo guardado! AUC: 0.5480\n",
      "\n",
      "Epoch 75/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3518 | MSE: 1.4673 | SSIM: 0.8802 | L1: 1.0373\n",
      "   Val Loss:\n",
      "     Total: 1.3173 | MSE: 1.4240 | SSIM: 0.8599 | L1: 1.0110\n",
      "   ROC AUC (Combined Scoring): 0.5480 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 76/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 1/201\n",
      "\n",
      "Epoch 76/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3518 | MSE: 1.4688 | SSIM: 0.8798 | L1: 1.0369\n",
      "   Val Loss:\n",
      "     Total: 1.3207 | MSE: 1.4260 | SSIM: 0.8626 | L1: 1.0140\n",
      "   ROC AUC (Combined Scoring): 0.5057 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 77/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 2/201\n",
      "\n",
      "Epoch 77/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3528 | MSE: 1.4700 | SSIM: 0.8801 | L1: 1.0385\n",
      "   Val Loss:\n",
      "     Total: 1.3286 | MSE: 1.4303 | SSIM: 0.8681 | L1: 1.0251\n",
      "   ROC AUC (Combined Scoring): 0.5058 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 78/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 3/201\n",
      "\n",
      "Epoch 78/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3522 | MSE: 1.4693 | SSIM: 0.8798 | L1: 1.0380\n",
      "   Val Loss:\n",
      "     Total: 1.3039 | MSE: 1.4196 | SSIM: 0.8458 | L1: 1.0067\n",
      "   ROC AUC (Combined Scoring): 0.5012 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 79/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 4/201\n",
      "\n",
      "Epoch 79/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3516 | MSE: 1.4679 | SSIM: 0.8799 | L1: 1.0369\n",
      "   Val Loss:\n",
      "     Total: 1.3302 | MSE: 1.4367 | SSIM: 0.8701 | L1: 1.0154\n",
      "   ROC AUC (Combined Scoring): 0.5017 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 80/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 5/201\n",
      "\n",
      "Epoch 80/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3517 | MSE: 1.4677 | SSIM: 0.8800 | L1: 1.0368\n",
      "   Val Loss:\n",
      "     Total: 1.3096 | MSE: 1.4112 | SSIM: 0.8552 | L1: 1.0102\n",
      "   ROC AUC (Combined Scoring): 0.5155 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 81/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 6/201\n",
      "\n",
      "Epoch 81/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3534 | MSE: 1.4710 | SSIM: 0.8804 | L1: 1.0389\n",
      "   Val Loss:\n",
      "     Total: 1.3233 | MSE: 1.4384 | SSIM: 0.8607 | L1: 1.0159\n",
      "   ROC AUC (Combined Scoring): 0.4728 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.59it/s]\n",
      "Epoch 82/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 7/201\n",
      "\n",
      "Epoch 82/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3494 | MSE: 1.4630 | SSIM: 0.8794 | L1: 1.0350\n",
      "   Val Loss:\n",
      "     Total: 1.3089 | MSE: 1.4030 | SSIM: 0.8581 | L1: 1.0077\n",
      "   ROC AUC (Combined Scoring): 0.5053 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 83/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 8/201\n",
      "\n",
      "Epoch 83/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3491 | MSE: 1.4623 | SSIM: 0.8794 | L1: 1.0347\n",
      "   Val Loss:\n",
      "     Total: 1.3066 | MSE: 1.3815 | SSIM: 0.8664 | L1: 0.9951\n",
      "   ROC AUC (Combined Scoring): 0.4921 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 84/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 9/201\n",
      "\n",
      "Epoch 84/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3502 | MSE: 1.4650 | SSIM: 0.8795 | L1: 1.0356\n",
      "   Val Loss:\n",
      "     Total: 1.3249 | MSE: 1.4394 | SSIM: 0.8617 | L1: 1.0185\n",
      "   ROC AUC (Combined Scoring): 0.5106 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 85/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 10/201\n",
      "\n",
      "Epoch 85/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3506 | MSE: 1.4653 | SSIM: 0.8798 | L1: 1.0361\n",
      "   Val Loss:\n",
      "     Total: 1.3180 | MSE: 1.4055 | SSIM: 0.8690 | L1: 1.0053\n",
      "   ROC AUC (Combined Scoring): 0.4967 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 86/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 11/201\n",
      "\n",
      "Epoch 86/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3501 | MSE: 1.4637 | SSIM: 0.8798 | L1: 1.0360\n",
      "   Val Loss:\n",
      "     Total: 1.3088 | MSE: 1.3954 | SSIM: 0.8619 | L1: 1.0031\n",
      "   ROC AUC (Combined Scoring): 0.5210 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.55it/s]\n",
      "Epoch 87/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 12/201\n",
      "\n",
      "Epoch 87/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3495 | MSE: 1.4625 | SSIM: 0.8797 | L1: 1.0348\n",
      "   Val Loss:\n",
      "     Total: 1.3394 | MSE: 1.4533 | SSIM: 0.8719 | L1: 1.0296\n",
      "   ROC AUC (Combined Scoring): 0.4691 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.55it/s]\n",
      "Epoch 88/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 13/201\n",
      "\n",
      "Epoch 88/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3502 | MSE: 1.4644 | SSIM: 0.8796 | L1: 1.0359\n",
      "   Val Loss:\n",
      "     Total: 1.3224 | MSE: 1.4199 | SSIM: 0.8685 | L1: 1.0082\n",
      "   ROC AUC (Combined Scoring): 0.5109 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.56it/s]\n",
      "Epoch 89/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 14/201\n",
      "\n",
      "Epoch 89/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3476 | MSE: 1.4585 | SSIM: 0.8792 | L1: 1.0333\n",
      "   Val Loss:\n",
      "     Total: 1.2998 | MSE: 1.3627 | SSIM: 0.8671 | L1: 0.9868\n",
      "   ROC AUC (Combined Scoring): 0.4943 | Best: 0.5480\n",
      "   Learning Rate: 6.25e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 90/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 15/201\n",
      "\n",
      "Epoch 90/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3510 | MSE: 1.4676 | SSIM: 0.8792 | L1: 1.0364\n",
      "   Val Loss:\n",
      "     Total: 1.3055 | MSE: 1.3923 | SSIM: 0.8596 | L1: 1.0006\n",
      "   ROC AUC (Combined Scoring): 0.5353 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.57it/s]\n",
      "Epoch 91/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 16/201\n",
      "\n",
      "Epoch 91/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3493 | MSE: 1.4632 | SSIM: 0.8792 | L1: 1.0349\n",
      "   Val Loss:\n",
      "     Total: 1.3253 | MSE: 1.4198 | SSIM: 0.8701 | L1: 1.0162\n",
      "   ROC AUC (Combined Scoring): 0.5061 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 92/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 17/201\n",
      "\n",
      "Epoch 92/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3507 | MSE: 1.4659 | SSIM: 0.8794 | L1: 1.0370\n",
      "   Val Loss:\n",
      "     Total: 1.3084 | MSE: 1.3992 | SSIM: 0.8598 | L1: 1.0042\n",
      "   ROC AUC (Combined Scoring): 0.4985 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.60it/s]\n",
      "Epoch 93/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 18/201\n",
      "\n",
      "Epoch 93/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3505 | MSE: 1.4650 | SSIM: 0.8797 | L1: 1.0361\n",
      "   Val Loss:\n",
      "     Total: 1.3240 | MSE: 1.4292 | SSIM: 0.8648 | L1: 1.0171\n",
      "   ROC AUC (Combined Scoring): 0.5279 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 94/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 19/201\n",
      "\n",
      "Epoch 94/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3504 | MSE: 1.4656 | SSIM: 0.8794 | L1: 1.0361\n",
      "   Val Loss:\n",
      "     Total: 1.2989 | MSE: 1.3850 | SSIM: 0.8562 | L1: 0.9921\n",
      "   ROC AUC (Combined Scoring): 0.5326 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.55it/s]\n",
      "Epoch 95/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 20/201\n",
      "\n",
      "Epoch 95/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3501 | MSE: 1.4648 | SSIM: 0.8793 | L1: 1.0359\n",
      "   Val Loss:\n",
      "     Total: 1.3001 | MSE: 1.3677 | SSIM: 0.8651 | L1: 0.9886\n",
      "   ROC AUC (Combined Scoring): 0.5100 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 96/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 21/201\n",
      "\n",
      "Epoch 96/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3494 | MSE: 1.4632 | SSIM: 0.8793 | L1: 1.0349\n",
      "   Val Loss:\n",
      "     Total: 1.3341 | MSE: 1.4427 | SSIM: 0.8707 | L1: 1.0239\n",
      "   ROC AUC (Combined Scoring): 0.4880 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.63it/s]\n",
      "Epoch 97/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 22/201\n",
      "\n",
      "Epoch 97/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3474 | MSE: 1.4598 | SSIM: 0.8786 | L1: 1.0329\n",
      "   Val Loss:\n",
      "     Total: 1.3252 | MSE: 1.4347 | SSIM: 0.8640 | L1: 1.0178\n",
      "   ROC AUC (Combined Scoring): 0.4817 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 98/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 23/201\n",
      "\n",
      "Epoch 98/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3487 | MSE: 1.4609 | SSIM: 0.8794 | L1: 1.0345\n",
      "   Val Loss:\n",
      "     Total: 1.2973 | MSE: 1.3788 | SSIM: 0.8556 | L1: 0.9958\n",
      "   ROC AUC (Combined Scoring): 0.5279 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 99/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 24/201\n",
      "\n",
      "Epoch 99/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3454 | MSE: 1.4559 | SSIM: 0.8781 | L1: 1.0308\n",
      "   Val Loss:\n",
      "     Total: 1.3154 | MSE: 1.3944 | SSIM: 0.8711 | L1: 1.0011\n",
      "   ROC AUC (Combined Scoring): 0.5039 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 100/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 25/201\n",
      "\n",
      "Epoch 100/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3490 | MSE: 1.4625 | SSIM: 0.8790 | L1: 1.0354\n",
      "   Val Loss:\n",
      "     Total: 1.3192 | MSE: 1.4382 | SSIM: 0.8548 | L1: 1.0197\n",
      "   ROC AUC (Combined Scoring): 0.5170 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 101/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 26/201\n",
      "\n",
      "Epoch 101/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3477 | MSE: 1.4605 | SSIM: 0.8785 | L1: 1.0337\n",
      "   Val Loss:\n",
      "     Total: 1.3135 | MSE: 1.3973 | SSIM: 0.8668 | L1: 1.0040\n",
      "   ROC AUC (Combined Scoring): 0.5023 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 102/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 27/201\n",
      "\n",
      "Epoch 102/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3489 | MSE: 1.4636 | SSIM: 0.8786 | L1: 1.0347\n",
      "   Val Loss:\n",
      "     Total: 1.2978 | MSE: 1.3674 | SSIM: 0.8614 | L1: 0.9922\n",
      "   ROC AUC (Combined Scoring): 0.4900 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 103/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 28/201\n",
      "\n",
      "Epoch 103/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4596 | SSIM: 0.8790 | L1: 1.0339\n",
      "   Val Loss:\n",
      "     Total: 1.3202 | MSE: 1.4064 | SSIM: 0.8717 | L1: 1.0050\n",
      "   ROC AUC (Combined Scoring): 0.5277 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 104/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 29/201\n",
      "\n",
      "Epoch 104/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3487 | MSE: 1.4624 | SSIM: 0.8789 | L1: 1.0347\n",
      "   Val Loss:\n",
      "     Total: 1.3048 | MSE: 1.4152 | SSIM: 0.8489 | L1: 1.0057\n",
      "   ROC AUC (Combined Scoring): 0.4972 | Best: 0.5480\n",
      "   Learning Rate: 3.13e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 105/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 30/201\n",
      "\n",
      "Epoch 105/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3491 | MSE: 1.4625 | SSIM: 0.8792 | L1: 1.0352\n",
      "   Val Loss:\n",
      "     Total: 1.3089 | MSE: 1.3872 | SSIM: 0.8666 | L1: 0.9974\n",
      "   ROC AUC (Combined Scoring): 0.4882 | Best: 0.5480\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 106/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 31/201\n",
      "\n",
      "Epoch 106/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3490 | MSE: 1.4625 | SSIM: 0.8792 | L1: 1.0344\n",
      "   Val Loss:\n",
      "     Total: 1.2950 | MSE: 1.3767 | SSIM: 0.8541 | L1: 0.9937\n",
      "   ROC AUC (Combined Scoring): 0.5294 | Best: 0.5480\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 107/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 32/201\n",
      "\n",
      "Epoch 107/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3458 | MSE: 1.4567 | SSIM: 0.8781 | L1: 1.0313\n",
      "   Val Loss:\n",
      "     Total: 1.3358 | MSE: 1.4337 | SSIM: 0.8774 | L1: 1.0189\n",
      "   ROC AUC (Combined Scoring): 0.5172 | Best: 0.5480\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 108/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 33/201\n",
      "\n",
      "Epoch 108/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3486 | MSE: 1.4624 | SSIM: 0.8787 | L1: 1.0344\n",
      "   Val Loss:\n",
      "     Total: 1.3021 | MSE: 1.3961 | SSIM: 0.8530 | L1: 1.0043\n",
      "   ROC AUC (Combined Scoring): 0.4954 | Best: 0.5480\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.62it/s]\n",
      "Epoch 109/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 34/201\n",
      "\n",
      "Epoch 109/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3504 | MSE: 1.4656 | SSIM: 0.8793 | L1: 1.0365\n",
      "   Val Loss:\n",
      "     Total: 1.3055 | MSE: 1.3917 | SSIM: 0.8595 | L1: 1.0017\n",
      "   ROC AUC (Combined Scoring): 0.4860 | Best: 0.5480\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 110/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 35/201\n",
      "\n",
      "Epoch 110/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3489 | MSE: 1.4628 | SSIM: 0.8789 | L1: 1.0347\n",
      "   Val Loss:\n",
      "     Total: 1.3079 | MSE: 1.3951 | SSIM: 0.8607 | L1: 1.0041\n",
      "   ROC AUC (Combined Scoring): 0.4974 | Best: 0.5480\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 111/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 36/201\n",
      "\n",
      "Epoch 111/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3498 | MSE: 1.4637 | SSIM: 0.8794 | L1: 1.0359\n",
      "   Val Loss:\n",
      "     Total: 1.3182 | MSE: 1.4480 | SSIM: 0.8493 | L1: 1.0219\n",
      "   ROC AUC (Combined Scoring): 0.4944 | Best: 0.5480\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.46it/s]\n",
      "Epoch 112/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 37/201\n",
      "\n",
      "Epoch 112/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3469 | MSE: 1.4585 | SSIM: 0.8785 | L1: 1.0326\n",
      "   Val Loss:\n",
      "     Total: 1.3345 | MSE: 1.4435 | SSIM: 0.8701 | L1: 1.0267\n",
      "   ROC AUC (Combined Scoring): 0.4946 | Best: 0.5480\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 113/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 38/201\n",
      "\n",
      "Epoch 113/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3463 | MSE: 1.4566 | SSIM: 0.8786 | L1: 1.0321\n",
      "   Val Loss:\n",
      "     Total: 1.2867 | MSE: 1.3617 | SSIM: 0.8509 | L1: 0.9875\n",
      "   ROC AUC (Combined Scoring): 0.4942 | Best: 0.5480\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 114/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 39/201\n",
      "\n",
      "Epoch 114/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3507 | MSE: 1.4655 | SSIM: 0.8795 | L1: 1.0372\n",
      "   Val Loss:\n",
      "     Total: 1.3137 | MSE: 1.4263 | SSIM: 0.8530 | L1: 1.0174\n",
      "   ROC AUC (Combined Scoring): 0.5069 | Best: 0.5480\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 115/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Nuevo mejor modelo guardado! AUC: 0.5520\n",
      "\n",
      "Epoch 115/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4605 | SSIM: 0.8786 | L1: 1.0335\n",
      "   Val Loss:\n",
      "     Total: 1.3249 | MSE: 1.4237 | SSIM: 0.8685 | L1: 1.0153\n",
      "   ROC AUC (Combined Scoring): 0.5520 | Best: 0.5520\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 116/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 1/201\n",
      "\n",
      "Epoch 116/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3473 | MSE: 1.4599 | SSIM: 0.8784 | L1: 1.0331\n",
      "   Val Loss:\n",
      "     Total: 1.3201 | MSE: 1.4107 | SSIM: 0.8679 | L1: 1.0130\n",
      "   ROC AUC (Combined Scoring): 0.4738 | Best: 0.5520\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 117/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 2/201\n",
      "\n",
      "Epoch 117/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3482 | MSE: 1.4604 | SSIM: 0.8790 | L1: 1.0344\n",
      "   Val Loss:\n",
      "     Total: 1.3132 | MSE: 1.3850 | SSIM: 0.8710 | L1: 1.0045\n",
      "   ROC AUC (Combined Scoring): 0.4842 | Best: 0.5520\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 118/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 3/201\n",
      "\n",
      "Epoch 118/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3494 | MSE: 1.4635 | SSIM: 0.8792 | L1: 1.0349\n",
      "   Val Loss:\n",
      "     Total: 1.3179 | MSE: 1.4019 | SSIM: 0.8705 | L1: 1.0049\n",
      "   ROC AUC (Combined Scoring): 0.5031 | Best: 0.5520\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.61it/s]\n",
      "Epoch 119/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 4/201\n",
      "\n",
      "Epoch 119/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3486 | MSE: 1.4623 | SSIM: 0.8787 | L1: 1.0349\n",
      "   Val Loss:\n",
      "     Total: 1.3028 | MSE: 1.3686 | SSIM: 0.8680 | L1: 0.9895\n",
      "   ROC AUC (Combined Scoring): 0.4913 | Best: 0.5520\n",
      "   Learning Rate: 1.56e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 120/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 5/201\n",
      "\n",
      "Epoch 120/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3474 | MSE: 1.4587 | SSIM: 0.8790 | L1: 1.0333\n",
      "   Val Loss:\n",
      "     Total: 1.3225 | MSE: 1.4427 | SSIM: 0.8571 | L1: 1.0202\n",
      "   ROC AUC (Combined Scoring): 0.5251 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 121/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 6/201\n",
      "\n",
      "Epoch 121/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3490 | MSE: 1.4634 | SSIM: 0.8786 | L1: 1.0354\n",
      "   Val Loss:\n",
      "     Total: 1.3074 | MSE: 1.3953 | SSIM: 0.8610 | L1: 1.0000\n",
      "   ROC AUC (Combined Scoring): 0.4976 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 122/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 7/201\n",
      "\n",
      "Epoch 122/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3476 | MSE: 1.4594 | SSIM: 0.8787 | L1: 1.0338\n",
      "   Val Loss:\n",
      "     Total: 1.3107 | MSE: 1.3932 | SSIM: 0.8656 | L1: 1.0013\n",
      "   ROC AUC (Combined Scoring): 0.5039 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 123/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 8/201\n",
      "\n",
      "Epoch 123/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3487 | MSE: 1.4624 | SSIM: 0.8789 | L1: 1.0347\n",
      "   Val Loss:\n",
      "     Total: 1.3126 | MSE: 1.4061 | SSIM: 0.8615 | L1: 1.0080\n",
      "   ROC AUC (Combined Scoring): 0.4910 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 124/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 9/201\n",
      "\n",
      "Epoch 124/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4609 | SSIM: 0.8786 | L1: 1.0336\n",
      "   Val Loss:\n",
      "     Total: 1.3226 | MSE: 1.4387 | SSIM: 0.8597 | L1: 1.0163\n",
      "   ROC AUC (Combined Scoring): 0.5192 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 125/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 10/201\n",
      "\n",
      "Epoch 125/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3490 | MSE: 1.4630 | SSIM: 0.8787 | L1: 1.0355\n",
      "   Val Loss:\n",
      "     Total: 1.3266 | MSE: 1.4154 | SSIM: 0.8740 | L1: 1.0137\n",
      "   ROC AUC (Combined Scoring): 0.4806 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 126/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 11/201\n",
      "\n",
      "Epoch 126/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3460 | MSE: 1.4571 | SSIM: 0.8781 | L1: 1.0321\n",
      "   Val Loss:\n",
      "     Total: 1.3187 | MSE: 1.4106 | SSIM: 0.8661 | L1: 1.0132\n",
      "   ROC AUC (Combined Scoring): 0.5225 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 127/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 12/201\n",
      "\n",
      "Epoch 127/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3497 | MSE: 1.4646 | SSIM: 0.8789 | L1: 1.0360\n",
      "   Val Loss:\n",
      "     Total: 1.2899 | MSE: 1.3659 | SSIM: 0.8543 | L1: 0.9834\n",
      "   ROC AUC (Combined Scoring): 0.5080 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 128/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 13/201\n",
      "\n",
      "Epoch 128/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3471 | MSE: 1.4598 | SSIM: 0.8781 | L1: 1.0333\n",
      "   Val Loss:\n",
      "     Total: 1.3099 | MSE: 1.3800 | SSIM: 0.8702 | L1: 0.9990\n",
      "   ROC AUC (Combined Scoring): 0.5025 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 129/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 14/201\n",
      "\n",
      "Epoch 129/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3485 | MSE: 1.4610 | SSIM: 0.8790 | L1: 1.0348\n",
      "   Val Loss:\n",
      "     Total: 1.3104 | MSE: 1.4039 | SSIM: 0.8605 | L1: 1.0041\n",
      "   ROC AUC (Combined Scoring): 0.5010 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.61it/s]\n",
      "Epoch 130/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 15/201\n",
      "\n",
      "Epoch 130/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3477 | MSE: 1.4597 | SSIM: 0.8786 | L1: 1.0346\n",
      "   Val Loss:\n",
      "     Total: 1.3247 | MSE: 1.4209 | SSIM: 0.8694 | L1: 1.0145\n",
      "   ROC AUC (Combined Scoring): 0.5065 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 131/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 16/201\n",
      "\n",
      "Epoch 131/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3473 | MSE: 1.4606 | SSIM: 0.8780 | L1: 1.0334\n",
      "   Val Loss:\n",
      "     Total: 1.3130 | MSE: 1.4051 | SSIM: 0.8628 | L1: 1.0061\n",
      "   ROC AUC (Combined Scoring): 0.4883 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 132/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 17/201\n",
      "\n",
      "Epoch 132/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3493 | MSE: 1.4643 | SSIM: 0.8786 | L1: 1.0353\n",
      "   Val Loss:\n",
      "     Total: 1.2933 | MSE: 1.3951 | SSIM: 0.8432 | L1: 1.0008\n",
      "   ROC AUC (Combined Scoring): 0.5039 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 133/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 18/201\n",
      "\n",
      "Epoch 133/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4602 | SSIM: 0.8787 | L1: 1.0342\n",
      "   Val Loss:\n",
      "     Total: 1.3109 | MSE: 1.3780 | SSIM: 0.8739 | L1: 0.9921\n",
      "   ROC AUC (Combined Scoring): 0.4870 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 134/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 134/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 19/201\n",
      "\n",
      "Epoch 134/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4613 | SSIM: 0.8782 | L1: 1.0338\n",
      "   Val Loss:\n",
      "     Total: 1.3346 | MSE: 1.4388 | SSIM: 0.8729 | L1: 1.0234\n",
      "   ROC AUC (Combined Scoring): 0.5168 | Best: 0.5520\n",
      "   Learning Rate: 7.81e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 135/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 20/201\n",
      "\n",
      "Epoch 135/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3470 | MSE: 1.4601 | SSIM: 0.8780 | L1: 1.0328\n",
      "   Val Loss:\n",
      "     Total: 1.3201 | MSE: 1.4059 | SSIM: 0.8705 | L1: 1.0097\n",
      "   ROC AUC (Combined Scoring): 0.4824 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 136/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 21/201\n",
      "\n",
      "Epoch 136/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3474 | MSE: 1.4605 | SSIM: 0.8782 | L1: 1.0333\n",
      "   Val Loss:\n",
      "     Total: 1.3241 | MSE: 1.4435 | SSIM: 0.8583 | L1: 1.0220\n",
      "   ROC AUC (Combined Scoring): 0.5068 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 137/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 22/201\n",
      "\n",
      "Epoch 137/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3458 | MSE: 1.4563 | SSIM: 0.8782 | L1: 1.0316\n",
      "   Val Loss:\n",
      "     Total: 1.3060 | MSE: 1.4006 | SSIM: 0.8574 | L1: 0.9995\n",
      "   ROC AUC (Combined Scoring): 0.5123 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 138/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 138/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 23/201\n",
      "\n",
      "Epoch 138/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3480 | MSE: 1.4605 | SSIM: 0.8788 | L1: 1.0340\n",
      "   Val Loss:\n",
      "     Total: 1.3242 | MSE: 1.4219 | SSIM: 0.8685 | L1: 1.0144\n",
      "   ROC AUC (Combined Scoring): 0.4806 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 139/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 24/201\n",
      "\n",
      "Epoch 139/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3467 | MSE: 1.4587 | SSIM: 0.8780 | L1: 1.0331\n",
      "   Val Loss:\n",
      "     Total: 1.2815 | MSE: 1.3416 | SSIM: 0.8534 | L1: 0.9813\n",
      "   ROC AUC (Combined Scoring): 0.4432 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 140/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 25/201\n",
      "\n",
      "Epoch 140/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3490 | MSE: 1.4632 | SSIM: 0.8788 | L1: 1.0351\n",
      "   Val Loss:\n",
      "     Total: 1.3153 | MSE: 1.4134 | SSIM: 0.8616 | L1: 1.0100\n",
      "   ROC AUC (Combined Scoring): 0.5125 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 141/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 26/201\n",
      "\n",
      "Epoch 141/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3487 | MSE: 1.4626 | SSIM: 0.8786 | L1: 1.0352\n",
      "   Val Loss:\n",
      "     Total: 1.3100 | MSE: 1.3776 | SSIM: 0.8710 | L1: 0.9996\n",
      "   ROC AUC (Combined Scoring): 0.5097 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 142/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 27/201\n",
      "\n",
      "Epoch 142/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3513 | MSE: 1.4659 | SSIM: 0.8798 | L1: 1.0384\n",
      "   Val Loss:\n",
      "     Total: 1.3176 | MSE: 1.4281 | SSIM: 0.8564 | L1: 1.0200\n",
      "   ROC AUC (Combined Scoring): 0.4964 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 143/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.55it/s]\n",
      "Epoch 143/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 28/201\n",
      "\n",
      "Epoch 143/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3466 | MSE: 1.4578 | SSIM: 0.8784 | L1: 1.0329\n",
      "   Val Loss:\n",
      "     Total: 1.3296 | MSE: 1.4469 | SSIM: 0.8635 | L1: 1.0236\n",
      "   ROC AUC (Combined Scoring): 0.4841 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 144/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 144/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 29/201\n",
      "\n",
      "Epoch 144/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3484 | MSE: 1.4624 | SSIM: 0.8785 | L1: 1.0344\n",
      "   Val Loss:\n",
      "     Total: 1.3042 | MSE: 1.3997 | SSIM: 0.8539 | L1: 1.0057\n",
      "   ROC AUC (Combined Scoring): 0.4691 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 145/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 30/201\n",
      "\n",
      "Epoch 145/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4604 | SSIM: 0.8785 | L1: 1.0343\n",
      "   Val Loss:\n",
      "     Total: 1.3338 | MSE: 1.4400 | SSIM: 0.8718 | L1: 1.0215\n",
      "   ROC AUC (Combined Scoring): 0.4738 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 146/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 31/201\n",
      "\n",
      "Epoch 146/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3476 | MSE: 1.4599 | SSIM: 0.8786 | L1: 1.0335\n",
      "   Val Loss:\n",
      "     Total: 1.3202 | MSE: 1.4060 | SSIM: 0.8709 | L1: 1.0084\n",
      "   ROC AUC (Combined Scoring): 0.4970 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 147/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 32/201\n",
      "\n",
      "Epoch 147/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3477 | MSE: 1.4600 | SSIM: 0.8787 | L1: 1.0337\n",
      "   Val Loss:\n",
      "     Total: 1.3409 | MSE: 1.4592 | SSIM: 0.8716 | L1: 1.0294\n",
      "   ROC AUC (Combined Scoring): 0.5101 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 148/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 33/201\n",
      "\n",
      "Epoch 148/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3482 | MSE: 1.4606 | SSIM: 0.8789 | L1: 1.0344\n",
      "   Val Loss:\n",
      "     Total: 1.3202 | MSE: 1.4148 | SSIM: 0.8674 | L1: 1.0090\n",
      "   ROC AUC (Combined Scoring): 0.5210 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 149/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 34/201\n",
      "\n",
      "Epoch 149/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3459 | MSE: 1.4573 | SSIM: 0.8779 | L1: 1.0317\n",
      "   Val Loss:\n",
      "     Total: 1.3195 | MSE: 1.4096 | SSIM: 0.8688 | L1: 1.0078\n",
      "   ROC AUC (Combined Scoring): 0.4889 | Best: 0.5520\n",
      "   Learning Rate: 3.91e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 150/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 35/201\n",
      "\n",
      "Epoch 150/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3479 | MSE: 1.4605 | SSIM: 0.8787 | L1: 1.0341\n",
      "   Val Loss:\n",
      "     Total: 1.3097 | MSE: 1.3976 | SSIM: 0.8624 | L1: 1.0029\n",
      "   ROC AUC (Combined Scoring): 0.5259 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 151/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.55it/s]\n",
      "Epoch 151/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 36/201\n",
      "\n",
      "Epoch 151/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3499 | MSE: 1.4639 | SSIM: 0.8792 | L1: 1.0366\n",
      "   Val Loss:\n",
      "     Total: 1.2914 | MSE: 1.3536 | SSIM: 0.8602 | L1: 0.9856\n",
      "   ROC AUC (Combined Scoring): 0.5156 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 152/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 152/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 37/201\n",
      "\n",
      "Epoch 152/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3479 | MSE: 1.4603 | SSIM: 0.8787 | L1: 1.0342\n",
      "   Val Loss:\n",
      "     Total: 1.3041 | MSE: 1.3960 | SSIM: 0.8566 | L1: 1.0001\n",
      "   ROC AUC (Combined Scoring): 0.5058 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 153/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.56it/s]\n",
      "Epoch 153/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 38/201\n",
      "\n",
      "Epoch 153/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3475 | MSE: 1.4601 | SSIM: 0.8784 | L1: 1.0340\n",
      "   Val Loss:\n",
      "     Total: 1.3220 | MSE: 1.4356 | SSIM: 0.8601 | L1: 1.0166\n",
      "   ROC AUC (Combined Scoring): 0.5361 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 154/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.60it/s]\n",
      "Epoch 154/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 39/201\n",
      "\n",
      "Epoch 154/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3481 | MSE: 1.4594 | SSIM: 0.8792 | L1: 1.0345\n",
      "   Val Loss:\n",
      "     Total: 1.3024 | MSE: 1.3825 | SSIM: 0.8613 | L1: 0.9933\n",
      "   ROC AUC (Combined Scoring): 0.4936 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 155/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.61it/s]\n",
      "Epoch 155/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 40/201\n",
      "\n",
      "Epoch 155/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3466 | MSE: 1.4586 | SSIM: 0.8781 | L1: 1.0328\n",
      "   Val Loss:\n",
      "     Total: 1.3141 | MSE: 1.3951 | SSIM: 0.8674 | L1: 1.0083\n",
      "   ROC AUC (Combined Scoring): 0.4547 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 156/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 156/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 41/201\n",
      "\n",
      "Epoch 156/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4614 | SSIM: 0.8783 | L1: 1.0337\n",
      "   Val Loss:\n",
      "     Total: 1.3170 | MSE: 1.3882 | SSIM: 0.8751 | L1: 1.0022\n",
      "   ROC AUC (Combined Scoring): 0.4612 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 157/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 157/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 42/201\n",
      "\n",
      "Epoch 157/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3484 | MSE: 1.4631 | SSIM: 0.8783 | L1: 1.0339\n",
      "   Val Loss:\n",
      "     Total: 1.3152 | MSE: 1.4052 | SSIM: 0.8648 | L1: 1.0093\n",
      "   ROC AUC (Combined Scoring): 0.4668 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 158/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 158/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 43/201\n",
      "\n",
      "Epoch 158/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4604 | SSIM: 0.8784 | L1: 1.0347\n",
      "   Val Loss:\n",
      "     Total: 1.3257 | MSE: 1.4148 | SSIM: 0.8730 | L1: 1.0141\n",
      "   ROC AUC (Combined Scoring): 0.4884 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 159/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 44/201\n",
      "\n",
      "Epoch 159/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4612 | SSIM: 0.8783 | L1: 1.0338\n",
      "   Val Loss:\n",
      "     Total: 1.3097 | MSE: 1.3929 | SSIM: 0.8632 | L1: 1.0063\n",
      "   ROC AUC (Combined Scoring): 0.5027 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 160/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 160/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 45/201\n",
      "\n",
      "Epoch 160/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3481 | MSE: 1.4613 | SSIM: 0.8785 | L1: 1.0347\n",
      "   Val Loss:\n",
      "     Total: 1.3112 | MSE: 1.4023 | SSIM: 0.8622 | L1: 1.0037\n",
      "   ROC AUC (Combined Scoring): 0.5092 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 161/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 161/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 46/201\n",
      "\n",
      "Epoch 161/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3475 | MSE: 1.4600 | SSIM: 0.8784 | L1: 1.0340\n",
      "   Val Loss:\n",
      "     Total: 1.3220 | MSE: 1.4100 | SSIM: 0.8725 | L1: 1.0050\n",
      "   ROC AUC (Combined Scoring): 0.5184 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 162/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 162/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 47/201\n",
      "\n",
      "Epoch 162/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3481 | MSE: 1.4612 | SSIM: 0.8786 | L1: 1.0344\n",
      "   Val Loss:\n",
      "     Total: 1.3134 | MSE: 1.4007 | SSIM: 0.8643 | L1: 1.0088\n",
      "   ROC AUC (Combined Scoring): 0.5077 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 163/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 163/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 48/201\n",
      "\n",
      "Epoch 163/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3468 | MSE: 1.4579 | SSIM: 0.8785 | L1: 1.0333\n",
      "   Val Loss:\n",
      "     Total: 1.3355 | MSE: 1.4294 | SSIM: 0.8781 | L1: 1.0209\n",
      "   ROC AUC (Combined Scoring): 0.5093 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 164/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 164/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 49/201\n",
      "\n",
      "Epoch 164/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3492 | MSE: 1.4645 | SSIM: 0.8785 | L1: 1.0355\n",
      "   Val Loss:\n",
      "     Total: 1.2874 | MSE: 1.3497 | SSIM: 0.8579 | L1: 0.9810\n",
      "   ROC AUC (Combined Scoring): 0.4573 | Best: 0.5520\n",
      "   Learning Rate: 1.95e-08\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 165/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 165/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 50/201\n",
      "\n",
      "Epoch 165/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3491 | MSE: 1.4624 | SSIM: 0.8791 | L1: 1.0354\n",
      "   Val Loss:\n",
      "     Total: 1.3005 | MSE: 1.3771 | SSIM: 0.8610 | L1: 0.9926\n",
      "   ROC AUC (Combined Scoring): 0.4914 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 166/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 166/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 51/201\n",
      "\n",
      "Epoch 166/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3473 | MSE: 1.4587 | SSIM: 0.8787 | L1: 1.0336\n",
      "   Val Loss:\n",
      "     Total: 1.2905 | MSE: 1.3597 | SSIM: 0.8563 | L1: 0.9880\n",
      "   ROC AUC (Combined Scoring): 0.5033 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 167/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 167/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 52/201\n",
      "\n",
      "Epoch 167/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3472 | MSE: 1.4592 | SSIM: 0.8784 | L1: 1.0335\n",
      "   Val Loss:\n",
      "     Total: 1.3085 | MSE: 1.3959 | SSIM: 0.8623 | L1: 0.9991\n",
      "   ROC AUC (Combined Scoring): 0.4875 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 168/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 168/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 53/201\n",
      "\n",
      "Epoch 168/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3473 | MSE: 1.4596 | SSIM: 0.8785 | L1: 1.0333\n",
      "   Val Loss:\n",
      "     Total: 1.3336 | MSE: 1.4573 | SSIM: 0.8634 | L1: 1.0285\n",
      "   ROC AUC (Combined Scoring): 0.5367 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.56it/s]\n",
      "Epoch 169/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 54/201\n",
      "\n",
      "Epoch 169/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3486 | MSE: 1.4629 | SSIM: 0.8785 | L1: 1.0347\n",
      "   Val Loss:\n",
      "     Total: 1.3084 | MSE: 1.3925 | SSIM: 0.8629 | L1: 1.0018\n",
      "   ROC AUC (Combined Scoring): 0.4787 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 170/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.63it/s]\n",
      "Epoch 170/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 55/201\n",
      "\n",
      "Epoch 170/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3484 | MSE: 1.4618 | SSIM: 0.8788 | L1: 1.0344\n",
      "   Val Loss:\n",
      "     Total: 1.3199 | MSE: 1.4283 | SSIM: 0.8596 | L1: 1.0187\n",
      "   ROC AUC (Combined Scoring): 0.4742 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 171/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 171/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 56/201\n",
      "\n",
      "Epoch 171/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3474 | MSE: 1.4607 | SSIM: 0.8781 | L1: 1.0337\n",
      "   Val Loss:\n",
      "     Total: 1.3272 | MSE: 1.4141 | SSIM: 0.8753 | L1: 1.0137\n",
      "   ROC AUC (Combined Scoring): 0.5089 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 172/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.56it/s]\n",
      "Epoch 172/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 57/201\n",
      "\n",
      "Epoch 172/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3473 | MSE: 1.4593 | SSIM: 0.8786 | L1: 1.0331\n",
      "   Val Loss:\n",
      "     Total: 1.3036 | MSE: 1.3683 | SSIM: 0.8693 | L1: 0.9880\n",
      "   ROC AUC (Combined Scoring): 0.4875 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 173/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 173/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 58/201\n",
      "\n",
      "Epoch 173/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3474 | MSE: 1.4594 | SSIM: 0.8786 | L1: 1.0334\n",
      "   Val Loss:\n",
      "     Total: 1.3203 | MSE: 1.4270 | SSIM: 0.8613 | L1: 1.0161\n",
      "   ROC AUC (Combined Scoring): 0.4683 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 174/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 174/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 59/201\n",
      "\n",
      "Epoch 174/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3480 | MSE: 1.4621 | SSIM: 0.8782 | L1: 1.0340\n",
      "   Val Loss:\n",
      "     Total: 1.3203 | MSE: 1.4033 | SSIM: 0.8720 | L1: 1.0086\n",
      "   ROC AUC (Combined Scoring): 0.5261 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 175/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 175/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 60/201\n",
      "\n",
      "Epoch 175/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4611 | SSIM: 0.8784 | L1: 1.0338\n",
      "   Val Loss:\n",
      "     Total: 1.3075 | MSE: 1.3846 | SSIM: 0.8653 | L1: 0.9990\n",
      "   ROC AUC (Combined Scoring): 0.5026 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 176/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 176/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 61/201\n",
      "\n",
      "Epoch 176/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3479 | MSE: 1.4602 | SSIM: 0.8788 | L1: 1.0337\n",
      "   Val Loss:\n",
      "     Total: 1.2950 | MSE: 1.3530 | SSIM: 0.8659 | L1: 0.9818\n",
      "   ROC AUC (Combined Scoring): 0.4808 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 177/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 177/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 62/201\n",
      "\n",
      "Epoch 177/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3472 | MSE: 1.4590 | SSIM: 0.8784 | L1: 1.0337\n",
      "   Val Loss:\n",
      "     Total: 1.3125 | MSE: 1.4000 | SSIM: 0.8640 | L1: 1.0063\n",
      "   ROC AUC (Combined Scoring): 0.4964 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 178/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 178/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 63/201\n",
      "\n",
      "Epoch 178/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3460 | MSE: 1.4564 | SSIM: 0.8782 | L1: 1.0326\n",
      "   Val Loss:\n",
      "     Total: 1.2991 | MSE: 1.3842 | SSIM: 0.8550 | L1: 0.9994\n",
      "   ROC AUC (Combined Scoring): 0.4644 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 179/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 64/201\n",
      "\n",
      "Epoch 179/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3460 | MSE: 1.4559 | SSIM: 0.8784 | L1: 1.0322\n",
      "   Val Loss:\n",
      "     Total: 1.3141 | MSE: 1.4283 | SSIM: 0.8534 | L1: 1.0146\n",
      "   ROC AUC (Combined Scoring): 0.4715 | Best: 0.5520\n",
      "   Learning Rate: 9.77e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 180/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 180/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 65/201\n",
      "\n",
      "Epoch 180/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4619 | SSIM: 0.8781 | L1: 1.0340\n",
      "   Val Loss:\n",
      "     Total: 1.3094 | MSE: 1.4118 | SSIM: 0.8552 | L1: 1.0081\n",
      "   ROC AUC (Combined Scoring): 0.5030 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 181/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 181/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 66/201\n",
      "\n",
      "Epoch 181/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3510 | MSE: 1.4662 | SSIM: 0.8796 | L1: 1.0372\n",
      "   Val Loss:\n",
      "     Total: 1.3213 | MSE: 1.4279 | SSIM: 0.8615 | L1: 1.0186\n",
      "   ROC AUC (Combined Scoring): 0.4692 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 182/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 182/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 67/201\n",
      "\n",
      "Epoch 182/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3481 | MSE: 1.4608 | SSIM: 0.8787 | L1: 1.0342\n",
      "   Val Loss:\n",
      "     Total: 1.2927 | MSE: 1.3592 | SSIM: 0.8602 | L1: 0.9837\n",
      "   ROC AUC (Combined Scoring): 0.5066 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 183/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 183/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 68/201\n",
      "\n",
      "Epoch 183/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3476 | MSE: 1.4605 | SSIM: 0.8784 | L1: 1.0339\n",
      "   Val Loss:\n",
      "     Total: 1.3128 | MSE: 1.3971 | SSIM: 0.8655 | L1: 1.0063\n",
      "   ROC AUC (Combined Scoring): 0.4903 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 184/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.60it/s]\n",
      "Epoch 184/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 69/201\n",
      "\n",
      "Epoch 184/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3460 | MSE: 1.4563 | SSIM: 0.8783 | L1: 1.0323\n",
      "   Val Loss:\n",
      "     Total: 1.3057 | MSE: 1.3897 | SSIM: 0.8623 | L1: 0.9948\n",
      "   ROC AUC (Combined Scoring): 0.4808 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 185/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 185/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 70/201\n",
      "\n",
      "Epoch 185/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3476 | MSE: 1.4612 | SSIM: 0.8781 | L1: 1.0339\n",
      "   Val Loss:\n",
      "     Total: 1.2958 | MSE: 1.3683 | SSIM: 0.8595 | L1: 0.9886\n",
      "   ROC AUC (Combined Scoring): 0.5340 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 186/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 186/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 71/201\n",
      "\n",
      "Epoch 186/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3473 | MSE: 1.4599 | SSIM: 0.8783 | L1: 1.0336\n",
      "   Val Loss:\n",
      "     Total: 1.2921 | MSE: 1.3648 | SSIM: 0.8572 | L1: 0.9848\n",
      "   ROC AUC (Combined Scoring): 0.5238 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 187/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.59it/s]\n",
      "Epoch 187/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 72/201\n",
      "\n",
      "Epoch 187/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3471 | MSE: 1.4591 | SSIM: 0.8783 | L1: 1.0334\n",
      "   Val Loss:\n",
      "     Total: 1.3131 | MSE: 1.4100 | SSIM: 0.8600 | L1: 1.0105\n",
      "   ROC AUC (Combined Scoring): 0.4707 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 188/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 188/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 73/201\n",
      "\n",
      "Epoch 188/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4604 | SSIM: 0.8787 | L1: 1.0337\n",
      "   Val Loss:\n",
      "     Total: 1.3214 | MSE: 1.4124 | SSIM: 0.8687 | L1: 1.0134\n",
      "   ROC AUC (Combined Scoring): 0.4874 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 189/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 74/201\n",
      "\n",
      "Epoch 189/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3478 | MSE: 1.4603 | SSIM: 0.8786 | L1: 1.0340\n",
      "   Val Loss:\n",
      "     Total: 1.3186 | MSE: 1.4182 | SSIM: 0.8628 | L1: 1.0143\n",
      "   ROC AUC (Combined Scoring): 0.4832 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 190/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.52it/s]\n",
      "Epoch 190/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 75/201\n",
      "\n",
      "Epoch 190/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3462 | MSE: 1.4574 | SSIM: 0.8783 | L1: 1.0318\n",
      "   Val Loss:\n",
      "     Total: 1.3001 | MSE: 1.3912 | SSIM: 0.8537 | L1: 0.9989\n",
      "   ROC AUC (Combined Scoring): 0.4899 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 191/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 191/200 (val): 100%|██████████| 54/54 [00:03<00:00, 15.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 76/201\n",
      "\n",
      "Epoch 191/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3487 | MSE: 1.4616 | SSIM: 0.8789 | L1: 1.0356\n",
      "   Val Loss:\n",
      "     Total: 1.3119 | MSE: 1.4054 | SSIM: 0.8615 | L1: 1.0056\n",
      "   ROC AUC (Combined Scoring): 0.5004 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 192/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 192/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 77/201\n",
      "\n",
      "Epoch 192/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3459 | MSE: 1.4575 | SSIM: 0.8778 | L1: 1.0320\n",
      "   Val Loss:\n",
      "     Total: 1.3319 | MSE: 1.4115 | SSIM: 0.8823 | L1: 1.0128\n",
      "   ROC AUC (Combined Scoring): 0.5273 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 193/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 193/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 78/201\n",
      "\n",
      "Epoch 193/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3482 | MSE: 1.4611 | SSIM: 0.8789 | L1: 1.0337\n",
      "   Val Loss:\n",
      "     Total: 1.3044 | MSE: 1.3918 | SSIM: 0.8582 | L1: 1.0016\n",
      "   ROC AUC (Combined Scoring): 0.5324 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 194/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 194/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 79/201\n",
      "\n",
      "Epoch 194/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3490 | MSE: 1.4622 | SSIM: 0.8790 | L1: 1.0354\n",
      "   Val Loss:\n",
      "     Total: 1.3144 | MSE: 1.3960 | SSIM: 0.8690 | L1: 1.0022\n",
      "   ROC AUC (Combined Scoring): 0.4737 | Best: 0.5520\n",
      "   Learning Rate: 4.88e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 195/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.51it/s]\n",
      "Epoch 195/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 80/201\n",
      "\n",
      "Epoch 195/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3480 | MSE: 1.4606 | SSIM: 0.8788 | L1: 1.0341\n",
      "   Val Loss:\n",
      "     Total: 1.3228 | MSE: 1.4171 | SSIM: 0.8687 | L1: 1.0133\n",
      "   ROC AUC (Combined Scoring): 0.4790 | Best: 0.5520\n",
      "   Learning Rate: 2.44e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 196/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.50it/s]\n",
      "Epoch 196/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 81/201\n",
      "\n",
      "Epoch 196/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3469 | MSE: 1.4589 | SSIM: 0.8783 | L1: 1.0330\n",
      "   Val Loss:\n",
      "     Total: 1.3107 | MSE: 1.4086 | SSIM: 0.8585 | L1: 1.0067\n",
      "   ROC AUC (Combined Scoring): 0.5147 | Best: 0.5520\n",
      "   Learning Rate: 2.44e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 197/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 197/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 82/201\n",
      "\n",
      "Epoch 197/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3491 | MSE: 1.4620 | SSIM: 0.8792 | L1: 1.0358\n",
      "   Val Loss:\n",
      "     Total: 1.3009 | MSE: 1.3748 | SSIM: 0.8620 | L1: 0.9941\n",
      "   ROC AUC (Combined Scoring): 0.5160 | Best: 0.5520\n",
      "   Learning Rate: 2.44e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 198/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "Epoch 198/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 83/201\n",
      "\n",
      "Epoch 198/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3472 | MSE: 1.4601 | SSIM: 0.8781 | L1: 1.0336\n",
      "   Val Loss:\n",
      "     Total: 1.2959 | MSE: 1.3561 | SSIM: 0.8639 | L1: 0.9896\n",
      "   ROC AUC (Combined Scoring): 0.5057 | Best: 0.5520\n",
      "   Learning Rate: 2.44e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 199/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 84/201\n",
      "\n",
      "Epoch 199/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3484 | MSE: 1.4616 | SSIM: 0.8786 | L1: 1.0351\n",
      "   Val Loss:\n",
      "     Total: 1.3380 | MSE: 1.4573 | SSIM: 0.8685 | L1: 1.0299\n",
      "   ROC AUC (Combined Scoring): 0.4952 | Best: 0.5520\n",
      "   Learning Rate: 2.44e-09\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200/200 (train): 100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "Epoch 200/200 (val): 100%|██████████| 54/54 [00:03<00:00, 16.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AUC no mejorado. Paciencia: 85/201\n",
      "\n",
      "Epoch 200/200:\n",
      "   Train Loss:\n",
      "     Total: 1.3462 | MSE: 1.4581 | SSIM: 0.8781 | L1: 1.0317\n",
      "   Val Loss:\n",
      "     Total: 1.3143 | MSE: 1.4306 | SSIM: 0.8531 | L1: 1.0133\n",
      "   ROC AUC (Combined Scoring): 0.5419 | Best: 0.5520\n",
      "   Learning Rate: 2.44e-09\n",
      "------------------------------------------------------------\n",
      "\n",
      " ENTRENAMIENTO COMPLETADO!\n",
      "   Mejor AUC alcanzado: 0.5520\n",
      "============================================================\n",
      "\n",
      " Entrenamiento finalizado!\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo\n",
    "print(f\"\\n INICIANDO ENTRENAMIENTO DEL MODELO ...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,  #  Usando val_loader en lugar de test_loader\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    output_dir=output_dir,\n",
    "    logs_dir=logs_dir,\n",
    "    model_name=model_name,\n",
    ")\n",
    "\n",
    "print(\"\\n Entrenamiento finalizado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33e4c91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CARGANDO MEJOR MODELO PARA EVALUACIÓN FINAL...\n",
      "Directorio verificado/creado: reports/SwinTransformerAutoencoder_2\n",
      "\n",
      "============================================================\n",
      " REALIZANDO EVALUACIÓN FINAL CON SCORING CONSISTENTE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluación final: 100%|██████████| 55/55 [00:08<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " RESULTADOS FINALES (SCORING CONSISTENTE)\n",
      "============================================================\n",
      "ROC AUC:        0.4977\n",
      "Average Precision: 0.5485\n",
      "Accuracy:       0.5543\n",
      "Precision:      0.5345\n",
      "Recall:         0.9977\n",
      "F1-Score:       0.6961\n",
      "Optimal Threshold: 0.542667\n",
      "============================================================\n",
      " Gráficos de evaluación guardados en: reports/SwinTransformerAutoencoder_2/evaluacion_final_consistente.png\n",
      "Creando visualizaciones en: reports/SwinTransformerAutoencoder_2/examples\n",
      "Total de imágenes: 866\n",
      "Distribución de etiquetas - Normal: 423, Anomalía: 443\n",
      "Distribución de predicciones - Normal: 38, Anomalía: 828\n",
      "True Positives: 443\n",
      "True Negatives: 38\n",
      "False Positives: 385\n",
      "False Negatives: 0\n",
      "Máscaras disponibles: True\n",
      "Creando visualización para true_positive con 5 ejemplos\n",
      "Guardado: reports/SwinTransformerAutoencoder_2/examples/true_positive.png\n",
      "Creando visualización para true_negative con 5 ejemplos\n",
      "Guardado: reports/SwinTransformerAutoencoder_2/examples/true_negative.png\n",
      "Creando visualización para false_positive con 5 ejemplos\n",
      "Guardado: reports/SwinTransformerAutoencoder_2/examples/false_positive.png\n",
      "No hay ejemplos para false_negative\n",
      "Matriz de confusión guardada: reports/SwinTransformerAutoencoder_2/matriz_de_confusion.png\n",
      "Visualizaciones completadas en: reports/SwinTransformerAutoencoder_2/examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluación Final con el conjunto de test independiente\n",
    "print(f\"\\n CARGANDO MEJOR MODELO PARA EVALUACIÓN FINAL...\")\n",
    "\n",
    "# Cargo el mejor modelo autoencoder\n",
    "model.load_state_dict(torch.load(os.path.join(output_dir, f'{model_name}.pth')))\n",
    "\n",
    "# Evaluación final\n",
    "resultados_finales = eval(model, final_test_loader, device, reports_path, model_name, model_type='autoencoder')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa330f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(resultados_finales)\n",
    "threshold = resultados_finales['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7633a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados finales\n",
    "results_to_save = {k: v for k, v in resultados_finales.items() if k not in ['scores', 'labels']}\n",
    "results_to_save = convert_numpy_types(results_to_save)  # Convertir tipos numpy\n",
    "results_file = os.path.join(reports_path+model_name, 'resultados_finales.json')\n",
    "\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results_to_save, f, indent=2)\n",
    "\n",
    "print(f\"\\n Resultados guardados en: {results_file}\")\n",
    "print(\"\\n ¡PROCESO COMPLETADO EXITOSAMENTE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58828f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar mapas de anomalías\n",
    "print(\"Generando mapas de anomalías...\")\n",
    "visualize_anomaly_maps(\n",
    "    model=model,\n",
    "    test_loader=final_test_loader,\n",
    "    device=device,\n",
    "    output_dir=reports_path+model_name,\n",
    "    threshold=threshold\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpc3-grupal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
