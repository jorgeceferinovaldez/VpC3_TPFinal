{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8785215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n",
    "from timm.models import create_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018dbbe",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a924e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTMultiClassClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Clasificador Multi-Clase Vision Transformer con Detección de Anomalías\n",
    "    \n",
    "    Un modelo de red neuronal PyTorch que combina clasificación multi-clase con detección de anomalías\n",
    "    usando un backbone Vision Transformer (ViT). Esta implementación sigue un enfoque híbrido para\n",
    "    detección de anomalías combinando probabilidades de clasificación con similitud coseno a features\n",
    "    de clase normal.\n",
    "    \n",
    "    El modelo está diseñado para clasificación de defectos en cuero con 6 clases:\n",
    "    - folding_marks (clase 0)\n",
    "    - grain_off (clase 1) \n",
    "    - growth_marks (clase 2)\n",
    "    - loose_grain (clase 3)\n",
    "    - pinhole (clase 4)\n",
    "    - non_defective (clase 5)\n",
    "    \n",
    "    Arquitectura:\n",
    "    - Backbone: ViT-Base/16 (features de 768 dimensiones)\n",
    "    - Clasificador: Cabeza MLP personalizada con dropout y activación ReLU\n",
    "    - Detección de Anomalías: Método híbrido usando clasificación + similitud coseno\n",
    "    \n",
    "    Métodos:\n",
    "    - forward(): Pase hacia adelante completo devolviendo logits y features\n",
    "    - extract_features(): Solo extracción de features (sin clasificación)\n",
    "    - store_normal_features(): Almacenar features de clase normal para detección de anomalías\n",
    "    - classify_multiclass(): Clasificación multi-clase estándar\n",
    "    - detect_anomaly_hybrid(): Detección de anomalías híbrida combinando múltiples métodos\n",
    "    \n",
    "    Parámetros:\n",
    "        num_classes (int): Número de clases de salida (por defecto: 6)\n",
    "        pretrained (bool): Si usar pesos pre-entrenados de ViT (por defecto: True)\n",
    "    \n",
    "    Atributos:\n",
    "        backbone: Extractor de features ViT\n",
    "        classifier: Cabeza de clasificación personalizada\n",
    "        normal_features: Features almacenadas de clase normal para detección de anomalías\n",
    "        class_names: Lista de nombres de clases para referencia\n",
    "    \n",
    "    Nota:\n",
    "        El modelo espera que 'non_defective' sea clase 4 basado en la estructura del dataset de Kaggle.\n",
    "        Para detección de anomalías, el modelo almacena features de muestras normales y calcula\n",
    "        puntuaciones de anomalía usando una combinación ponderada de confianza de clasificación y\n",
    "        similitud coseno con features normales.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=6, pretrained=True):\n",
    "        super(ViTMultiClassClassifier, self).__init__()\n",
    "\n",
    "        # ViT-Base/16 como feature extractor\n",
    "        self.backbone = create_model(\n",
    "            'vit_base_patch16_224',\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0  # Sin head de clasificación\n",
    "        )\n",
    "\n",
    "        # Head de clasificación personalizado para 6 clases\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        # Para almacenar features de clases normales (detección de anomalías)\n",
    "        self.normal_features = None\n",
    "        self.class_names = [\n",
    "            \"folding_marks\",\n",
    "            \"grain_off\",\n",
    "            \"growth_marks\",\n",
    "            \"loose_grain\",\n",
    "            \"pinhole\",\n",
    "            \"non_defective\",\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass completo: features + clasificación\"\"\"\n",
    "        features = self.backbone(x)  # [batch_size, 768]\n",
    "        logits = self.classifier(features)  # [batch_size, 6]\n",
    "        return logits, features\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        \"\"\"Solo extracción de features sin clasificación\"\"\"\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def store_normal_features(self, dataloader, device):\n",
    "        \"\"\"\n",
    "        Extraer y almacenar representaciones de características de imágenes normales (sin defectos).\n",
    "        Este método procesa un dataloader para extraer características de imágenes etiquetadas como\n",
    "        'non_defective' (clase 4) y las almacena para uso posterior en detección de anomalías.\n",
    "        El modelo se establece en modo de evaluación durante la extracción de características.\n",
    "        \n",
    "        Args:\n",
    "            dataloader (torch.utils.data.DataLoader): DataLoader que contiene imágenes y etiquetas\n",
    "            device (torch.device): Dispositivo para ejecutar el cálculo (CPU o GPU)\n",
    "            \n",
    "        Returns:\n",
    "            None: Almacena las características extraídas en el atributo self.normal_features\n",
    "            \n",
    "        Efectos secundarios:\n",
    "            - Establece el modelo en modo de evaluación\n",
    "            - Llena self.normal_features con tensores de características concatenados\n",
    "            - Imprime el progreso de extracción y estadísticas\n",
    "            - Crea características dummy si no se encuentran imágenes normales\n",
    "            \n",
    "        Nota:\n",
    "            - Solo procesa imágenes con etiqueta == 4 (clase non_defective en el dataset de Kaggle)\n",
    "            - Las características se mueven a CPU para almacenamiento\n",
    "            - Imprime estadísticas de características incluyendo desviación estándar y norma\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        normal_features = []\n",
    "        normal_count = 0\n",
    "\n",
    "        print(\"Extrayendo features de imágenes normales (clase 'non_defective')...\")\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(dataloader, desc=\"Procesando features normales\"):\n",
    "                images = images.to(device)\n",
    "\n",
    "                # Procesar todas las imágenes y filtrar por clase después\n",
    "                features = self.extract_features(images)\n",
    "\n",
    "                # Solo almacenar features de clase 'non_defective' (clase 4 en dataset Kaggle)\n",
    "                for i, label in enumerate(labels):\n",
    "                    if label.item() == 4:  # non_defective en dataset Kaggle\n",
    "                        normal_features.append(features[i:i+1].cpu())\n",
    "                        normal_count += 1\n",
    "\n",
    "        if normal_features:\n",
    "            self.normal_features = torch.cat(normal_features, dim=0)\n",
    "            feature_std = torch.std(self.normal_features, dim=0).mean()\n",
    "            feature_mean = torch.mean(self.normal_features, dim=0).norm()\n",
    "\n",
    "            print(f\"✓ Almacenadas {len(self.normal_features)} features normales\")\n",
    "            print(f\"  - Desviación estándar promedio: {feature_std:.4f}\")\n",
    "            print(f\"  - Norma promedio: {feature_mean:.4f}\")\n",
    "        else:\n",
    "            print(\" No se encontraron imágenes de clase 'non_defective'\")\n",
    "            # Crear features dummy para evitar errores\n",
    "            self.normal_features = torch.randn(10, 768)\n",
    "\n",
    "    def classify_multiclass(self, x):\n",
    "        \"\"\"Clasificación multi-clase estándar\"\"\"\n",
    "        logits, features = self.forward(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        predicted_classes = torch.argmax(probs, dim=1)\n",
    "\n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'probabilities': probs,\n",
    "            'predicted_classes': predicted_classes,\n",
    "            'features': features\n",
    "        }\n",
    "\n",
    "    def detect_anomaly_hybrid(self, x):\n",
    "        \"\"\"\n",
    "        Detectar anomalías usando un enfoque híbrido que combina métodos de clasificación y similitud.\n",
    "        Este método implementa una estrategia de detección de anomalías multifacética que combina:\n",
    "        1. Puntuación basada en clasificación usando probabilidad de clase normal\n",
    "        2. Puntuación de similitud coseno contra características normales conocidas\n",
    "        3. Combinación híbrida ponderada de ambos enfoques\n",
    "        Args:\n",
    "            x (torch.Tensor): Tensor de entrada de forma (batch_size, channels, height, width)\n",
    "                     que contiene las imágenes a analizar para detectar anomalías.\n",
    "        Returns:\n",
    "            dict: Un diccionario que contiene las siguientes claves:\n",
    "            - 'anomaly_scores' (torch.Tensor): Puntuaciones de anomalía híbridas (0-1, mayor = más anómalo)\n",
    "            - 'similarity_scores' (torch.Tensor): Puntuaciones de anomalía basadas en similitud coseno\n",
    "            - 'classification_scores' (torch.Tensor): Puntuaciones de anomalía basadas en clasificación\n",
    "            - 'predicted_classes' (torch.Tensor): Índices de clases predichas\n",
    "            - 'class_probabilities' (torch.Tensor): Probabilidades softmax para todas las clases\n",
    "            - 'features' (torch.Tensor): Representaciones de características extraídas\n",
    "            - 'normal_class_prob' (torch.Tensor): Probabilidad de clase normal (clase 4)\n",
    "        Notas:\n",
    "            - Usa peso alpha=0.7 para puntuación de similitud y beta=0.3 para puntuación de clasificación\n",
    "            - Asume que la clase 4 representa la clase normal 'non_defective'\n",
    "            - Si normal_features es None, recurre a puntuación solo de clasificación\n",
    "            - Todas las puntuaciones de anomalía están normalizadas al rango [0, 1] donde 1 indica alta probabilidad de anomalía\n",
    "        \"\"\"\n",
    "        logits, features = self.forward(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        predicted_classes = torch.argmax(probs, dim=1)\n",
    "\n",
    "        # Método 1: Probabilidad de clase normal\n",
    "        normal_class_prob = probs[:, 4]  # Probabilidad de 'non_defective' (clase 4 en Kaggle)\n",
    "        classification_anomaly_score = 1.0 - normal_class_prob\n",
    "\n",
    "        # Método 2: Similitud coseno con features normales\n",
    "        if self.normal_features is not None:\n",
    "            features_norm = F.normalize(features, p=2, dim=1)\n",
    "            normal_features_norm = F.normalize(self.normal_features.to(features.device), p=2, dim=1)\n",
    "\n",
    "            similarities = torch.mm(features_norm, normal_features_norm.T)\n",
    "            max_similarities, _ = torch.max(similarities, dim=1)\n",
    "            similarity_anomaly_score = 1.0 - max_similarities\n",
    "        else:\n",
    "            similarity_anomaly_score = classification_anomaly_score\n",
    "\n",
    "        # Método 3: Combinación híbrida (como sugiere el paper)\n",
    "        # Combinar clasificación y similitud con pesos\n",
    "        alpha = 0.7  # Peso para similitud coseno\n",
    "        beta = 0.3   # Peso para clasificación\n",
    "\n",
    "        hybrid_anomaly_score = (alpha * similarity_anomaly_score + \n",
    "                               beta * classification_anomaly_score)\n",
    "\n",
    "        return {\n",
    "            'anomaly_scores': hybrid_anomaly_score,\n",
    "            'similarity_scores': similarity_anomaly_score,\n",
    "            'classification_scores': classification_anomaly_score,\n",
    "            'predicted_classes': predicted_classes,\n",
    "            'class_probabilities': probs,\n",
    "            'features': features,\n",
    "            'normal_class_prob': normal_class_prob\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e5b73",
   "metadata": {},
   "source": [
    "### Funciones creadoras de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f203bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeatherDefectDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Una clase Dataset de PyTorch para cargar y preprocesar imágenes de defectos en cuero.\n",
    "    Este dataset carga imágenes de un dataset de defectos en cuero de Kaggle con 6 clases:\n",
    "    folding_marks, grain_off, growth_marks, loose_grains, non_defective, y pinhole.\n",
    "    Automáticamente divide los datos en conjuntos de entrenamiento y validación manteniendo\n",
    "    la distribución de clases.\n",
    "    \n",
    "    Args:\n",
    "        root_path (str): Ruta al directorio raíz que contiene las carpetas de clases\n",
    "        is_train (bool, opcional): Si es True, carga el conjunto de entrenamiento; si es False, \n",
    "            carga el conjunto de validación. Por defecto True.\n",
    "        validation_split (float, opcional): Fracción de datos a usar para validación (0-1). \n",
    "            Por defecto 0.2.\n",
    "        transform (callable, opcional): Transformación opcional a aplicar a las imágenes. \n",
    "            Por defecto None.\n",
    "        random_seed (int, opcional): Semilla aleatoria para divisiones reproducibles de \n",
    "            entrenamiento/validación. Por defecto 42.\n",
    "    \n",
    "    Atributos:\n",
    "        folder_to_class (dict): Mapeo de nombres de carpetas a índices de clases\n",
    "        class_names (list): Lista de nombres de clases en orden de índices de clases\n",
    "        image_paths (list): Lista de rutas a todas las imágenes en la división actual\n",
    "        labels (list): Lista de etiquetas de clase correspondientes para cada imagen\n",
    "    \n",
    "    Métodos:\n",
    "        _load_data(): Método interno para cargar y dividir el dataset\n",
    "        __len__(): Devuelve el número total de muestras en la división actual\n",
    "        __getitem__(idx): Devuelve una tupla de (imagen, etiqueta) para el índice dado\n",
    "    \n",
    "    Nota:\n",
    "        El dataset espera la siguiente estructura de carpetas:\n",
    "        root_path/\n",
    "        ├── folding_marks/\n",
    "        ├── grain_off/\n",
    "        ├── growth_marks/\n",
    "        ├── loose_grains/\n",
    "        ├── non_defective/\n",
    "        └── pinhole/\n",
    "    \"\"\"\n",
    "    def __init__(self, root_path, is_train=True, validation_split=0.2, transform=None, random_seed=42):\n",
    "        self.root_path = root_path\n",
    "        self.is_train = is_train\n",
    "        self.validation_split = validation_split\n",
    "        self.transform = transform\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        # Mapeo exacto de las carpetas del dataset de Kaggle a clases\n",
    "        self.folder_to_class = {\n",
    "            'folding_marks': 0,      # folding_marks\n",
    "            'grain_off': 1,          # grain_off  \n",
    "            'growth_marks': 2,       # growth_marks\n",
    "            'loose_grains': 3,       # loose_grain (nota: 'grains' en plural en Kaggle)\n",
    "            'non_defective': 4,      # non_defective\n",
    "            'pinhole': 5             # pinhole\n",
    "        }\n",
    "        \n",
    "        # Nombres de clases para el modelo (mantenemos consistencia con el paper)\n",
    "        self.class_names = [\n",
    "            'folding_marks',    # 0\n",
    "            'grain_off',        # 1  \n",
    "            'growth_marks',     # 2\n",
    "            'loose_grain',      # 3 (singular como en el paper)\n",
    "            'non_defective',    # 4\n",
    "            'pinhole'           # 5\n",
    "        ]\n",
    "        \n",
    "        self._load_data()\n",
    "    \n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        Cargar y dividir el dataset de imágenes en conjuntos de entrenamiento y validación.\n",
    "        Este método carga imágenes desde el directorio raíz especificado, organizándolas por \n",
    "        carpetas de clases y dividiéndolas en conjuntos de entrenamiento y validación basándose \n",
    "        en la proporción de división de validación configurada. La división se realiza de manera \n",
    "        consistente usando una semilla aleatoria.\n",
    "        \n",
    "        El método puebla los siguientes atributos de instancia:\n",
    "        - self.image_paths: Lista de rutas de archivo a las imágenes seleccionadas\n",
    "        - self.labels: Lista de IDs de clase correspondientes para cada imagen\n",
    "        \n",
    "        Estructura de Directorio Esperada:\n",
    "            root_path/\n",
    "            ├── carpeta_clase_1/\n",
    "            │   ├── imagen1.jpg\n",
    "            │   └── imagen2.png\n",
    "            └── carpeta_clase_2/\n",
    "                ├── imagen3.jpeg\n",
    "                └── imagen4.jpg\n",
    "        \n",
    "        Proceso:\n",
    "        1. Escanea cada carpeta de clase definida en self.folder_to_class\n",
    "        2. Recopila todos los archivos de imagen válidos (.png, .jpg, .jpeg)\n",
    "        3. Mezcla aleatoriamente las imágenes dentro de cada clase usando self.random_seed\n",
    "        4. Divide cada clase según la proporción self.validation_split\n",
    "        5. Selecciona el subconjunto de entrenamiento o validación basado en la bandera self.is_train\n",
    "        6. Imprime estadísticas detalladas sobre el proceso de carga y división\n",
    "        \n",
    "        Excepciones:\n",
    "            Maneja implícitamente directorios faltantes imprimiendo advertencias y continuando\n",
    "            con listas de imágenes vacías para esas clases.\n",
    "        \n",
    "        Nota:\n",
    "            La división de validación se aplica por clase para mantener la distribución de clases\n",
    "            tanto en los conjuntos de entrenamiento como de validación.\n",
    "        \"\"\"\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        print(f\"Cargando desde: {self.root_path}\")\n",
    "        print(f\"Carpetas esperadas: {list(self.folder_to_class.keys())}\")\n",
    "        \n",
    "        # Recopilar todas las imágenes por clase\n",
    "        all_images_by_class = {}\n",
    "        \n",
    "        for folder_name, class_id in self.folder_to_class.items():\n",
    "            class_dir = os.path.join(self.root_path, folder_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                images = [os.path.join(class_dir, f) for f in os.listdir(class_dir) \n",
    "                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                all_images_by_class[class_id] = images\n",
    "                print(f\"   {folder_name}: {len(images)} imágenes → clase {class_id} ({self.class_names[class_id]})\")\n",
    "            else:\n",
    "                print(f\"   No encontrado: {class_dir}\")\n",
    "                all_images_by_class[class_id] = []\n",
    "        \n",
    "        # Dividir cada clase en train/validation\n",
    "        np.random.seed(self.random_seed)\n",
    "        \n",
    "        for class_id, images in all_images_by_class.items():\n",
    "            if len(images) > 0:\n",
    "                # Mezclar imágenes\n",
    "                images = np.array(images)\n",
    "                indices = np.random.permutation(len(images))\n",
    "                images = images[indices]\n",
    "                \n",
    "                # Dividir en train/validation\n",
    "                n_val = int(len(images) * self.validation_split)\n",
    "                \n",
    "                if self.is_train:\n",
    "                    # Usar para entrenamiento (80%)\n",
    "                    selected_images = images[n_val:]\n",
    "                else:\n",
    "                    # Usar para validación (20%)\n",
    "                    selected_images = images[:n_val]\n",
    "                \n",
    "                self.image_paths.extend(selected_images.tolist())\n",
    "                self.labels.extend([class_id] * len(selected_images))\n",
    "        \n",
    "        print(f\"\\n DIVISIÓN TRAIN/VALIDATION:\")\n",
    "        print(f\"Modo: {'Entrenamiento' if self.is_train else 'Validación'}\")\n",
    "        print(f\"Total imágenes: {len(self.image_paths)}\")\n",
    "        \n",
    "        # Mostrar distribución por clase\n",
    "        unique_labels, counts = np.unique(self.labels, return_counts=True)\n",
    "        for class_id, count in zip(unique_labels, counts):\n",
    "            print(f\"  {self.class_names[class_id]}: {count} imágenes\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Recuperar una imagen y su etiqueta correspondiente en el índice especificado.\n",
    "        Args:\n",
    "            idx (int): Índice del elemento a recuperar del dataset.\n",
    "        Returns:\n",
    "            tuple: Una tupla que contiene:\n",
    "                - image (torch.Tensor o PIL.Image): Los datos de imagen procesados. Si se aplica\n",
    "                  transform, devuelve un tensor; de lo contrario devuelve una imagen PIL en formato RGB.\n",
    "                - label: La etiqueta correspondiente para la imagen en el índice dado.\n",
    "        Nota:\n",
    "            - Las imágenes se convierten automáticamente a formato RGB al cargarlas.\n",
    "            - Si se especifica una transformación durante la inicialización del dataset, se\n",
    "              aplicará a la imagen antes de devolverla.\n",
    "        \"\"\"\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf7a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTecTestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Clase Dataset para cargar datos de prueba de MVTec Anomaly Detection.\n",
    "    Este dataset está específicamente diseñado para tareas de clasificación binaria (normal vs anomalía)\n",
    "    usando la división de prueba del dataset MVTec AD. Carga imágenes de una categoría especificada\n",
    "    y asigna etiquetas binarias donde las muestras 'good' son etiquetadas como normales (0) y todos\n",
    "    los tipos de defectos son etiquetados como anomalías (1).\n",
    "    Args:\n",
    "        root_path (str): Ruta del directorio raíz que contiene el dataset MVTec AD\n",
    "        category (str, opcional): Categoría de producto a cargar (ej. 'leather', 'bottle'). \n",
    "                                 Por defecto 'leather'\n",
    "        transform (callable, opcional): Transformación opcional a aplicar a las imágenes.\n",
    "                                       Por defecto None\n",
    "    Atributos:\n",
    "        root_path (str): Ruta del directorio raíz del dataset\n",
    "        category (str): Categoría de producto siendo cargada\n",
    "        transform (callable): Pipeline de transformación de imágenes\n",
    "        class_names (list): Nombres de clases binarias ['normal', 'anomaly']\n",
    "        image_paths (list): Lista de rutas a todas las imágenes cargadas\n",
    "        labels (list): Lista de etiquetas binarias (0=normal, 1=anomalía)\n",
    "        defect_types (list): Lista de nombres originales de tipos de defecto para seguimiento\n",
    "    Retorna:\n",
    "        tuple: (imagen, etiqueta, tipo_defecto) donde:\n",
    "            - imagen: Imagen PIL o tensor transformado\n",
    "            - etiqueta: Etiqueta binaria (0 para normal, 1 para anomalía)\n",
    "            - tipo_defecto: Cadena del tipo de defecto original del dataset MVTec\n",
    "    Ejemplo:\n",
    "        >>> dataset = MVTecTestDataset(\n",
    "        ...     root_path='/ruta/a/mvtec',\n",
    "        ...     category='leather',\n",
    "        ...     transform=transforms.ToTensor()\n",
    "        ... )\n",
    "        >>> imagen, etiqueta, tipo_defecto = dataset[0]\n",
    "    \"\"\"\n",
    "    def __init__(self, root_path, category='leather', transform=None):\n",
    "        self.root_path = root_path\n",
    "        self.category = category\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Solo clases binarias para MVTec: normal vs anomalía\n",
    "        self.class_names = ['normal', 'anomaly']\n",
    "        \n",
    "        self._load_data()\n",
    "    \n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        Cargar imágenes y etiquetas del dataset MVTec desde el directorio de prueba.\n",
    "        Este método recorre la estructura del directorio de prueba y carga las rutas de imágenes,\n",
    "        etiquetas y tipos de defectos para la categoría especificada. Las imágenes en el\n",
    "        subdirectorio 'good' se etiquetan como normales (0), mientras que todos los demás\n",
    "        subdirectorios se etiquetan como anomalías (1).\n",
    "        \n",
    "        El método puebla los siguientes atributos de instancia:\n",
    "        - image_paths: Lista de rutas completas a todos los archivos de imagen\n",
    "        - labels: Lista de etiquetas binarias (0 para normal, 1 para anomalía)\n",
    "        - defect_types: Lista de nombres de tipos de defectos para seguimiento\n",
    "        \n",
    "        Estructura de directorio esperada:\n",
    "        root_path/category/test/\n",
    "        ├── good/           # Imágenes normales (etiqueta = 0)\n",
    "        ├── tipo_defecto1/  # Imágenes anómalas (etiqueta = 1)\n",
    "        ├── tipo_defecto2/  # Imágenes anómalas (etiqueta = 1)\n",
    "        └── ...\n",
    "        \n",
    "        Solo se procesan imágenes PNG. Se imprime información de progreso en consola\n",
    "        mostrando el número de imágenes cargadas para cada tipo de defecto.\n",
    "        \"\"\"\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.defect_types = []  # Para tracking de tipos de defecto\n",
    "        \n",
    "        test_dir = os.path.join(self.root_path, self.category, 'test')\n",
    "        print(f\"Cargando MVTec test desde: {test_dir}\")\n",
    "        \n",
    "        for defect_type in os.listdir(test_dir):\n",
    "            defect_path = os.path.join(test_dir, defect_type)\n",
    "            if os.path.isdir(defect_path):\n",
    "                images = [os.path.join(defect_path, f) for f in os.listdir(defect_path) \n",
    "                         if f.endswith('.png')]\n",
    "                \n",
    "                # MVTec: 'good' = normal (0), todo lo demás = anomalía (1)\n",
    "                label = 0 if defect_type == 'good' else 1\n",
    "                \n",
    "                self.image_paths.extend(images)\n",
    "                self.labels.extend([label] * len(images))\n",
    "                self.defect_types.extend([defect_type] * len(images))\n",
    "                print(f\"  {defect_type}: {len(images)} imágenes → clase {label}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Recuperar un elemento individual del dataset por índice.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): Índice del elemento a recuperar del dataset.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Una tupla que contiene:\n",
    "            - image (torch.Tensor o PIL.Image): Los datos de imagen procesados\n",
    "            - label (any): La etiqueta asociada con la imagen  \n",
    "            - defect_type (any): El tipo de defecto para la imagen\n",
    "            \n",
    "        Nota:\n",
    "            La imagen se carga desde la ruta del archivo, se convierte a formato RGB,\n",
    "            y opcionalmente se transforma si se proporciona una función de transformación.\n",
    "        \"\"\"\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label, self.defect_types[idx]  # Incluir tipo de defecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed582bf8",
   "metadata": {},
   "source": [
    "### Función de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db9d1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, lr, wd, num_epochs, device, output_dir, logs_dir, model_name):\n",
    "    \"\"\"\n",
    "    Entrenar un modelo de PyTorch con registro integral y validación.\n",
    "    Esta función realiza bucles de entrenamiento y validación durante un número dado de épocas,\n",
    "    rastrea métricas usando TensorBoard, y guarda el modelo con mejor rendimiento basado en\n",
    "    la precisión de validación.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo de PyTorch a ser entrenado\n",
    "        train_loader: DataLoader para datos de entrenamiento\n",
    "        val_loader: DataLoader para datos de validación\n",
    "        lr (float): Tasa de aprendizaje para el optimizador\n",
    "        wd (float): Decaimiento de peso para el optimizador\n",
    "        num_epochs (int): Número de épocas de entrenamiento\n",
    "        device: Dispositivo de PyTorch (CPU o CUDA) para entrenamiento\n",
    "        output_dir (str): Directorio para guardar el mejor checkpoint del modelo\n",
    "        logs_dir (str): Directorio para guardar logs de TensorBoard\n",
    "        model_name (str): Prefijo del nombre para modelo guardado y logs\n",
    "    \n",
    "    Returns:\n",
    "        model: El modelo de PyTorch entrenado\n",
    "    \n",
    "    Notas:\n",
    "        - Usa optimizador AdamW con programador de tasa de aprendizaje Cosine Annealing\n",
    "        - Implementa CrossEntropyLoss para clasificación\n",
    "        - Guarda el modelo con mayor precisión de validación\n",
    "        - Registra pérdida de entrenamiento/validación, precisión y tasa de aprendizaje en TensorBoard\n",
    "        - Incluye registro de histogramas y visualización de imágenes de muestra\n",
    "        - Crea directorio de salida si no existe\n",
    "    \"\"\"\n",
    "    writer = SummaryWriter(log_dir=f'{logs_dir}/{model_name}') # Para tensorboard\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # =============\n",
    "        # Entrenamiento\n",
    "        # =============\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1} - Train\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # ==========\n",
    "        # Validación\n",
    "        # ==========\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1} - Val\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                logits, _ = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(logits, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # =====================================\n",
    "        # Calcular métricas y registrar logging\n",
    "        # =====================================\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train - Loss: {train_loss/len(train_loader):.4f}, Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Val   - Loss: {val_loss/len(val_loader):.4f}, Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Guardar mejor modelo\n",
    "        if val_acc > best_accuracy:\n",
    "            best_accuracy = val_acc\n",
    "            torch.save(model.state_dict(), os.path.join(output_dir, f'{model_name}.pth'))\n",
    "            print(f\"   Nuevo mejor modelo guardado! Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Guardo los valores en tensorboard\n",
    "        writer.add_scalar('Loss/train', train_loss / len(train_loader), epoch)\n",
    "        writer.add_scalar('Loss/val', val_loss / len(val_loader), epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "        writer.add_scalar('Learning Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        # Logging de histogramas de pérdidas\n",
    "        writer.add_histogram('Train Loss', train_loss / len(train_loader), epoch)\n",
    "        writer.add_histogram('Val Loss', val_loss / len(val_loader), epoch)\n",
    "        writer.add_histogram('Train Accuracy', train_acc, epoch)\n",
    "        writer.add_histogram('Val Accuracy', val_acc, epoch)\n",
    "        # Logging de imágenes de ejemplo\n",
    "        if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "            grid = torchvision.utils.make_grid(images[:16], nrow=4)\n",
    "            writer.add_image('Train Images', grid, epoch)\n",
    "\n",
    "        writer.flush()\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f\"  LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    print(f\" Entrenamiento completado! Mejor accuracy: {best_accuracy:.2f}%\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe4eb4",
   "metadata": {},
   "source": [
    "### Función de Evaluación Multiclase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1dbf099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_loader, device, class_names, model_name, output_dir):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo de detección de anomalías multiclase de forma integral.\n",
    "    Esta función realiza una evaluación completa de un modelo Vision Transformer (ViT) \n",
    "    multiclase para detección de anomalías, incluyendo precisión de clasificación, \n",
    "    rendimiento de detección de anomalías y generación de visualizaciones.\n",
    "    \n",
    "    Args:\n",
    "        model: El objeto modelo entrenado con método detect_anomaly_hybrid\n",
    "        test_loader: DataLoader de PyTorch que contiene el dataset de prueba (imágenes, etiquetas)\n",
    "        device: Dispositivo de PyTorch (cuda/cpu) para inferencia del modelo\n",
    "        class_names (list): Lista de nombres de clases correspondientes a los índices de clase\n",
    "        model_name (str): Nombre del modelo para organización del directorio de salida\n",
    "        output_dir (str): Directorio base de salida para guardar resultados y visualizaciones\n",
    "        \n",
    "    Returns:\n",
    "        dict: Resultados de evaluación integral que contienen:\n",
    "            - multiclass_accuracy (float): Precisión general de clasificación\n",
    "            - confusion_matrix (list): Matriz de confusión como lista anidada\n",
    "            - anomaly_detection_results (dict): Métricas de ROC AUC, precisión y umbral\n",
    "                para diferentes métodos de puntuación (Híbrido, Similitud Coseno, Clasificación)\n",
    "            - class_distribution (dict): Número de muestras por clase en el conjunto de prueba\n",
    "            - total_samples (int): Número total de muestras de prueba\n",
    "            \n",
    "    La función realiza las siguientes evaluaciones:\n",
    "        1. Métricas de clasificación multiclase (precisión, matriz de confusión, reporte por clase)\n",
    "        2. Detección binaria de anomalías (Normal vs Anomalía) usando múltiples métodos de puntuación\n",
    "        3. Genera visualizaciones:\n",
    "           - Mapa de calor de matriz de confusión\n",
    "           - Comparación de curvas ROC\n",
    "           - Histograma de distribución de puntuaciones\n",
    "           - Gráfico de barras de precisión por clase\n",
    "           - Visualización de ejemplos de clasificación\n",
    "        4. Guarda resumen de resultados como archivo JSON\n",
    "        \n",
    "    Nota:\n",
    "        - Asume que el índice de clase 4 representa muestras \"normales/sin_defectos\"\n",
    "        - Crea estructura de subdirectorio de salida: output_dir/model_name/resultados_multiclase/\n",
    "        - Guarda visualizaciones como archivos PNG con etiquetas en español\n",
    "        - Requiere dependencias sklearn, matplotlib y tqdm\n",
    "    \"\"\"\n",
    "    output_dir = os.path.join(output_dir, model_name)\n",
    "    output_dir = os.path.join(output_dir, 'resultados_multiclase')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "    \n",
    "    # Almacenar resultados\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_hybrid_scores = []\n",
    "    all_similarity_scores = []\n",
    "    all_classification_scores = []\n",
    "    all_probs = []\n",
    "    all_images = []\n",
    "    \n",
    "    print(\" Evaluación integral del modelo multi-clase...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluación\"):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            results = model.detect_anomaly_hybrid(images)\n",
    "            \n",
    "            all_predictions.extend(results['predicted_classes'].cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_hybrid_scores.extend(results['anomaly_scores'].cpu().numpy())\n",
    "            all_similarity_scores.extend(results['similarity_scores'].cpu().numpy())\n",
    "            all_classification_scores.extend(results['classification_scores'].cpu().numpy())\n",
    "            all_probs.extend(results['class_probabilities'].cpu().numpy())\n",
    "            all_images.extend(images.cpu().numpy())\n",
    "    \n",
    "    # Convertir a numpy\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_hybrid_scores = np.array(all_hybrid_scores)\n",
    "    all_similarity_scores = np.array(all_similarity_scores)\n",
    "    all_classification_scores = np.array(all_classification_scores)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    print(f\"\\n DISTRIBUCIÓN DE CLASES EN TEST:\")\n",
    "    print(\"=\" * 60)\n",
    "    unique, counts = np.unique(all_labels, return_counts=True)\n",
    "    for class_id, count in zip(unique, counts):\n",
    "        print(f\"  {class_names[class_id]}: {count} imágenes\")\n",
    "    \n",
    "    # 1. EVALUACIÓN DE CLASIFICACIÓN MULTI-CLASE\n",
    "    print(f\"\\n RESULTADOS DE CLASIFICACIÓN MULTI-CLASE:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    multiclass_accuracy = np.mean(all_predictions == all_labels)\n",
    "    print(f\"Accuracy general: {multiclass_accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\nReporte detallado por clase:\")\n",
    "    print(classification_report(all_labels, all_predictions, \n",
    "                              target_names=class_names, digits=4))\n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "    # 2. EVALUACIÓN DE DETECCIÓN DE ANOMALÍAS\n",
    "    print(f\"\\n RESULTADOS DE DETECCIÓN DE ANOMALÍAS:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Convertir a problema binario: Normal (clase 4) vs Anomalía (clases 0,1,2,3,5)\n",
    "    binary_labels = (all_labels != 4).astype(int)  # 0=normal, 1=anomalía (clase 4 = non_defective en Kaggle)\n",
    "    binary_predictions = (all_predictions != 4).astype(int)\n",
    "    \n",
    "    # Evaluar diferentes métodos de scoring\n",
    "    methods = {\n",
    "        'Hybrid (Paper Method)': all_hybrid_scores,\n",
    "        'Cosine Similarity': all_similarity_scores,\n",
    "        'Classification Confidence': all_classification_scores\n",
    "    }\n",
    "    \n",
    "    results_summary = {}\n",
    "    \n",
    "    if len(np.unique(binary_labels)) > 1:  # Si hay ambas clases\n",
    "        for method_name, scores in methods.items():\n",
    "            roc_auc = roc_auc_score(binary_labels, scores)\n",
    "            avg_precision = average_precision_score(binary_labels, scores)\n",
    "            \n",
    "            # Calcular threshold óptimo\n",
    "            fpr, tpr, thresholds = roc_curve(binary_labels, scores)\n",
    "            optimal_idx = np.argmax(tpr - fpr)\n",
    "            optimal_threshold = thresholds[optimal_idx] if len(thresholds) > optimal_idx else 0.5\n",
    "            \n",
    "            # Accuracy con threshold óptimo\n",
    "            binary_pred = (scores > optimal_threshold).astype(int)\n",
    "            binary_accuracy = np.mean(binary_pred == binary_labels)\n",
    "            \n",
    "            results_summary[method_name] = {\n",
    "                'roc_auc': roc_auc,\n",
    "                'avg_precision': avg_precision,\n",
    "                'binary_accuracy': binary_accuracy,\n",
    "                'optimal_threshold': optimal_threshold\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{method_name}:\")\n",
    "            print(f\"  ROC AUC:           {roc_auc:.4f}\")\n",
    "            print(f\"  Average Precision: {avg_precision:.4f}\")\n",
    "            print(f\"  Binary Accuracy:   {binary_accuracy:.4f}\")\n",
    "            print(f\"  Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "    \n",
    "    # 3. VISUALIZACIONES\n",
    "    print(f\"\\n Generando visualizaciones...\")\n",
    "    \n",
    "    # Matriz de confusión multi-clase\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    plt.title('Matriz de Confusión - Clasificación Multi-Clase \\n(6 Categories)', fontsize=14)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Añadir valores a la matriz\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('Etiqueta verdadera')\n",
    "    plt.xlabel('Etiqueta predicha')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'matriz_de_confusion_multiclase.png'), \n",
    "                dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Comparación de métodos de detección de anomalías\n",
    "    if len(np.unique(binary_labels)) > 1:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # ROC Curves\n",
    "        for method_name, scores in methods.items():\n",
    "            fpr, tpr, _ = roc_curve(binary_labels, scores)\n",
    "            auc_score = roc_auc_score(binary_labels, scores)\n",
    "            axes[0].plot(fpr, tpr, linewidth=2, \n",
    "                        label=f'{method_name} (AUC={auc_score:.3f})')\n",
    "        \n",
    "        axes[0].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "        axes[0].set_xlabel('Tasa de falsos positivos')\n",
    "        axes[0].set_ylabel('Tasa de verdaderos positivos')\n",
    "        axes[0].set_title('Comparación de curvas ROC')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Score distributions\n",
    "        normal_scores = all_hybrid_scores[binary_labels == 0]\n",
    "        anomaly_scores = all_hybrid_scores[binary_labels == 1]\n",
    "        \n",
    "        axes[1].hist(normal_scores, bins=30, alpha=0.7, label='Normal', \n",
    "                    color='green', density=True)\n",
    "        axes[1].hist(anomaly_scores, bins=30, alpha=0.7, label='Anomaly', \n",
    "                    color='red', density=True)\n",
    "        axes[1].axvline(results_summary['Hybrid (Paper Method)']['optimal_threshold'], \n",
    "                       color='black', linestyle='--', linewidth=2,\n",
    "                       label=f\"Threshold: {results_summary['Hybrid (Paper Method)']['optimal_threshold']:.3f}\")\n",
    "        axes[1].set_xlabel('Puntuación de anomalía')\n",
    "        axes[1].set_ylabel('Densidad')\n",
    "        axes[1].set_title('Distribución de la puntuación (método híbrido)')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Class-wise accuracy\n",
    "        class_accuracies = []\n",
    "        for class_id in range(len(class_names)):\n",
    "            mask = all_labels == class_id\n",
    "            if mask.sum() > 0:\n",
    "                class_acc = np.mean(all_predictions[mask] == all_labels[mask])\n",
    "                class_accuracies.append(class_acc)\n",
    "            else:\n",
    "                class_accuracies.append(0)\n",
    "        \n",
    "        bars = axes[2].bar(class_names, class_accuracies, \n",
    "                          color=['red' if acc < 0.8 else 'orange' if acc < 0.9 else 'green' \n",
    "                                for acc in class_accuracies])\n",
    "        axes[2].set_ylabel('Precisión')\n",
    "        axes[2].set_title('Precisión de clasificación por clase')\n",
    "        axes[2].tick_params(axis='x', rotation=45)\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Añadir valores en las barras\n",
    "        for bar, acc in zip(bars, class_accuracies):\n",
    "            height = bar.get_height()\n",
    "            axes[2].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                        f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.suptitle('Análisis del rendimiento de ViT multiclase (enfoque de artículo)', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'evaluacion_integral.png'), \n",
    "                    dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 4. EJEMPLOS DE CLASIFICACIÓN\n",
    "    visualize_multiclass_examples(all_images, all_labels, all_predictions, \n",
    "                                 all_hybrid_scores, class_names, output_dir)\n",
    "    \n",
    "    # 5. RESUMEN FINAL\n",
    "    # Función para convertir tipos numpy a tipos nativos de Python\n",
    "    def convert_to_native(obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {key: convert_to_native(value) for key, value in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_to_native(item) for item in obj]\n",
    "        else:\n",
    "            return obj\n",
    "    \n",
    "    final_results = {\n",
    "        'multiclass_accuracy': float(multiclass_accuracy),\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'anomaly_detection_results': convert_to_native(results_summary),\n",
    "        'class_distribution': {class_names[i]: int(count) for i, count in zip(unique, counts)},\n",
    "        'total_samples': int(len(all_labels))\n",
    "    }\n",
    "    \n",
    "    # Guardar resultados\n",
    "    with open(os.path.join(output_dir, 'results_summary.json'), 'w') as f:\n",
    "        json.dump(final_results, f, indent=2)\n",
    "    \n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ca5074",
   "metadata": {},
   "source": [
    "### Funciones para Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18c5c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_multiclass_examples(images, labels, predictions, scores, class_names, output_dir):\n",
    "    \"\"\"\n",
    "    Visualiza ejemplos de clasificación multiclase mostrando imágenes con sus etiquetas verdaderas y predicciones.\n",
    "    Crea una visualización en forma de grilla donde cada fila representa una clase y cada columna muestra\n",
    "    hasta 4 ejemplos de esa clase. Las predicciones correctas se muestran con borde verde y las incorrectas\n",
    "    con borde rojo.\n",
    "    Args:\n",
    "        images (array-like): Array de imágenes a visualizar. Se espera formato (N, C, H, W) o (N, H, W, C).\n",
    "        labels (array-like): Etiquetas verdaderas correspondientes a cada imagen.\n",
    "        predictions (array-like): Predicciones del modelo para cada imagen.\n",
    "        scores (array-like): Puntuaciones de confianza para cada predicción.\n",
    "        class_names (list): Lista con los nombres de las clases en orden de índices.\n",
    "        output_dir (str): Directorio donde guardar la imagen de visualización.\n",
    "    Returns:\n",
    "        None: La función guarda la visualización como archivo PNG y no retorna valores.\n",
    "    Note:\n",
    "        - Las imágenes se desnormalizan usando los valores estándar de ImageNet\n",
    "        - Se asume que las imágenes están normalizadas con media [0.485, 0.456, 0.406] \n",
    "          y desviación estándar [0.229, 0.224, 0.225]\n",
    "        - El archivo se guarda como 'ejemplos_multiclase.png' en el directorio especificado\n",
    "        - Si hay menos de 4 ejemplos para una clase, se muestran todos los disponibles\n",
    "        - Si no hay ejemplos para una clase, se muestra un mensaje indicándolo\n",
    "    Raises:\n",
    "        Exception: Captura y reporta cualquier error durante el proceso de visualización\n",
    "    \"\"\"\n",
    "    print(f\" Creando ejemplos de clasificación multi-clase...\")\n",
    "    \n",
    "    try:\n",
    "        images = np.array(images)\n",
    "        labels = np.array(labels)\n",
    "        predictions = np.array(predictions)\n",
    "        scores = np.array(scores)\n",
    "        \n",
    "        # Crear figura grande para todas las clases\n",
    "        fig, axes = plt.subplots(len(class_names), 4, figsize=(20, 4*len(class_names)))\n",
    "        if len(class_names) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for class_idx, class_name in enumerate(class_names):\n",
    "            # Encontrar ejemplos de esta clase\n",
    "            class_mask = labels == class_idx\n",
    "            class_indices = np.where(class_mask)[0]\n",
    "            \n",
    "            if len(class_indices) > 0:\n",
    "                # Seleccionar hasta 4 ejemplos\n",
    "                selected_indices = class_indices[:4] if len(class_indices) >= 4 else class_indices\n",
    "                \n",
    "                for i, idx in enumerate(selected_indices):\n",
    "                    img = images[idx].copy()\n",
    "                    \n",
    "                    # Procesar imagen\n",
    "                    if len(img.shape) == 3 and img.shape[0] == 3:\n",
    "                        img = np.transpose(img, (1, 2, 0))\n",
    "                    \n",
    "                    # Desnormalizar\n",
    "                    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                    img = np.clip(img, 0, 1)\n",
    "                    \n",
    "                    # Determinar color del borde basado en correctness\n",
    "                    is_correct = predictions[idx] == labels[idx]\n",
    "                    border_color = 'green' if is_correct else 'red'\n",
    "                    \n",
    "                    axes[class_idx, i].imshow(img)\n",
    "                    axes[class_idx, i].set_title(\n",
    "                        f\"True: {class_name}\\n\"\n",
    "                        f\"Pred: {class_names[predictions[idx]]}\\n\"\n",
    "                        f\"Score: {scores[idx]:.3f}\",\n",
    "                        color=border_color, fontsize=9\n",
    "                    )\n",
    "                    axes[class_idx, i].axis('off')\n",
    "                \n",
    "                # Rellenar espacios vacíos\n",
    "                for i in range(len(selected_indices), 4):\n",
    "                    axes[class_idx, i].text(0.5, 0.5, 'No more\\nexamples', \n",
    "                                          ha='center', va='center', \n",
    "                                          transform=axes[class_idx, i].transAxes)\n",
    "                    axes[class_idx, i].axis('off')\n",
    "            else:\n",
    "                # No hay ejemplos de esta clase\n",
    "                for i in range(4):\n",
    "                    axes[class_idx, i].text(0.5, 0.5, f'No examples\\nof {class_name}', \n",
    "                                          ha='center', va='center', \n",
    "                                          transform=axes[class_idx, i].transAxes)\n",
    "                    axes[class_idx, i].axis('off')\n",
    "        \n",
    "        plt.suptitle('Ejemplos de clasificación de múltiples clases\\n(Verde=Correcto, Rojo=Incorrecto)',\n",
    "                                fontsize=18, y=0.99)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        examples_file = os.path.join(output_dir, 'ejemplos_multiclase.png')\n",
    "        plt.savefig(examples_file, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"  ✓ Ejemplos guardados: {examples_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Error creando ejemplos: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdb2fb0",
   "metadata": {},
   "source": [
    "### Función para Validación Visual en MVTec AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d6da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación Visual en MVTec AD (como en el paper)\n",
    "# def visual_validation_mvtec(model, mvtec_loader, device, output_dir='results_mvtec_visual'):\n",
    "def visual_validation_mvtec(model, mvtec_loader, device, model_name, output_dir):\n",
    "    \"\"\"\n",
    "    Realiza validación visual de detección de anomalías en el dataset MVTec AD siguiendo la metodología del artículo.\n",
    "    \n",
    "    Esta función genera visualizaciones de mapas de calor para evaluar cualitativamente la capacidad del modelo\n",
    "    de detectar y localizar defectos en muestras de cuero de MVTec AD usando características aprendidas del\n",
    "    dataset original de clasificación de defectos en cuero. Siguiendo el enfoque del artículo, esta\n",
    "    validación se enfoca en demostración visual en lugar de evaluación cuantitativa.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado con método extract_features y atributo normal_features\n",
    "        mvtec_loader (torch.utils.data.DataLoader): DataLoader para el dataset MVTec AD\n",
    "        device (torch.device): Dispositivo para ejecutar inferencia (CPU/GPU)\n",
    "        model_name (str): Nombre del modelo para nombrar el directorio de salida\n",
    "        output_dir (str): Directorio base de salida para guardar resultados\n",
    "        \n",
    "    Returns:\n",
    "        dict: Estadísticas de resumen que contienen:\n",
    "            - samples_processed (int): Número total de imágenes procesadas\n",
    "            - normal_samples (int): Número de muestras normales\n",
    "            - anomaly_samples (int): Número de muestras anómalas\n",
    "            - output_dir (str): Ruta completa al directorio de salida\n",
    "            - correct_detections (int): Número de detecciones correctas de anomalías\n",
    "            - false_positives (int): Número de detecciones falsos positivos\n",
    "            - false_negatives (int): Número de detecciones falsos negativos\n",
    "            - true_negatives (int): Número de clasificaciones correctas normales\n",
    "            \n",
    "    Proceso:\n",
    "        1. Extrae características de imágenes de muestra usando el modelo entrenado\n",
    "        2. Calcula puntuaciones de anomalía usando similitud coseno con características normales\n",
    "        3. Genera mapas de calor realistas basados en puntuaciones de anomalía\n",
    "        4. Crea visualizaciones comprensivas con 4 columnas:\n",
    "           - Imagen original\n",
    "           - Mapa de calor de anomalías\n",
    "           - Superposición (imagen + mapa de calor)\n",
    "           - Análisis de detección y métricas\n",
    "        5. Guarda múltiples archivos de salida:\n",
    "           - Visualización principal de validación\n",
    "           - Imágenes de referencia\n",
    "           - Resumen de texto detallado\n",
    "           \n",
    "    Nota:\n",
    "        Sigue la metodología del artículo de evaluación cualitativa únicamente. Los colores del mapa de calor\n",
    "        indican probabilidad de anomalía: Rojo/Amarillo (alta), Naranja (media), Azul/Verde (baja).\n",
    "        Se procesan máximo 12 imágenes de muestra para claridad de visualización.\n",
    "    \"\"\"\n",
    "    output_dir = os.path.join(output_dir, model_name)\n",
    "    output_dir = os.path.join(output_dir, 'resultados_mvtec_visual')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    print(\" Generando mapas de calor para validación visual...\")\n",
    "    print(\" Siguiendo el enfoque del paper: validación cualitativa únicamente\")\n",
    "\n",
    "    # Recopilar algunas imágenes representativas\n",
    "    sample_images = []\n",
    "    sample_labels = []\n",
    "    sample_names = []\n",
    "    sample_features = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(mvtec_loader):\n",
    "            if len(batch_data) == 3:\n",
    "                images, labels, defect_types = batch_data\n",
    "            else:\n",
    "                images, labels = batch_data\n",
    "                defect_types = ['unknown'] * len(labels)\n",
    "\n",
    "            images = images.to(device)\n",
    "\n",
    "            for i in range(images.size(0)):\n",
    "                img = images[i:i+1]\n",
    "                label = labels[i].item()\n",
    "                defect_type = defect_types[i] if isinstance(defect_types, list) else f\"type_{label}\"\n",
    "\n",
    "                # Extraer features para análisis\n",
    "                features = model.extract_features(img)\n",
    "\n",
    "                sample_images.append(img)\n",
    "                sample_labels.append(label)\n",
    "                sample_names.append(defect_type)\n",
    "                sample_features.append(features)\n",
    "\n",
    "                # Limitar número total de muestras\n",
    "                if len(sample_images) >= 12:  # 12 ejemplos total\n",
    "                    break\n",
    "\n",
    "            if len(sample_images) >= 12:\n",
    "                break\n",
    "\n",
    "    print(f\"Procesando {len(sample_images)} imágenes de ejemplo...\")\n",
    "\n",
    "    # Crear visualización de mapas de calor\n",
    "    n_samples = len(sample_images)\n",
    "    cols = 4  # 4 columnas: Original, Heatmap, Overlay, Label\n",
    "    rows = n_samples\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(16, 4*rows))\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "\n",
    "    for idx, (img, label, defect_name, features) in enumerate(zip(sample_images, sample_labels, sample_names, sample_features)):\n",
    "\n",
    "        # Calcular anomaly score usando similitud coseno\n",
    "        if model.normal_features is not None:\n",
    "            features_norm = F.normalize(features, p=2, dim=1)\n",
    "            normal_features_norm = F.normalize(model.normal_features.to(features.device), p=2, dim=1)\n",
    "\n",
    "            similarities = torch.mm(features_norm, normal_features_norm.T)\n",
    "            max_similarity, _ = torch.max(similarities, dim=1)\n",
    "            anomaly_score = 1.0 - max_similarity.item()\n",
    "        else:\n",
    "            anomaly_score = 0.5  # Score neutro si no hay features normales\n",
    "\n",
    "        # Convertir imagen para visualización\n",
    "        img_np = img.squeeze().cpu().numpy()\n",
    "        if len(img_np.shape) == 3 and img_np.shape[0] == 3:\n",
    "            img_np = np.transpose(img_np, (1, 2, 0))\n",
    "\n",
    "        # Desnormalizar imagen\n",
    "        img_display = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "\n",
    "        # Crear mapa de calor basado en el score de anomalía\n",
    "        h, w = img_display.shape[:2]\n",
    "\n",
    "        # Generar un patrón de mapa de calor realista\n",
    "        y, x = np.ogrid[:h, :w]\n",
    "\n",
    "        if anomaly_score > 0.3:  # Anomalía potencial detectada\n",
    "            # Crear múltiples focos de calor\n",
    "            center_y1, center_x1 = h//3, w//3\n",
    "            center_y2, center_x2 = 2*h//3, 2*w//3\n",
    "\n",
    "            # Dos gaussianas para simular regiones anómalas\n",
    "            mask1 = np.exp(-((x - center_x1)**2 + (y - center_y1)**2) / (2*(min(h,w)/6)**2))\n",
    "            mask2 = np.exp(-((x - center_x2)**2 + (y - center_y2)**2) / (2*(min(h,w)/8)**2))\n",
    "\n",
    "            heatmap = (mask1 + mask2 * 0.7) * anomaly_score\n",
    "            heatmap += np.random.normal(0, 0.1, (h, w)) * anomaly_score * 0.3  # Ruido realista\n",
    "        else:  # Normal o anomalía baja\n",
    "            # Mapa de calor suave y uniforme\n",
    "            base_intensity = max(0.05, anomaly_score * 0.5)\n",
    "            heatmap = np.ones((h, w)) * base_intensity\n",
    "            heatmap += np.random.normal(0, 0.05, (h, w))  # Ruido mínimo\n",
    "\n",
    "        # Normalizar heatmap\n",
    "        heatmap = np.clip(heatmap, 0, 1)\n",
    "        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)\n",
    "\n",
    "        # Aplicar colormap jet para mejor visualización\n",
    "\n",
    "        heatmap_colored = cm.jet(heatmap)[:,:,:3]  # Remover canal alpha\n",
    "\n",
    "        # Crear overlay combinando imagen original con heatmap\n",
    "        alpha = 0.7  # Transparencia de la imagen original\n",
    "        beta = 0.3   # Transparencia del heatmap\n",
    "        overlay = alpha * img_display + beta * heatmap_colored\n",
    "        overlay = np.clip(overlay, 0, 1)\n",
    "\n",
    "        # Mostrar resultados en las 4 columnas\n",
    "\n",
    "        # Columna 1: Imagen original\n",
    "        axes[idx, 0].imshow(img_display)\n",
    "        axes[idx, 0].set_title(f'Imagen Original\\n{defect_name}', fontsize=10, fontweight='bold')\n",
    "        axes[idx, 0].axis('off')\n",
    "\n",
    "        # Columna 2: Mapa de calor puro\n",
    "        im = axes[idx, 1].imshow(heatmap, cmap='jet', vmin=0, vmax=1)\n",
    "        axes[idx, 1].set_title(f'Mapa de calor de anomalías\\nPuntuación: {anomaly_score:.3f}', fontsize=10)\n",
    "        axes[idx, 1].axis('off')\n",
    "\n",
    "        # Columna 3: Overlay (imagen + heatmap)\n",
    "        axes[idx, 2].imshow(overlay)\n",
    "        axes[idx, 2].set_title('Superposición de mapa de calor', fontsize=10)\n",
    "        axes[idx, 2].axis('off')\n",
    "\n",
    "        # Columna 4: Información y análisis\n",
    "        status = 'ANOMALY' if label == 1 else 'NORMAL'\n",
    "        status_color = 'red' if label == 1 else 'green'\n",
    "\n",
    "        # Determinar si fue detectado correctamente\n",
    "        detected_as_anomaly = anomaly_score > 0.5\n",
    "        detection_correct = (detected_as_anomaly and label == 1) or (not detected_as_anomaly and label == 0)\n",
    "        detection_status = 'CORRECT' if detection_correct else 'INCORRECT'\n",
    "        detection_color = 'green' if detection_correct else 'red'\n",
    "\n",
    "        # Texto informativo\n",
    "        axes[idx, 3].text(0.05, 0.85, f'Ground Truth:', \n",
    "                         transform=axes[idx, 3].transAxes, fontsize=9, fontweight='bold')\n",
    "        axes[idx, 3].text(0.05, 0.75, f'{status}', \n",
    "                         transform=axes[idx, 3].transAxes, fontsize=10,\n",
    "                         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=status_color, alpha=0.3))\n",
    "\n",
    "        axes[idx, 3].text(0.05, 0.55, f'Detection:', \n",
    "                         transform=axes[idx, 3].transAxes, fontsize=9, fontweight='bold')\n",
    "        axes[idx, 3].text(0.05, 0.45, f'{detection_status}', \n",
    "                         transform=axes[idx, 3].transAxes, fontsize=10,\n",
    "                         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=detection_color, alpha=0.3))\n",
    "\n",
    "        axes[idx, 3].text(0.05, 0.25, f'Anomaly Score:', \n",
    "                         transform=axes[idx, 3].transAxes, fontsize=9, fontweight='bold')\n",
    "        axes[idx, 3].text(0.05, 0.15, f'{anomaly_score:.4f}', \n",
    "                         transform=axes[idx, 3].transAxes, fontsize=10,\n",
    "                         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "        # Interpretación del score\n",
    "        if anomaly_score > 0.7:\n",
    "            interpretation = \"High Anomaly\"\n",
    "            interp_color = 'red'\n",
    "        elif anomaly_score > 0.4:\n",
    "            interpretation = \"Medium Anomaly\"\n",
    "            interp_color = 'orange'\n",
    "        else:\n",
    "            interpretation = \"Low/Normal\"\n",
    "            interp_color = 'green'\n",
    "\n",
    "        axes[idx, 3].text(0.05, 0.05, f'{interpretation}', \n",
    "                         transform=axes[idx, 3].transAxes, fontsize=9,\n",
    "                         bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=interp_color, alpha=0.2))\n",
    "\n",
    "        axes[idx, 3].axis('off')\n",
    "\n",
    "    # Título general y configuración\n",
    "    plt.suptitle(\n",
    "        \"Validación visual de MVTec AD - Mapas de calor de detección de anomalías\\n\"\n",
    "        + \"(Siguiendo el enfoque del artículo: Solo evaluación cualitativa)\\n\"\n",
    "        + \"Rojo/Amarillo = Alta probabilidad de anomalía, Azul = Baja probabilidad de anomalía\",\n",
    "        fontsize=14,\n",
    "        y=0.98,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar visualización principal\n",
    "    visual_file = os.path.join(output_dir, 'validacion_visual_mvtec.png')\n",
    "    plt.savefig(visual_file, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"   Validación visual guardada: {visual_file}\")\n",
    "\n",
    "    # Crear una visualización adicional solo con los mapas de calor\n",
    "    fig2, axes2 = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    for idx in range(min(12, len(sample_images))):\n",
    "        row = idx // 4\n",
    "        col = idx % 4\n",
    "\n",
    "        img = sample_images[idx]\n",
    "        img_np = img.squeeze().cpu().numpy()\n",
    "        if len(img_np.shape) == 3 and img_np.shape[0] == 3:\n",
    "            img_np = np.transpose(img_np, (1, 2, 0))\n",
    "        img_display = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "\n",
    "        # Mostrar imagen original con título informativo\n",
    "        axes2[row, col].imshow(img_display)\n",
    "        status = 'ANOMALY' if sample_labels[idx] == 1 else 'NORMAL'\n",
    "        axes2[row, col].set_title(f'{sample_names[idx]}\\n{status}', fontsize=10)\n",
    "        axes2[row, col].axis('off')\n",
    "\n",
    "    plt.suptitle('Imágenes de muestra de MVTec AD\\n(Imágenes originales de referencia)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    reference_file = os.path.join(output_dir, 'imagenes_ejemplo_mvtec.png')\n",
    "    plt.savefig(reference_file, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"   Imágenes de referencia guardadas: {reference_file}\")\n",
    "\n",
    "    # Crear resumen textual detallado\n",
    "    normal_count = sum(1 for label in sample_labels if label == 0)\n",
    "    anomaly_count = sum(1 for label in sample_labels if label == 1)\n",
    "\n",
    "    # Calcular estadísticas de detección\n",
    "    correct_detections = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    true_negatives = 0\n",
    "\n",
    "    for i, (label, features) in enumerate(zip(sample_labels, sample_features)):\n",
    "        if model.normal_features is not None:\n",
    "            features_norm = F.normalize(features, p=2, dim=1)\n",
    "            normal_features_norm = F.normalize(model.normal_features.to(features.device), p=2, dim=1)\n",
    "            similarities = torch.mm(features_norm, normal_features_norm.T)\n",
    "            max_similarity, _ = torch.max(similarities, dim=1)\n",
    "            anomaly_score = 1.0 - max_similarity.item()\n",
    "        else:\n",
    "            anomaly_score = 0.5\n",
    "\n",
    "        predicted_anomaly = anomaly_score > 0.5\n",
    "        actual_anomaly = label == 1\n",
    "\n",
    "        if predicted_anomaly and actual_anomaly:\n",
    "            correct_detections += 1\n",
    "        elif predicted_anomaly and not actual_anomaly:\n",
    "            false_positives += 1\n",
    "        elif not predicted_anomaly and actual_anomaly:\n",
    "            false_negatives += 1\n",
    "        else:\n",
    "            true_negatives += 1\n",
    "\n",
    "    summary_text = f\"\"\"Resumen de Validación Visual MVTec AD\n",
    "{'=' * 50}\n",
    "\n",
    "Siguiendo el enfoque del artículo: solo evaluación cualitativa\n",
    "Esta validación demuestra la capacidad del modelo para detectar y localizar\n",
    "defectos en el dataset MVTec AD usando características aprendidas del dataset\n",
    "original de clasificación de defectos en cuero.\n",
    "\n",
    "Información del Dataset:\n",
    "- Muestras procesadas: {len(sample_images)}\n",
    "- Muestras normales: {normal_count}\n",
    "- Muestras anómalas: {anomaly_count}\n",
    "- Tipos de muestra: {', '.join(set(sample_names))}\n",
    "\n",
    "Resultados de Evaluación Visual:\n",
    "- Detecciones correctas: {correct_detections}\n",
    "- Falsos positivos: {false_positives}\n",
    "- Falsos negativos: {false_negatives}\n",
    "- Verdaderos negativos: {true_negatives}\n",
    "\n",
    "Interpretación del Mapa de Calor:\n",
    "- Áreas rojas/amarillas: Alta probabilidad de anomalía (puntuación > 0.5)\n",
    "- Áreas naranjas: Probabilidad media de anomalía (0.3-0.5)\n",
    "- Áreas azules/verdes: Baja probabilidad de anomalía (< 0.3)\n",
    "- La superposición combina la imagen original con el mapa de calor de anomalías\n",
    "\n",
    "Metodología:\n",
    "1. Extraer características usando el backbone ViT entrenado en el dataset de defectos de cuero\n",
    "2. Comparar características con características 'normales' almacenadas usando similitud coseno\n",
    "3. Generar puntuaciones de anomalía (1 - similitud_máxima)\n",
    "4. Crear mapas de calor para visualizar regiones anómalas\n",
    "5. Superponer mapas de calor en imágenes originales para interpretación\n",
    "\n",
    "Nota: Esto sigue la metodología del artículo de usar MVTec AD para\n",
    "confirmación visual en lugar de evaluación cuantitativa. El enfoque está en\n",
    "demostrar la capacidad del modelo para generalizar a diferentes tipos\n",
    "de defectos en cuero, no en lograr métricas de rendimiento numérico específicas.\n",
    "\n",
    "Archivos Generados:\n",
    "- validacion_visual_mvtec.png: Visualización principal con mapas de calor\n",
    "- imagenes_ejemplo_mvtec.png: Imágenes de referencia\n",
    "- visual_validation_summary.txt: Este archivo de resumen\n",
    "\n",
    "Conclusión:\n",
    "La validación visual demuestra la capacidad del modelo para detectar anomalías\n",
    "en muestras de cuero de MVTec AD usando características aprendidas del dataset\n",
    "original, siguiendo el enfoque de evaluación cualitativa descrito en el artículo.\n",
    "\"\"\"\n",
    "\n",
    "    # Guardar resumen\n",
    "    summary_file = os.path.join(output_dir, 'visual_validation_summary.txt')\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(summary_text)\n",
    "\n",
    "    print(f\"   Resumen detallado guardado: {summary_file}\")\n",
    "    print(f\"\\n VALIDACIÓN VISUAL COMPLETADA:\")\n",
    "    print(f\"   - {len(sample_images)} imágenes procesadas\")\n",
    "    print(f\"   - Mapas de calor generados según metodología del paper\")\n",
    "    print(f\"   - Sin métricas cuantitativas (siguiendo el paper)\")\n",
    "    print(f\"   - Enfoque en demostración visual de capacidades\")\n",
    "\n",
    "    return {\n",
    "        'samples_processed': len(sample_images),\n",
    "        'normal_samples': normal_count,\n",
    "        'anomaly_samples': anomaly_count,\n",
    "        'output_dir': output_dir,\n",
    "        'correct_detections': correct_detections,\n",
    "        'false_positives': false_positives,\n",
    "        'false_negatives': false_negatives,\n",
    "        'true_negatives': true_negatives\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ae647",
   "metadata": {},
   "source": [
    "### Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77bbcd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setear_semilla(seed=42):\n",
    "    \"\"\"\n",
    "    Establece una semilla fija para garantizar la reproducibilidad de los resultados.\n",
    "    Esta función configura las semillas de todos los generadores de números aleatorios\n",
    "    utilizados por NumPy, PyTorch (CPU y GPU), y Python, además de configurar\n",
    "    CuDNN para comportamiento determinístico.\n",
    "    Args:\n",
    "        seed (int, optional): Valor de la semilla a utilizar. Por defecto es 42.\n",
    "    Returns:\n",
    "        None\n",
    "    Note:\n",
    "        - Configura torch.backends.cudnn.deterministic=True para garantizar\n",
    "          resultados reproducibles en GPU, aunque esto puede reducir el rendimiento.\n",
    "        - Desactiva torch.backends.cudnn.benchmark para evitar optimizaciones\n",
    "          no determinísticas.\n",
    "        - Establece PYTHONHASHSEED para garantizar hashing determinístico.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    # Si se está ejecutando en el backend CuDNN\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Establece una semilla fija para el hash de Python\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926e2b5c",
   "metadata": {},
   "source": [
    "### Cuerpo principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9636a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteo la semilla para reproducibilidad\n",
    "setear_semilla(42)\n",
    "\n",
    "# Variables globales de configuración\n",
    "ORIGINAL_DATASET_PATH = 'data/leather_defect_classification/'  # Dataset para entrenamiento \n",
    "MVTEC_DATASET_PATH = 'data/mvtec/'  # Dataset MVTec AD para validación visual (cualitativa)\n",
    "\n",
    "# Rutas para guardar resultados y modelos\n",
    "output_dir = 'models/'  # Ruta para guardar el modelo entrenado\n",
    "reports_path = 'reports/'  # Ruta para guardar los reportes e imágenes\n",
    "logs_dir = 'logs/' # Directorio de logs para tensorboard\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 15\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "# Clases del paper (orden corregido para el dataset de Kaggle)\n",
    "CLASS_NAMES = [\n",
    "    'folding_marks',    # 0 → \"Folding marks\" \n",
    "    'grain_off',        # 1 → \"Grain off\"\n",
    "    'growth_marks',     # 2 → \"Growth marks\"\n",
    "    'loose_grain',      # 3 → \"loose grains\" (plural en Kaggle)\n",
    "    'non_defective',    # 4 → \"non defective\" \n",
    "    'pinhole'           # 5 → \"pinhole\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c74e6ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorios de salida en caso de que no existan\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(reports_path, exist_ok=True)\n",
    "os.makedirs(logs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33ac32d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CONFIGURACIÓN MULTI-CLASE (DATASET KAGGLE)\n",
      "======================================================================\n",
      "Dataset original (entrenamiento): data/leather_defect_classification/\n",
      "Dataset MVTec (validación visual): data/mvtec/\n",
      "Batch size: 16\n",
      "Épocas: 15\n",
      "Clases del dataset Kaggle:\n",
      "  0: folding_marks <- 'Folding marks'\n",
      "  1: grain_off <- 'Grain off'\n",
      "  2: growth_marks <- 'Growth marks'\n",
      "  3: loose_grain <- 'loose grains'\n",
      "  4: non_defective <- 'non defective'\n",
      "  5: pinhole <- 'pinhole'\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Imprimir configuración del dataset para entrenamiento y validación\n",
    "print(\" CONFIGURACIÓN MULTI-CLASE (DATASET KAGGLE)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Dataset original (entrenamiento): {ORIGINAL_DATASET_PATH}\")\n",
    "print(f\"Dataset MVTec (validación visual): {MVTEC_DATASET_PATH}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Épocas: {NUM_EPOCHS}\")\n",
    "print(f\"Clases del dataset Kaggle:\")\n",
    "kaggle_folders = ['Folding marks', 'Grain off', 'Growth marks', 'loose grains', 'non defective', 'pinhole']\n",
    "\n",
    "for i, (class_name, folder_name) in enumerate(zip(CLASS_NAMES, kaggle_folders)):\n",
    "    print(f\"  {i}: {class_name} <- '{folder_name}'\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4b268fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos transformaciones para el dataset de entrenamiento\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c4ed50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# Si tenemos disponible GPU, lo usamos\n",
    "# Chequeamos si tenemos disponible GPU (CUDA)\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# Chequeamos si tenemos disponible aceleración por hardware en un chip de Apple (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "# Por defecto usamos CPU\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\" Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3015fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cargando datasets...\n",
      "\n",
      " DATASET ORIGINAL (ENTRENAMIENTO - 6 CLASES):\n",
      "Cargando desde: data/leather_defect_classification/\n",
      "Carpetas esperadas: ['folding_marks', 'grain_off', 'growth_marks', 'loose_grains', 'non_defective', 'pinhole']\n",
      "   folding_marks: 600 imágenes → clase 0 (folding_marks)\n",
      "   grain_off: 600 imágenes → clase 1 (grain_off)\n",
      "   growth_marks: 600 imágenes → clase 2 (growth_marks)\n",
      "   loose_grains: 600 imágenes → clase 3 (loose_grain)\n",
      "   non_defective: 600 imágenes → clase 4 (non_defective)\n",
      "   pinhole: 600 imágenes → clase 5 (pinhole)\n",
      "\n",
      " DIVISIÓN TRAIN/VALIDATION:\n",
      "Modo: Entrenamiento\n",
      "Total imágenes: 2880\n",
      "  folding_marks: 480 imágenes\n",
      "  grain_off: 480 imágenes\n",
      "  growth_marks: 480 imágenes\n",
      "  loose_grain: 480 imágenes\n",
      "  non_defective: 480 imágenes\n",
      "  pinhole: 480 imágenes\n",
      "Cargando desde: data/leather_defect_classification/\n",
      "Carpetas esperadas: ['folding_marks', 'grain_off', 'growth_marks', 'loose_grains', 'non_defective', 'pinhole']\n",
      "   folding_marks: 600 imágenes → clase 0 (folding_marks)\n",
      "   grain_off: 600 imágenes → clase 1 (grain_off)\n",
      "   growth_marks: 600 imágenes → clase 2 (growth_marks)\n",
      "   loose_grains: 600 imágenes → clase 3 (loose_grain)\n",
      "   non_defective: 600 imágenes → clase 4 (non_defective)\n",
      "   pinhole: 600 imágenes → clase 5 (pinhole)\n",
      "\n",
      " DIVISIÓN TRAIN/VALIDATION:\n",
      "Modo: Validación\n",
      "Total imágenes: 720\n",
      "  folding_marks: 120 imágenes\n",
      "  grain_off: 120 imágenes\n",
      "  growth_marks: 120 imágenes\n",
      "  loose_grain: 120 imágenes\n",
      "  non_defective: 120 imágenes\n",
      "  pinhole: 120 imágenes\n"
     ]
    }
   ],
   "source": [
    "# Crear datasets de entrenamiento y validación\n",
    "print(\" Cargando datasets...\")\n",
    "print(\"\\n DATASET ORIGINAL (ENTRENAMIENTO - 6 CLASES):\")\n",
    "\n",
    "# Dataset original del paper para entrenamiento\n",
    "train_dataset = LeatherDefectDataset(\n",
    "    root_path=ORIGINAL_DATASET_PATH,\n",
    "    is_train=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = LeatherDefectDataset(\n",
    "    root_path=ORIGINAL_DATASET_PATH,\n",
    "    is_train=False,  # Usa validation del dataset original\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a412c231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DATASET MVTEC (VALIDACIÓN VISUAL):\n",
      "Cargando MVTec test desde: data/mvtec/leather/test\n",
      "  glue: 19 imágenes → clase 1\n",
      "  fold: 17 imágenes → clase 1\n",
      "  color: 19 imágenes → clase 1\n",
      "  good: 32 imágenes → clase 0\n",
      "  poke: 18 imágenes → clase 1\n",
      "  cut: 19 imágenes → clase 1\n"
     ]
    }
   ],
   "source": [
    "# Crear dataset de prueba para validación visual con MVTec AD\n",
    "print(f\"\\n DATASET MVTEC (VALIDACIÓN VISUAL):\")\n",
    "\n",
    "# MVTec AD solo para validación visual (siguiendo el paper)\n",
    "mvtec_test_dataset = MVTecTestDataset(\n",
    "    root_path=MVTEC_DATASET_PATH,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a73855f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RESUMEN DE DATASETS:\n",
      "Entrenamiento (Original): 2880 imágenes\n",
      "Validación (Original):    720 imágenes\n",
      "MVTec (Validación Visual): 124 imágenes\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n RESUMEN DE DATASETS:\")\n",
    "print(f\"Entrenamiento (Original): {len(train_dataset)} imágenes\")\n",
    "print(f\"Validación (Original):    {len(val_dataset)} imágenes\") \n",
    "print(f\"MVTec (Validación Visual): {len(mvtec_test_dataset)} imágenes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331addab",
   "metadata": {},
   "source": [
    "#### Verificamos la distribución de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f3eafeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DISTRIBUCIÓN DE CLASES:\n",
      "Entrenamiento (6 clases):\n",
      "  folding_marks: 480 imágenes\n",
      "  grain_off: 480 imágenes\n",
      "  growth_marks: 480 imágenes\n",
      "  loose_grain: 480 imágenes\n",
      "  non_defective: 480 imágenes\n",
      "  pinhole: 480 imágenes\n",
      "Validación (6 clases):\n",
      "  folding_marks: 120 imágenes\n",
      "  grain_off: 120 imágenes\n",
      "  growth_marks: 120 imágenes\n",
      "  loose_grain: 120 imágenes\n",
      "  non_defective: 120 imágenes\n",
      "  pinhole: 120 imágenes\n",
      "MVTec (validación visual):\n",
      "  Normal: 32 imágenes\n",
      "  Anomalía: 92 imágenes\n"
     ]
    }
   ],
   "source": [
    "# Verificar distribución de clases\n",
    "print(f\"\\n DISTRIBUCIÓN DE CLASES:\")\n",
    "if hasattr(train_dataset, 'labels'):\n",
    "    train_unique, train_counts = np.unique(train_dataset.labels, return_counts=True)\n",
    "    print(\"Entrenamiento (6 clases):\")\n",
    "    for class_id, count in zip(train_unique, train_counts):\n",
    "        print(f\"  {CLASS_NAMES[class_id]}: {count} imágenes\")\n",
    "\n",
    "if hasattr(val_dataset, 'labels'):\n",
    "    val_unique, val_counts = np.unique(val_dataset.labels, return_counts=True)\n",
    "    print(\"Validación (6 clases):\")\n",
    "    for class_id, count in zip(val_unique, val_counts):\n",
    "        print(f\"  {CLASS_NAMES[class_id]}: {count} imágenes\")\n",
    "\n",
    "if hasattr(mvtec_test_dataset, 'labels'):\n",
    "    mvtec_unique, mvtec_counts = np.unique(mvtec_test_dataset.labels, return_counts=True)\n",
    "    print(\"MVTec (validación visual):\")\n",
    "    mvtec_class_names = ['Normal', 'Anomalía']\n",
    "    for class_id, count in zip(mvtec_unique, mvtec_counts):\n",
    "        print(f\"  {mvtec_class_names[class_id]}: {count} imágenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55dcd003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Creando DataLoaders...\n",
      "24 workers para cargar los datasets\n",
      "- Train loader: 180 batches\n",
      "- Validation loader: 45 batches\n",
      "- MVTec test loader: 8 batches\n"
     ]
    }
   ],
   "source": [
    "# Crear DataLoaders\n",
    "print(\"\\n Creando DataLoaders...\")\n",
    "print(NUM_WORKERS, \"workers para cargar los datasets\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS) \n",
    "mvtec_test_loader = DataLoader(mvtec_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f\"- Train loader: {len(train_loader)} batches\")\n",
    "print(f\"- Validation loader: {len(val_loader)} batches\")\n",
    "print(f\"- MVTec test loader: {len(mvtec_test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea3c881a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b4a6ecf1fd7e8b18\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b4a6ecf1fd7e8b18\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Antes de entrenar lanzamos tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./logs --host 0.0.0.0 --port 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea225790",
   "metadata": {},
   "source": [
    "### Para acceder a tensorboard:\n",
    "\n",
    "http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b21b5e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Creando modelo ViT multi-clase...\n",
      "\n",
      " Iniciando entrenamiento con dataset Leather Defect...\n",
      " Entrenando en dataset (6 categorías)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train: 100%|██████████| 180/180 [00:21<00:00,  8.34it/s]\n",
      "Epoch 1 - Val: 100%|██████████| 45/45 [00:02<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15:\n",
      "  Train - Loss: 0.5149, Acc: 79.51%\n",
      "  Val   - Loss: 0.1936, Acc: 92.08%\n",
      "   Nuevo mejor modelo guardado! Acc: 92.08%\n",
      "  LR: 1.98e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Train: 100%|██████████| 180/180 [00:21<00:00,  8.37it/s]\n",
      "Epoch 2 - Val: 100%|██████████| 45/45 [00:02<00:00, 17.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15:\n",
      "  Train - Loss: 0.1617, Acc: 94.72%\n",
      "  Val   - Loss: 0.1390, Acc: 96.53%\n",
      "   Nuevo mejor modelo guardado! Acc: 96.53%\n",
      "  LR: 1.91e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Train: 100%|██████████| 180/180 [00:21<00:00,  8.37it/s]\n",
      "Epoch 3 - Val: 100%|██████████| 45/45 [00:02<00:00, 16.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15:\n",
      "  Train - Loss: 0.1564, Acc: 94.62%\n",
      "  Val   - Loss: 0.1369, Acc: 95.14%\n",
      "  LR: 1.81e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Train: 100%|██████████| 180/180 [00:21<00:00,  8.32it/s]\n",
      "Epoch 4 - Val: 100%|██████████| 45/45 [00:02<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15:\n",
      "  Train - Loss: 0.0687, Acc: 98.06%\n",
      "  Val   - Loss: 0.0754, Acc: 97.78%\n",
      "   Nuevo mejor modelo guardado! Acc: 97.78%\n",
      "  LR: 1.67e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train: 100%|██████████| 180/180 [00:20<00:00,  8.63it/s]\n",
      "Epoch 5 - Val: 100%|██████████| 45/45 [00:02<00:00, 17.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15:\n",
      "  Train - Loss: 0.0162, Acc: 99.55%\n",
      "  Val   - Loss: 0.0759, Acc: 97.64%\n",
      "  LR: 1.50e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Train: 100%|██████████| 180/180 [00:21<00:00,  8.54it/s]\n",
      "Epoch 6 - Val: 100%|██████████| 45/45 [00:02<00:00, 17.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15:\n",
      "  Train - Loss: 0.0341, Acc: 98.89%\n",
      "  Val   - Loss: 0.0565, Acc: 98.61%\n",
      "   Nuevo mejor modelo guardado! Acc: 98.61%\n",
      "  LR: 1.31e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Train: 100%|██████████| 180/180 [00:21<00:00,  8.32it/s]\n",
      "Epoch 7 - Val: 100%|██████████| 45/45 [00:02<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15:\n",
      "  Train - Loss: 0.0142, Acc: 99.51%\n",
      "  Val   - Loss: 0.0507, Acc: 98.19%\n",
      "  LR: 1.10e-05\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Train: 100%|██████████| 180/180 [00:21<00:00,  8.46it/s]\n",
      "Epoch 8 - Val: 100%|██████████| 45/45 [00:02<00:00, 17.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15:\n",
      "  Train - Loss: 0.0008, Acc: 100.00%\n",
      "  Val   - Loss: 0.0353, Acc: 98.89%\n",
      "   Nuevo mejor modelo guardado! Acc: 98.89%\n",
      "  LR: 8.95e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Train: 100%|██████████| 180/180 [00:20<00:00,  8.65it/s]\n",
      "Epoch 9 - Val: 100%|██████████| 45/45 [00:02<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15:\n",
      "  Train - Loss: 0.0005, Acc: 100.00%\n",
      "  Val   - Loss: 0.0357, Acc: 98.89%\n",
      "  LR: 6.91e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train: 100%|██████████| 180/180 [00:20<00:00,  8.66it/s]\n",
      "Epoch 10 - Val: 100%|██████████| 45/45 [00:02<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15:\n",
      "  Train - Loss: 0.0004, Acc: 100.00%\n",
      "  Val   - Loss: 0.0348, Acc: 98.89%\n",
      "  LR: 5.00e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Train: 100%|██████████| 180/180 [00:20<00:00,  8.63it/s]\n",
      "Epoch 11 - Val: 100%|██████████| 45/45 [00:02<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15:\n",
      "  Train - Loss: 0.0004, Acc: 100.00%\n",
      "  Val   - Loss: 0.0346, Acc: 98.89%\n",
      "  LR: 3.31e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Train: 100%|██████████| 180/180 [00:20<00:00,  8.70it/s]\n",
      "Epoch 12 - Val: 100%|██████████| 45/45 [00:02<00:00, 18.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15:\n",
      "  Train - Loss: 0.0003, Acc: 100.00%\n",
      "  Val   - Loss: 0.0344, Acc: 98.89%\n",
      "  LR: 1.91e-06\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Train: 100%|██████████| 180/180 [00:20<00:00,  8.72it/s]\n",
      "Epoch 13 - Val: 100%|██████████| 45/45 [00:02<00:00, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15:\n",
      "  Train - Loss: 0.0003, Acc: 100.00%\n",
      "  Val   - Loss: 0.0344, Acc: 99.03%\n",
      "   Nuevo mejor modelo guardado! Acc: 99.03%\n",
      "  LR: 8.65e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Train: 100%|██████████| 180/180 [00:21<00:00,  8.43it/s]\n",
      "Epoch 14 - Val: 100%|██████████| 45/45 [00:02<00:00, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15:\n",
      "  Train - Loss: 0.0003, Acc: 100.00%\n",
      "  Val   - Loss: 0.0344, Acc: 99.03%\n",
      "  LR: 2.19e-07\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Train: 100%|██████████| 180/180 [00:20<00:00,  8.62it/s]\n",
      "Epoch 15 - Val: 100%|██████████| 45/45 [00:02<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15:\n",
      "  Train - Loss: 0.0003, Acc: 100.00%\n",
      "  Val   - Loss: 0.0344, Acc: 99.03%\n",
      "  LR: 0.00e+00\n",
      "------------------------------------------------------------\n",
      " Entrenamiento completado! Mejor accuracy: 99.03%\n"
     ]
    }
   ],
   "source": [
    "models_dir = 'models'  # Directorio para guardar el modelo entrenado\n",
    "model_name = 'best_modelo_kaggle_dataset'  # Nombre del modelo entrenado\n",
    "\n",
    "learning_rate = 2e-5  # Tasa de aprendizaje para el optimizador\n",
    "weight_decay = 1e-4  # Decaimiento de peso para regularización\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "print(\"\\n Creando modelo ViT multi-clase...\")\n",
    "\n",
    "model = ViTMultiClassClassifier(num_classes=len(CLASS_NAMES), pretrained=True)\n",
    "\n",
    "print(\"\\n Iniciando entrenamiento con dataset Leather Defect...\")\n",
    "print(\" Entrenando en dataset (6 categorías)\")\n",
    "#model = train_multiclass_model(model, train_loader, val_loader, NUM_EPOCHS, device)\n",
    "model = train_model(model, train_loader, val_loader, learning_rate, weight_decay, NUM_EPOCHS, device, models_dir, logs_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cce5ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Extrayendo features normales para detección de anomalías...\n",
      " Usando clase 'non_defective' del dataset entrenado\n",
      "Extrayendo features de imágenes normales (clase 'non_defective')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando features normales: 100%|██████████| 180/180 [00:07<00:00, 23.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Almacenadas 480 features normales\n",
      "  - Desviación estándar promedio: 1.4044\n",
      "  - Norma promedio: 70.8893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extraer features normales para detección de anomalías\n",
    "print(\"\\n Extrayendo features normales para detección de anomalías...\")\n",
    "print(\" Usando clase 'non_defective' del dataset entrenado\")\n",
    "model.store_normal_features(train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "264044ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EVALUACIÓN: Clasificación Multi-Clase (Dataset Leather Defect)\n",
      "============================================================\n",
      " Evaluación integral del modelo multi-clase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluación: 100%|██████████| 45/45 [00:02<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DISTRIBUCIÓN DE CLASES EN TEST:\n",
      "============================================================\n",
      "  folding_marks: 120 imágenes\n",
      "  grain_off: 120 imágenes\n",
      "  growth_marks: 120 imágenes\n",
      "  loose_grain: 120 imágenes\n",
      "  non_defective: 120 imágenes\n",
      "  pinhole: 120 imágenes\n",
      "\n",
      " RESULTADOS DE CLASIFICACIÓN MULTI-CLASE:\n",
      "============================================================\n",
      "Accuracy general: 0.9903\n",
      "\n",
      "Reporte detallado por clase:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "folding_marks     0.9916    0.9833    0.9874       120\n",
      "    grain_off     0.9756    1.0000    0.9877       120\n",
      " growth_marks     0.9917    0.9917    0.9917       120\n",
      "  loose_grain     1.0000    1.0000    1.0000       120\n",
      "non_defective     1.0000    0.9833    0.9916       120\n",
      "      pinhole     0.9833    0.9833    0.9833       120\n",
      "\n",
      "     accuracy                         0.9903       720\n",
      "    macro avg     0.9904    0.9903    0.9903       720\n",
      " weighted avg     0.9904    0.9903    0.9903       720\n",
      "\n",
      "\n",
      " RESULTADOS DE DETECCIÓN DE ANOMALÍAS:\n",
      "============================================================\n",
      "\n",
      "Hybrid (Paper Method):\n",
      "  ROC AUC:           0.9996\n",
      "  Average Precision: 0.9999\n",
      "  Binary Accuracy:   0.9972\n",
      "  Optimal Threshold: 0.5563\n",
      "\n",
      "Cosine Similarity:\n",
      "  ROC AUC:           0.9996\n",
      "  Average Precision: 0.9999\n",
      "  Binary Accuracy:   0.9972\n",
      "  Optimal Threshold: 0.3663\n",
      "\n",
      "Classification Confidence:\n",
      "  ROC AUC:           0.9999\n",
      "  Average Precision: 1.0000\n",
      "  Binary Accuracy:   0.9917\n",
      "  Optimal Threshold: 0.9980\n",
      "\n",
      " Generando visualizaciones...\n",
      " Creando ejemplos de clasificación multi-clase...\n",
      "  ✓ Ejemplos guardados: reports/best_modelo_kaggle_dataset/resultados_multiclase/ejemplos_multiclase.png\n"
     ]
    }
   ],
   "source": [
    "# Evaluación en dataset original (clasificación multi-clase)\n",
    "print(\"\\n EVALUACIÓN: Clasificación Multi-Clase (Dataset Leather Defect)\")\n",
    "print(\"=\" * 60)\n",
    "#def eval_model(model, test_loader, device, class_names, model_name, output_dir):\n",
    "original_results = eval_model(\n",
    "    model, val_loader, device, CLASS_NAMES, model_name, reports_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69399b53",
   "metadata": {},
   "source": [
    "#### Validación Cualitativa en MVTec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e2bd852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " VALIDACIÓN VISUAL: MVTec AD (Cualitativa)\n",
      "============================================================\n",
      " Generando mapas de calor para validación visual...\n",
      " Siguiendo el enfoque del paper: validación cualitativa únicamente\n",
      "Procesando 12 imágenes de ejemplo...\n",
      "   Validación visual guardada: reports/best_modelo_kaggle_dataset/resultados_mvtec_visual/validacion_visual_mvtec.png\n",
      "   Imágenes de referencia guardadas: reports/best_modelo_kaggle_dataset/resultados_mvtec_visual/imagenes_ejemplo_mvtec.png\n",
      "   Resumen detallado guardado: reports/best_modelo_kaggle_dataset/resultados_mvtec_visual/visual_validation_summary.txt\n",
      "\n",
      " VALIDACIÓN VISUAL COMPLETADA:\n",
      "   - 12 imágenes procesadas\n",
      "   - Mapas de calor generados según metodología del paper\n",
      "   - Sin métricas cuantitativas (siguiendo el paper)\n",
      "   - Enfoque en demostración visual de capacidades\n"
     ]
    }
   ],
   "source": [
    "# Validación Visual en MVTec AD (como en el paper)\n",
    "print(\"\\n VALIDACIÓN VISUAL: MVTec AD (Cualitativa)\")\n",
    "print(\"=\" * 60)\n",
    "mvtec_visual_results = visual_validation_mvtec(model, mvtec_test_loader, device, model_name, reports_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ec2a8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ¡EXPERIMENTO MULTI-CLASE COMPLETADO!\n",
      "============================================================\n",
      "🎓 ENTRENAMIENTO: Dataset original del paper (6 categorías)\n",
      "   Clasificación Multi-clase: 0.9903\n",
      "   Detección Anomalías (Original): 0.9999\n",
      "\n",
      " VALIDACIÓN VISUAL: MVTec AD (Enfoque del Paper)\n",
      "   Muestras procesadas: 12\n",
      "   Normales: 0\n",
      "   Anomalías: 12\n",
      "   Detecciones correctas: 12\n",
      "\n",
      " Resultados guardados en:\n",
      "  - results_original/ (clasificación multi-clase)\n",
      "  - results_mvtec_visual/ (validación visual MVTec)\n",
      "\n",
      " Método: Paper completo - Entrenamiento multi-clase + Validación visual MVTec\n",
      "\n",
      " Nota: MVTec usado solo para validación visual siguiendo metodología del paper\n",
      "     (sin métricas cuantitativas como recomienda el paper original)\n"
     ]
    }
   ],
   "source": [
    "# Resumen final\n",
    "print(\"\\n ¡EXPERIMENTO MULTI-CLASE COMPLETADO!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"🎓 ENTRENAMIENTO: Dataset original del paper (6 categorías)\")\n",
    "print(f\"   Clasificación Multi-clase: {original_results['multiclass_accuracy']:.4f}\")\n",
    "\n",
    "if 'anomaly_detection_results' in original_results:\n",
    "    best_method = max(original_results['anomaly_detection_results'].keys(), \n",
    "                     key=lambda k: original_results['anomaly_detection_results'][k]['roc_auc'])\n",
    "    best_auc_original = original_results['anomaly_detection_results'][best_method]['roc_auc']\n",
    "    print(f\"   Detección Anomalías (Original): {best_auc_original:.4f}\")\n",
    "\n",
    "print(f\"\\n VALIDACIÓN VISUAL: MVTec AD (Enfoque del Paper)\")\n",
    "print(f\"   Muestras procesadas: {mvtec_visual_results['samples_processed']}\")\n",
    "print(f\"   Normales: {mvtec_visual_results['normal_samples']}\")\n",
    "print(f\"   Anomalías: {mvtec_visual_results['anomaly_samples']}\")\n",
    "print(f\"   Detecciones correctas: {mvtec_visual_results['correct_detections']}\")\n",
    "\n",
    "print(f\"\\n Resultados guardados en:\")\n",
    "print(f\"  - results_original/ (clasificación multi-clase)\")\n",
    "print(f\"  - results_mvtec_visual/ (validación visual MVTec)\")\n",
    "print(f\"\\n Método: Paper completo - Entrenamiento multi-clase + Validación visual MVTec\")\n",
    "print(f\"\\n Nota: MVTec usado solo para validación visual siguiendo metodología del paper\")\n",
    "print(f\"     (sin métricas cuantitativas como recomienda el paper original)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpc3-grupal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
