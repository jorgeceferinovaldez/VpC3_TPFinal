<img src="https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg" width="500" align="center">

<hr>

# MaestrÃ­a en Inteligencia Artificial

# VisiÃ³n por Computadora 3

# Trabajo PrÃ¡ctico NÃºmero 3

---
# Integrantes:
   - **Jorge Ceferino Valdez**
   - **MatÃ­as Marando**
   - **Fabian Sarmiento**

# DetecciÃ³n de AnomalÃ­as en MVTec AD con Swin Transformer

Este proyecto implementa un sistema de detecciÃ³n de anomalÃ­as utilizando Swin Transformer en el dataset MVTec AD. Se implementan dos enfoques diferentes: supervisado y no supervisado (autoencoder).

## ğŸ“‹ DescripciÃ³n

El proyecto utiliza Vision Transformers (especÃ­ficamente Swin Transformer) para detectar anomalÃ­as en imÃ¡genes industriales del dataset MVTec AD. Se incluyen dos aproximaciones:

- **Modelo Supervisado**: ClasificaciÃ³n binaria normal vs. anÃ³malo
- **Modelo Autoencoder**: DetecciÃ³n de anomalÃ­as basada en error de reconstrucciÃ³n

## ğŸ—ï¸ Estructura del Proyecto

```
â”œâ”€â”€ data/                          # Dataset MVTec AD (se descarga automÃ¡ticamente)
â”œâ”€â”€ models/                        # Modelos entrenados guardados
â”œâ”€â”€ reports/                       # Reportes, grÃ¡ficos y visualizaciones
â”‚   â”œâ”€â”€ examples/                  # Ejemplos de predicciones
â”‚   â”œâ”€â”€ anomaly_maps/             # Mapas de anomalÃ­as
â”‚   â”œâ”€â”€ curvas_de_evaluacion.png  # Curvas ROC y Precision-Recall
â”‚   â”œâ”€â”€ confusion_matrix.png      # Matriz de confusiÃ³n
â”‚   â””â”€â”€ resultados_finales.json   # MÃ©tricas finales
â”œâ”€â”€ 1.0.download-dataset.ipynb    # Notebook: Descarga y extrae el dataset
â”œâ”€â”€ 2.0-EDA.ipynb                 # Notebook: AnÃ¡lisis exploratorio de datos
â”œâ”€â”€ 3.0.model-training.ipynb      # Notebook: Entrenamiento y evaluaciÃ³n
â”œâ”€â”€ requirements.txt              # Dependencias del proyecto
â””â”€â”€ README.md                     # Este archivo
```

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/jorgeceferinovaldez/VpC3_TPFinal.git
cd mvtec-anomaly-detection
```

### 2. Crear entorno virtual (recomendado)
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

## ğŸ“Š Dataset

El proyecto utiliza el dataset **MVTec AD** (Anomaly Detection), que contiene:
- 15 categorÃ­as de objetos industriales
- ImÃ¡genes normales para entrenamiento
- ImÃ¡genes normales y anÃ³malas para test
- MÃ¡scaras de ground truth para anomalÃ­as

### CategorÃ­as incluidas:
- bottle, cable, capsule, carpet, grid
- hazelnut, leather, metal_nut, pill, screw
- tile, toothbrush, transistor, wood, zipper

## ğŸ¯ Uso

### 1. Descargar y preparar el dataset
Ejecuta el notebook `1.0.download-dataset.ipynb` para descargar automÃ¡ticamente el dataset MVTec AD desde Google Drive y extraerlo en la carpeta `data/`.

### 2. AnÃ¡lisis exploratorio de datos (opcional)
Ejecuta el notebook `2.0-EDA.ipynb` para:
- Visualizar la distribuciÃ³n de imÃ¡genes por categorÃ­a
- Explorar ejemplos de imÃ¡genes normales y anÃ³malas
- Generar grÃ¡ficos estadÃ­sticos del dataset

### 3. Entrenamiento y evaluaciÃ³n
Ejecuta el notebook `3.0.model-training.ipynb` para:
- Entrenar el modelo seleccionado (supervisado o autoencoder)
- Evaluar el rendimiento en el conjunto de test
- Generar visualizaciones y reportes

## âš™ï¸ ConfiguraciÃ³n

En el notebook `3.0.model-training.ipynb` puedes modificar las siguientes variables en las celdas correspondientes:

```python
# Tipo de modelo
model_type = 'autoencoder'  # o 'supervisado'

# HiperparÃ¡metros
batch_size = 8
lr = 1e-4
num_epochs = 10  # Ajustar segÃºn necesidades
pretrained = True
```

### EjecuciÃ³n en Jupyter

Para ejecutar los notebooks:

1. **Iniciar Jupyter Lab/Notebook**:
```bash
jupyter lab
# o
jupyter notebook
```

2. **Ejecutar notebooks en orden**:
   - `1.0.download-dataset.ipynb` (una sola vez)
   - `2.0-EDA.ipynb` (opcional, para exploraciÃ³n)
   - `3.0.model-training.ipynb` (entrenamiento principal)

## ğŸ›ï¸ Arquitectura de los Modelos

### Modelo Supervisado
- **Backbone**: Swin Transformer Tiny pre-entrenado
- **Cabeza**: Red neuronal con capas lineales, BatchNorm, ReLU y Dropout
- **Salida**: Probabilidad de anomalÃ­a (0-1)
- **PÃ©rdida**: Binary Cross Entropy (BCE)

### Modelo Autoencoder
- **Encoder**: Swin Transformer Tiny pre-entrenado
- **Decoder**: Red neuronal que reconstruye la imagen
- **DetecciÃ³n**: Error de reconstrucciÃ³n MSE
- **PÃ©rdida**: Mean Squared Error (MSE)

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

El sistema evalÃºa los modelos utilizando:
- **ROC AUC**: Ãrea bajo la curva ROC
- **Precision-Recall AUC**: Ãrea bajo la curva Precision-Recall
- **Accuracy**: PrecisiÃ³n general
- **Precision, Recall, F1-Score**: MÃ©tricas de clasificaciÃ³n binaria

## ğŸ“Š Visualizaciones

El proyecto genera automÃ¡ticamente:

1. **AnÃ¡lisis Exploratorio**:
   - DistribuciÃ³n de imÃ¡genes por categorÃ­a
   - Ejemplos de imÃ¡genes normales y anÃ³malas

2. **Resultados de EvaluaciÃ³n**:
   - Curvas ROC y Precision-Recall
   - Matriz de confusiÃ³n
   - Ejemplos de predicciones (TP, TN, FP, FN)
   - Mapas de anomalÃ­as (para autoencoder)

## ğŸ”§ CaracterÃ­sticas TÃ©cnicas

- **Framework**: PyTorch
- **Transformaciones**: Redimensionado, normalizaciÃ³n, data augmentation
- **Optimizador**: AdamW con weight decay
- **Scheduler**: Cosine Annealing Learning Rate
- **Dispositivo**: Soporte automÃ¡tico para CUDA, MPS (Apple Silicon) y CPU
- **Reproducibilidad**: Seeds fijas para resultados consistentes

## ğŸ“‹ Resultados Esperados

El modelo genera los siguientes archivos de salida:

```
models/
â”œâ”€â”€ mejor_modelo_supervisado.pth      # Mejor modelo supervisado
â””â”€â”€ mejor_modelo_multiclase_autoencoder.pth  # Mejor modelo autoencoder

reports/
â”œâ”€â”€ curvas_de_evaluacion.png         # Curvas ROC y PR
â”œâ”€â”€ confusion_matrix.png             # Matriz de confusiÃ³n
â”œâ”€â”€ resultados_finales.json          # MÃ©tricas en formato JSON
â”œâ”€â”€ examples/                        # Ejemplos de predicciones
â”‚   â”œâ”€â”€ true_positive.png
â”‚   â”œâ”€â”€ true_negative.png
â”‚   â”œâ”€â”€ false_positive.png
â”‚   â””â”€â”€ false_negative.png
â””â”€â”€ anomaly_maps/                    # Mapas de anomalÃ­as
    â”œâ”€â”€ normal_0.png
    â”œâ”€â”€ normal_1.png
    â”œâ”€â”€ anomaly_0.png
    â””â”€â”€ anomaly_1.png
```

## ğŸ› ï¸ Requisitos del Sistema

- Python 3.8+
- 8GB+ RAM recomendado
- GPU con CUDA (opcional, mejora significativamente el rendimiento)
- ~5GB de espacio en disco para el dataset

## ğŸ› SoluciÃ³n de Problemas

### Error de memoria
```python
# Reducir batch_size en 3.0.model-training.py
batch_size = 4  # En lugar de 8
```

### Error de CUDA
```python
# El cÃ³digo detecta automÃ¡ticamente el dispositivo disponible
# Si hay problemas con CUDA, forzar CPU:
device = "cpu"
```

### Dataset no encontrado
```bash
# Ejecutar nuevamente el notebook de descarga
# Abrir y ejecutar: 1.0.download-dataset.ipynb
```

### Error al ejecutar notebooks
- AsegÃºrate de que Jupyter estÃ© instalado: `pip install jupyter`
- Inicia Jupyter Lab: `jupyter lab`
- Ejecuta las celdas en orden secuencial

## ğŸ“š Referencias

- [MVTec AD Dataset](https://www.mvtec.com/company/research/datasets/mvtec-ad)
- [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)
- [Timm: PyTorch Image Models](https://github.com/rwightman/pytorch-image-models)

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver el archivo LICENSE para mÃ¡s detalles.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue para discutir cambios mayores antes de enviar un pull request.

## ğŸ“§ Contacto

Para preguntas o problemas, por favor abre un issue en el repositorio.

---

**Nota**: Este proyecto es para fines educativos y de investigaciÃ³n. Los resultados pueden variar segÃºn el hardware y la configuraciÃ³n utilizada.